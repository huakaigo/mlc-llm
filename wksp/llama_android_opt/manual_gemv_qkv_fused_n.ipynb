{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=================final mod===============================\n",
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(lv8: T.Buffer((512, 12288), \"uint32\"), lv9: T.Buffer((128, 12288), \"float16\"), p_lv6: T.handle, p_output0: T.handle):\n",
      "        T.func_attr({\"tir.is_scheduled\": 1, \"tir.noalias\": T.bool(True)})\n",
      "        n = T.int32()\n",
      "        lv6 = T.match_buffer(p_lv6, (1, n, 4096), \"float16\")\n",
      "        var_NT_matmul_intermediate = T.match_buffer(p_output0, (1, n, 12288), \"float16\")\n",
      "        # with T.block(\"root\"):\n",
      "        decode_local = T.alloc_buffer((4096, 12288), \"float16\", scope=\"local\")\n",
      "        lv8_local = T.alloc_buffer((512, 12288), \"uint32\", scope=\"local\")\n",
      "        lv9_local = T.alloc_buffer((128, 12288), \"float16\", scope=\"local\")\n",
      "        lv6_pad_local = T.alloc_buffer((1, (n + 31) // 32 * 32, 4096), \"float16\", scope=\"local\")\n",
      "        var_NT_matmul_intermediate_pad_local = T.alloc_buffer((1, (n + 31) // 32 * 32, 12288), \"float16\", scope=\"local\")\n",
      "        BlockIdx_x: T.int32 = 24\n",
      "        ThreadIdx_x: T.int32 = 128\n",
      "        ThreadIdx_y: T.int32 = 2\n",
      "        vectorize_factor: T.int32 = 4\n",
      "        processed_columns_per_thread: T.int32 = vectorize_factor\n",
      "        processed_rows_per_thread: T.int32 = 16\n",
      "        for i0_i1_fused_0_i0_i1_fused_1_0_fused in T.thread_binding((n + 31) // 32, thread=\"blockIdx.y\"):\n",
      "            for i2_0 in T.thread_binding(BlockIdx_x, thread=\"blockIdx.x\"):\n",
      "                for i0_i1_fused_1_1 in T.thread_binding(ThreadIdx_y, thread=\"threadIdx.y\"):\n",
      "                    for i2_1 in T.thread_binding(ThreadIdx_x, thread=\"threadIdx.x\"):\n",
      "                        for i0_i1_fused_1_2_init in range(processed_rows_per_thread):\n",
      "                            for i2_2_init in T.vectorized(vectorize_factor):\n",
      "                                with T.block(\"NT_matmul_init\"):\n",
      "                                    v_i0 = T.axis.spatial(1, 0)\n",
      "                                    v_i1 = T.axis.spatial((n + 31) // 32 * 32, i0_i1_fused_0_i0_i1_fused_1_0_fused * 32 + i0_i1_fused_1_1 * processed_rows_per_thread + i0_i1_fused_1_2_init)\n",
      "                                    v_i2 = T.axis.spatial(12288, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + i2_2_init)\n",
      "                                    T.reads()\n",
      "                                    T.writes(var_NT_matmul_intermediate_pad_local[v_i0, v_i1, v_i2])\n",
      "                                    var_NT_matmul_intermediate_pad_local[v_i0, v_i1, v_i2] = T.float16(0)\n",
      "                        for k_0 in range(128):\n",
      "                            for ax0 in range(1):\n",
      "                                for ax1 in T.vectorized(vectorize_factor):\n",
      "                                    with T.block(\"lv9_local\"):\n",
      "                                        v0 = T.axis.spatial(128, k_0 + ax0)\n",
      "                                        v1 = T.axis.spatial(12288, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + ax1)\n",
      "                                        T.reads(lv9[v0, v1])\n",
      "                                        T.writes(lv9_local[v0, v1])\n",
      "                                        lv9_local[v0, v1] = lv9[v0, v1]\n",
      "                            for k_1 in range(4):\n",
      "                                for ax0 in range(1):\n",
      "                                    for ax1 in T.vectorized(vectorize_factor):\n",
      "                                        with T.block(\"lv8_local\"):\n",
      "                                            v0 = T.axis.spatial(512, k_0 * 4 + k_1 + ax0)\n",
      "                                            v1 = T.axis.spatial(12288, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + ax1)\n",
      "                                            T.reads(lv8[v0, v1])\n",
      "                                            T.writes(lv8_local[v0, v1])\n",
      "                                            lv8_local[v0, v1] = lv8[v0, v1]\n",
      "                                for k_2 in range(8):\n",
      "                                    for ax0 in range(1):\n",
      "                                        for ax1 in T.vectorized(vectorize_factor):\n",
      "                                            with T.block(\"decode\"):\n",
      "                                                v_i = T.axis.spatial(4096, k_0 * 32 + k_1 * 8 + k_2 + ax0)\n",
      "                                                v_j = T.axis.spatial(12288, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + ax1)\n",
      "                                                T.reads(lv8_local[v_i // 8, v_j], lv9_local[v_i // 32, v_j])\n",
      "                                                T.writes(decode_local[v_i, v_j])\n",
      "                                                decode_local[v_i, v_j] = (T.Cast(\"float16\", T.bitwise_and(T.shift_right(lv8_local[v_i // 8, v_j], T.Cast(\"uint32\", v_i % 8) * T.uint32(4)), T.uint32(15))) - T.float16(7)) * lv9_local[v_i // 32, v_j]\n",
      "                                    for ax0, ax1 in T.grid(1, processed_rows_per_thread):\n",
      "                                        for ax2 in T.vectorized(1):\n",
      "                                            with T.block(\"lv6_pad_local\"):\n",
      "                                                v0 = T.axis.spatial(1, ax0)\n",
      "                                                v1 = T.axis.spatial((n + 31) // 32 * 32, i0_i1_fused_0_i0_i1_fused_1_0_fused * 32 + i0_i1_fused_1_1 * processed_rows_per_thread + ax1)\n",
      "                                                v2 = T.axis.spatial(4096, k_0 * 32 + k_1 * 8 + k_2 + ax2)\n",
      "                                                T.reads(lv6[v0, v1, v2])\n",
      "                                                T.writes(lv6_pad_local[v0, v1, v2])\n",
      "                                                lv6_pad_local[v0, v1, v2] = T.if_then_else(v1 < n, lv6[v0, v1, v2], T.float16(0))\n",
      "                                    for i0_i1_fused_1_2 in range(processed_rows_per_thread):\n",
      "                                        for i2_2 in T.vectorized(vectorize_factor):\n",
      "                                            with T.block(\"NT_matmul_update\"):\n",
      "                                                v_i0 = T.axis.spatial(1, 0)\n",
      "                                                v_i1 = T.axis.spatial((n + 31) // 32 * 32, i0_i1_fused_0_i0_i1_fused_1_0_fused * 32 + i0_i1_fused_1_1 * processed_rows_per_thread + i0_i1_fused_1_2)\n",
      "                                                v_i2 = T.axis.spatial(12288, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + i2_2)\n",
      "                                                v_k = T.axis.reduce(4096, k_0 * 32 + k_1 * 8 + k_2)\n",
      "                                                T.reads(var_NT_matmul_intermediate_pad_local[v_i0, v_i1, v_i2], lv6_pad_local[v_i0, v_i1, v_k], decode_local[v_k, v_i2])\n",
      "                                                T.writes(var_NT_matmul_intermediate_pad_local[v_i0, v_i1, v_i2])\n",
      "                                                var_NT_matmul_intermediate_pad_local[v_i0, v_i1, v_i2] = var_NT_matmul_intermediate_pad_local[v_i0, v_i1, v_i2] + lv6_pad_local[v_i0, v_i1, v_k] * decode_local[v_k, v_i2]\n",
      "                        for ax0, ax1 in T.grid(1, processed_rows_per_thread):\n",
      "                            for ax2 in T.vectorized(vectorize_factor):\n",
      "                                with T.block(\"var_NT_matmul_intermediate_pad_local\"):\n",
      "                                    v0 = T.axis.spatial(1, ax0)\n",
      "                                    v1 = T.axis.spatial((n + 31) // 32 * 32, i0_i1_fused_0_i0_i1_fused_1_0_fused * 32 + i0_i1_fused_1_1 * processed_rows_per_thread + ax1)\n",
      "                                    v2 = T.axis.spatial(12288, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + ax2)\n",
      "                                    T.reads(var_NT_matmul_intermediate_pad_local[v0, v1, v2])\n",
      "                                    T.writes(var_NT_matmul_intermediate[v0, v1, v2])\n",
      "                                    if v1 < n:\n",
      "                                        var_NT_matmul_intermediate[v0, v1, v2] = var_NT_matmul_intermediate_pad_local[v0, v1, v2]\n",
      "\n",
      "\n",
      "=================kernel source===============================\n",
      "// Function: main_kernel\n",
      "#ifdef cl_khr_fp16\n",
      "#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n",
      "#elif defined(cl_amd_fp16)\n",
      "#pragma OPENCL EXTENSION cl_amd_fp16 : enable\n",
      "#else\n",
      "#error \"Half precision floating point not supported by OpenCL implementation on your device.\" \n",
      "#endif\n",
      "\n",
      "__kernel void main_kernel(__global half* restrict lv6, __global uint* restrict lv8, __global half* restrict lv9, __global half* restrict var_NT_matmul_intermediate, int n) {\n",
      "  half4 var_NT_matmul_intermediate_pad_local[16];\n",
      "  half4 lv9_local[1];\n",
      "  uint4 lv8_local[1];\n",
      "  half4 decode_local[1];\n",
      "  half lv6_pad_local[16];\n",
      "  for (int i0_i1_fused_1_2_init = 0; i0_i1_fused_1_2_init < 16; ++i0_i1_fused_1_2_init) {\n",
      "    var_NT_matmul_intermediate_pad_local[i0_i1_fused_1_2_init] = ((half4)((half)0.000000e+00f, (half)0.000000e+00f, (half)0.000000e+00f, (half)0.000000e+00f));\n",
      "  }\n",
      "  for (int k_0 = 0; k_0 < 128; ++k_0) {\n",
      "    lv9_local[0] = vload4(0, lv9 + (((k_0 * 12288) + ((convert_int(get_group_id(0))) * 512)) + ((convert_int(get_local_id(0))) * 4)));\n",
      "    for (int k_1 = 0; k_1 < 4; ++k_1) {\n",
      "      lv8_local[0] = vload4(0, lv8 + ((((k_0 * 49152) + (k_1 * 12288)) + ((convert_int(get_group_id(0))) * 512)) + ((convert_int(get_local_id(0))) * 4)));\n",
      "      for (int k_2 = 0; k_2 < 8; ++k_2) {\n",
      "        decode_local[0] = (((convert_half4(((lv8_local[0]  >>  ((uint4)(((convert_uint(k_2)) * (uint)4), ((convert_uint(k_2)) * (uint)4), ((convert_uint(k_2)) * (uint)4), ((convert_uint(k_2)) * (uint)4))))  &  ((uint4)((uint)15, (uint)15, (uint)15, (uint)15))))) - ((half4)((half)7.000000e+00f, (half)7.000000e+00f, (half)7.000000e+00f, (half)7.000000e+00f))) * lv9_local[0]);\n",
      "        for (int ax1 = 0; ax1 < 16; ++ax1) {\n",
      "          lv6_pad_local[ax1] = ((((((convert_int(get_group_id(1))) * 32) + ((convert_int(get_local_id(1))) * 16)) + ax1) < n) ? lv6[(((((((convert_int(get_group_id(1))) * 131072) + ((convert_int(get_local_id(1))) * 65536)) + (ax1 * 4096)) + (k_0 * 32)) + (k_1 * 8)) + k_2)] : (half)0.000000e+00f);\n",
      "        }\n",
      "        for (int i0_i1_fused_1_2 = 0; i0_i1_fused_1_2 < 16; ++i0_i1_fused_1_2) {\n",
      "          var_NT_matmul_intermediate_pad_local[i0_i1_fused_1_2] = (var_NT_matmul_intermediate_pad_local[i0_i1_fused_1_2] + (((half4)(lv6_pad_local[i0_i1_fused_1_2], lv6_pad_local[i0_i1_fused_1_2], lv6_pad_local[i0_i1_fused_1_2], lv6_pad_local[i0_i1_fused_1_2])) * decode_local[0]));\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  for (int ax1_1 = 0; ax1_1 < 16; ++ax1_1) {\n",
      "    if (((((convert_int(get_group_id(1))) * 32) + ((convert_int(get_local_id(1))) * 16)) + ax1_1) < n) {\n",
      "      vstore4(var_NT_matmul_intermediate_pad_local[ax1_1], 0, var_NT_matmul_intermediate + ((((((convert_int(get_group_id(1))) * 393216) + ((convert_int(get_local_id(1))) * 196608)) + (ax1_1 * 12288)) + ((convert_int(get_group_id(0))) * 512)) + ((convert_int(get_local_id(0))) * 4)));\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tvm\n",
    "from tvm.script import ir as I\n",
    "from tvm.script import tir as T\n",
    "from tvm import autotvm, auto_scheduler\n",
    "from tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n",
    "from tvm import meta_schedule as ms\n",
    "from tvm.ir import IRModule\n",
    "from tvm import relax\n",
    "from tvm import rpc\n",
    "from tvm.contrib import utils, ndk\n",
    "x_shape = 4096\n",
    "w_w_x = 512\n",
    "w_s_x = 128\n",
    "w_y = 4096*3\n",
    "func_name = \"main\"\n",
    "@I.ir_module\n",
    "class ModuleSrc:\n",
    "    @T.prim_func(private=False)\n",
    "    # fused_fused_decode2_NT_matmul\n",
    "    def main(lv4: T.Buffer((T.int64(512), T.int64(12288)), \"uint32\"), lv5: T.Buffer((T.int64(128), T.int64(12288)), \"float16\"), p_lv6: T.handle, p_output0: T.handle):\n",
    "        T.func_attr({\"tir.noalias\": T.bool(True)})\n",
    "        n = T.int64()\n",
    "        lv6 = T.match_buffer(p_lv6, (T.int64(1), n, T.int64(4096)), \"float16\")\n",
    "        var_NT_matmul_intermediate = T.match_buffer(p_output0, (T.int64(1), n, T.int64(12288)), \"float16\")\n",
    "        # with T.block(\"root\"):\n",
    "        decode = T.alloc_buffer((T.int64(4096), T.int64(12288)), \"float16\")\n",
    "        p_output0_intermediate = T.alloc_buffer((T.int64(12288), T.int64(4096)), \"float16\")\n",
    "        for i, j in T.grid(T.int64(4096), T.int64(12288)):\n",
    "            with T.block(\"decode\"):\n",
    "                v_i, v_j = T.axis.remap(\"SS\", [i, j])\n",
    "                T.reads(lv4[v_i // T.int64(8), v_j], lv5[v_i // T.int64(32), v_j])\n",
    "                T.writes(decode[v_i, v_j])\n",
    "                decode[v_i, v_j] = (T.Cast(\"float16\", T.bitwise_and(T.shift_right(lv4[v_i // T.int64(8), v_j], T.Cast(\"uint32\", v_i % T.int64(8)) * T.uint32(4)), T.uint32(15))) - T.float16(7)) * lv5[v_i // T.int64(32), v_j]\n",
    "        for ax0, ax1 in T.grid(T.int64(12288), T.int64(4096)):\n",
    "            with T.block(\"T_transpose\"):\n",
    "                v_ax0, v_ax1 = T.axis.remap(\"SS\", [ax0, ax1])\n",
    "                T.reads(decode[v_ax1, v_ax0])\n",
    "                T.writes(p_output0_intermediate[v_ax0, v_ax1])\n",
    "                p_output0_intermediate[v_ax0, v_ax1] = decode[v_ax1, v_ax0]\n",
    "        for i0, i1, i2, k in T.grid(T.int64(1), n, T.int64(12288), T.int64(4096)):\n",
    "            with T.block(\"NT_matmul\"):\n",
    "                v_i0, v_i1, v_i2, v_k = T.axis.remap(\"SSSR\", [i0, i1, i2, k])\n",
    "                T.reads(lv6[v_i0, v_i1, v_k], p_output0_intermediate[v_i2, v_k])\n",
    "                T.writes(var_NT_matmul_intermediate[v_i0, v_i1, v_i2])\n",
    "                with T.init():\n",
    "                    var_NT_matmul_intermediate[v_i0, v_i1, v_i2] = T.float16(0)\n",
    "                var_NT_matmul_intermediate[v_i0, v_i1, v_i2] = var_NT_matmul_intermediate[v_i0, v_i1, v_i2] + lv6[v_i0, v_i1, v_k] * p_output0_intermediate[v_i2, v_k]\n",
    "\n",
    "\n",
    "@I.ir_module\n",
    "class ModuleToManual:\n",
    "    @T.prim_func(private=False)\n",
    "    # fused_decode_NT_matmul_after\n",
    "    # 优化kernel配置:\n",
    "    # vf pr bx  tx ty\n",
    "    # 4\t 4\t48\t64\t8\n",
    "    def main(\n",
    "        lv8: T.Buffer((512, w_y), \"uint32\"),\n",
    "        lv9: T.Buffer((128, w_y), \"float16\"),\n",
    "        p_lv6: T.handle,\n",
    "        p_output0: T.handle,\n",
    "    ):\n",
    "        T.func_attr({\"tir.noalias\": T.bool(True), \"tir.is_scheduled\": 1})\n",
    "        n = T.int32()\n",
    "        #输入hidden states\n",
    "        lv6 = T.match_buffer(p_lv6, (1, n, 4096), \"float16\")\n",
    "        # 输出 [1, n, 12288]\n",
    "        var_NT_matmul_intermediate = T.match_buffer(p_output0, (1, n, w_y), \"float16\")\n",
    "        # with T.block(\"root\"):\n",
    "        # 解码后的shape不变\n",
    "        decode_local = T.alloc_buffer((4096, w_y), \"float16\", scope=\"local\")\n",
    "        lv8_local = T.alloc_buffer((512, w_y), \"uint32\", scope=\"local\")\n",
    "        lv9_local = T.alloc_buffer((128, w_y), \"float16\", scope=\"local\")\n",
    "        # 输入, 将n padding到32的倍数\n",
    "        lv6_pad_local = T.alloc_buffer(\n",
    "            (1, (n + 31) // 32 * 32, 4096), \"float16\", scope=\"local\"\n",
    "        )\n",
    "        # 输出中间结果, padding到32的倍数\n",
    "        var_NT_matmul_intermediate_pad_local = T.alloc_buffer(\n",
    "            (1, (n + 31) // 32 * 32, w_y), \"float16\", scope=\"local\"\n",
    "        )\n",
    "\n",
    "        # 任务划分:\n",
    "        ### 一个thread处理 `processed_rows_per_thread`行 `vectorize_factor` 列(输出角度)\n",
    "        ### 完整处理 `processed_rows_per_thread` 行输入需要: blockIdx.x * threadIdx.x 配合\n",
    "        ### 完整处理 `n` 行输入需要: blockIdx.y * threadIdx.y 配合\n",
    "        #### 分析: 根据`n`变化的只有 blockIdx.y, 说明 blockIdx.x * threadIdx.x * threadIdx.y 可以完整处理32行输入\n",
    "        #  4 16 24 128 2\n",
    "        BlockIdx_x = 24#32\n",
    "        # n = 32\n",
    "        # BlockIdx_y = (n+31)//32 * 32 # 这里32是假设输入为32的倍数, //32的32 = thready * \n",
    "        ThreadIdx_x = 128#16 * 3\n",
    "        ThreadIdx_y = 2#8\n",
    "        vectorize_factor = 4#8\n",
    "        processed_columns_per_thread = vectorize_factor# w_y / (BlockIdx_x * ThreadIdx_x) == vectorize_factor\n",
    "        processed_rows_per_thread = 16#4 32 / threadIdx.y\n",
    "\n",
    "        #\n",
    "        # BlockIdx_x = 32\n",
    "        # # n = 32\n",
    "        # # BlockIdx_y = (n+31)//32 * 32 # 这里32是假设输入为32的倍数, //32的32 = thready * \n",
    "        # ThreadIdx_x = 16 * 3\n",
    "        # ThreadIdx_y = 8\n",
    "        # vectorize_factor = 8\n",
    "        # processed_columns_per_thread = vectorize_factor# w_y / (BlockIdx_x * ThreadIdx_x) == vectorize_factor\n",
    "        # processed_rows_per_thread = 4\n",
    "\n",
    "        ## BlockIdx.y == [BlockIdx.x, ThreadIdx.x, ThraedIdx.y] 解决 seq_length为32的处理\n",
    "        for i0_i1_fused_0_i0_i1_fused_1_0_fused in T.thread_binding(\n",
    "            (n + 31) // 32, thread=\"blockIdx.y\"\n",
    "        ):\n",
    "            # 32的倍数, block负责完成n/processed_rows_per_thread的处理, thread负责完成 processed_rows_per_thread/n的处理\n",
    "            for i2_0 in T.thread_binding(BlockIdx_x, thread=\"blockIdx.x\"):\n",
    "                # threadIdx.X * threadIdx.y 是线程数，每个线程处理 4*8个元素的和\n",
    "                for i0_i1_fused_1_1 in T.thread_binding(ThreadIdx_y, thread=\"threadIdx.y\"):\n",
    "                    for i2_1 in T.thread_binding(ThreadIdx_x, thread=\"threadIdx.x\"):\n",
    "                        for i0_i1_fused_1_2_init in range(processed_rows_per_thread):\n",
    "                            for i2_2_init in T.vectorized(vectorize_factor):\n",
    "                                with T.block(\"NT_matmul_init\"):\n",
    "                                    v_i0 = T.axis.spatial(1, 0)\n",
    "                                    v_i1 = T.axis.spatial(\n",
    "                                        (n + 31) // 32 * 32,\n",
    "                                        i0_i1_fused_0_i0_i1_fused_1_0_fused * 32\n",
    "                                        + i0_i1_fused_1_1 * processed_rows_per_thread\n",
    "                                        + i0_i1_fused_1_2_init,\n",
    "                                    )\n",
    "                                    v_i2 = T.axis.spatial(\n",
    "                                        w_y, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + i2_2_init\n",
    "                                    )\n",
    "                                    T.reads()\n",
    "                                    T.writes(\n",
    "                                        var_NT_matmul_intermediate_pad_local[\n",
    "                                            v_i0, v_i1, v_i2\n",
    "                                        ]\n",
    "                                    )\n",
    "                                    var_NT_matmul_intermediate_pad_local[\n",
    "                                        v_i0, v_i1, v_i2\n",
    "                                    ] = T.float16(0)\n",
    "                        for k_0 in range(128):\n",
    "                            for ax0 in range(1):\n",
    "                                for ax1 in T.vectorized(vectorize_factor):\n",
    "                                    with T.block(\"lv9_local\"):\n",
    "                                        v0 = T.axis.spatial(128, k_0 + ax0)\n",
    "                                        v1 = T.axis.spatial(\n",
    "                                            w_y, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + ax1\n",
    "                                        )\n",
    "                                        T.reads(lv9[v0, v1])\n",
    "                                        T.writes(lv9_local[v0, v1])\n",
    "                                        lv9_local[v0, v1] = lv9[v0, v1]\n",
    "                            for k_1 in range(4):\n",
    "                                for ax0 in range(1):\n",
    "                                    for ax1 in T.vectorized(vectorize_factor):\n",
    "                                        with T.block(\"lv8_local\"):\n",
    "                                            v0 = T.axis.spatial(512, k_0 * 4 + k_1 + ax0)\n",
    "                                            v1 = T.axis.spatial(\n",
    "                                                w_y, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + ax1\n",
    "                                            )\n",
    "                                            T.reads(lv8[v0, v1])\n",
    "                                            T.writes(lv8_local[v0, v1])\n",
    "                                            lv8_local[v0, v1] = lv8[v0, v1]\n",
    "                                for k_2 in range(8):\n",
    "                                    for ax0 in range(1):\n",
    "                                        for ax1 in T.vectorized(vectorize_factor):\n",
    "                                            with T.block(\"decode\"):\n",
    "                                                v_i = T.axis.spatial(\n",
    "                                                    4096, k_0 * 32 + k_1 * 8 + k_2 + ax0\n",
    "                                                )\n",
    "                                                v_j = T.axis.spatial(\n",
    "                                                    w_y, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + ax1\n",
    "                                                )\n",
    "                                                T.reads(\n",
    "                                                    lv8_local[v_i // 8, v_j],\n",
    "                                                    lv9_local[v_i // 32, v_j],\n",
    "                                                )\n",
    "                                                T.writes(decode_local[v_i, v_j])\n",
    "                                                decode_local[v_i, v_j] = (\n",
    "                                                    T.Cast(\n",
    "                                                        \"float16\",\n",
    "                                                        T.bitwise_and(\n",
    "                                                            T.shift_right(\n",
    "                                                                lv8_local[v_i // 8, v_j],\n",
    "                                                                T.Cast(\"uint32\", v_i % 8)\n",
    "                                                                * T.uint32(4),\n",
    "                                                            ),\n",
    "                                                            T.uint32(15),\n",
    "                                                        ),\n",
    "                                                    )\n",
    "                                                    - T.float16(7)\n",
    "                                                ) * lv9_local[v_i // 32, v_j]\n",
    "                                    for ax0, ax1 in T.grid(1, processed_rows_per_thread):\n",
    "                                        for ax2 in T.vectorized(1):\n",
    "                                            with T.block(\"lv6_pad_local\"):\n",
    "                                                v0 = T.axis.spatial(1, ax0)\n",
    "                                                v1 = T.axis.spatial(\n",
    "                                                    (n + 31) // 32 * 32,\n",
    "                                                    i0_i1_fused_0_i0_i1_fused_1_0_fused * 32\n",
    "                                                    + i0_i1_fused_1_1 * processed_rows_per_thread\n",
    "                                                    + ax1,\n",
    "                                                )\n",
    "                                                v2 = T.axis.spatial(\n",
    "                                                    4096, k_0 * 32 + k_1 * 8 + k_2 + ax2\n",
    "                                                )\n",
    "                                                T.reads(lv6[v0, v1, v2])\n",
    "                                                T.writes(lv6_pad_local[v0, v1, v2])\n",
    "                                                lv6_pad_local[v0, v1, v2] = T.if_then_else(\n",
    "                                                    v1 < n, lv6[v0, v1, v2], T.float16(0)\n",
    "                                                )\n",
    "                                    for i0_i1_fused_1_2 in range(processed_rows_per_thread):\n",
    "                                        for i2_2 in T.vectorized(vectorize_factor):\n",
    "                                            with T.block(\"NT_matmul_update\"):\n",
    "                                                v_i0 = T.axis.spatial(1, 0)\n",
    "                                                v_i1 = T.axis.spatial(\n",
    "                                                    (n + 31) // 32 * 32,\n",
    "                                                    i0_i1_fused_0_i0_i1_fused_1_0_fused * 32\n",
    "                                                    + i0_i1_fused_1_1 * processed_rows_per_thread\n",
    "                                                    + i0_i1_fused_1_2,\n",
    "                                                )\n",
    "                                                v_i2 = T.axis.spatial(\n",
    "                                                    w_y, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + i2_2\n",
    "                                                )\n",
    "                                                v_k = T.axis.reduce(\n",
    "                                                    4096, k_0 * 32 + k_1 * 8 + k_2\n",
    "                                                )\n",
    "                                                T.reads(\n",
    "                                                    var_NT_matmul_intermediate_pad_local[\n",
    "                                                        v_i0, v_i1, v_i2\n",
    "                                                    ],\n",
    "                                                    lv6_pad_local[v_i0, v_i1, v_k],\n",
    "                                                    decode_local[v_k, v_i2],\n",
    "                                                )\n",
    "                                                T.writes(\n",
    "                                                    var_NT_matmul_intermediate_pad_local[\n",
    "                                                        v_i0, v_i1, v_i2\n",
    "                                                    ]\n",
    "                                                )\n",
    "                                                var_NT_matmul_intermediate_pad_local[\n",
    "                                                    v_i0, v_i1, v_i2\n",
    "                                                ] = (\n",
    "                                                    var_NT_matmul_intermediate_pad_local[\n",
    "                                                        v_i0, v_i1, v_i2\n",
    "                                                    ]\n",
    "                                                    + lv6_pad_local[v_i0, v_i1, v_k]\n",
    "                                                    * decode_local[v_k, v_i2]\n",
    "                                                )\n",
    "                        for ax0, ax1 in T.grid(1, processed_rows_per_thread):\n",
    "                            for ax2 in T.vectorized(vectorize_factor):\n",
    "                                with T.block(\"var_NT_matmul_intermediate_pad_local\"):\n",
    "                                    v0 = T.axis.spatial(1, ax0)\n",
    "                                    v1 = T.axis.spatial(\n",
    "                                        (n + 31) // 32 * 32,\n",
    "                                        i0_i1_fused_0_i0_i1_fused_1_0_fused * 32\n",
    "                                        + i0_i1_fused_1_1 * processed_rows_per_thread\n",
    "                                        + ax1,\n",
    "                                    )\n",
    "                                    v2 = T.axis.spatial(w_y, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * (vectorize_factor) + ax2)\n",
    "                                    T.reads(\n",
    "                                        var_NT_matmul_intermediate_pad_local[v0, v1, v2]\n",
    "                                    )\n",
    "                                    T.writes(var_NT_matmul_intermediate[v0, v1, v2])\n",
    "                                    if v1 < n:\n",
    "                                        var_NT_matmul_intermediate[\n",
    "                                            v0, v1, v2\n",
    "                                        ] = var_NT_matmul_intermediate_pad_local[v0, v1, v2]\n",
    "\n",
    "sch_manual = tvm.tir.Schedule(ModuleToManual)\n",
    "# sch_manual.mod['main'] = sch_fused_decode4_matmul3(sch_manual.mod[func_name])\n",
    "print(\"\\n\\n=================final mod===============================\")\n",
    "print(sch_manual.mod.script())\n",
    "print(\"\\n\\n=================kernel source===============================\")\n",
    "rt_mod = tvm.build(sch_manual.mod, target=\"opencl\")\n",
    "print(rt_mod.imported_modules[0].get_source())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda -keys=cuda,gpu -arch=sm_61 -max_num_threads=1024 -max_shared_memory_per_block=49152 -max_threads_per_block=1024 -registers_per_block=65536 -thread_warp_size=32\n",
      "[[[-6764. -5420. -6856. -6464. -6528. -6744. -6700. -6512. -6676. -6472.]\n",
      "  [-6488. -5436. -6748. -6308. -6424. -6692. -6536. -6392. -6604. -6364.]]]\n",
      "[[[-6764. -5420. -6856. -6464. -6528. -6744. -6700. -6512. -6676. -6472.]\n",
      "  [-6488. -5436. -6748. -6308. -6424. -6692. -6536. -6392. -6604. -6364.]]]\n"
     ]
    }
   ],
   "source": [
    "# run and compare with cuda\n",
    "import numpy as np\n",
    "def _detect_local_cuda():\n",
    "    dev = tvm.cuda()\n",
    "    if not dev.exist:\n",
    "        return None\n",
    "    return tvm.target.Target(\n",
    "        {\n",
    "            \"kind\": \"cuda\",\n",
    "            \"max_shared_memory_per_block\": dev.max_shared_memory_per_block,\n",
    "            \"max_threads_per_block\": dev.max_threads_per_block,\n",
    "            \"thread_warp_size\": dev.warp_size,\n",
    "            \"registers_per_block\": 65536,\n",
    "            \"arch\": \"sm_\" + tvm.cuda().compute_version.replace(\".\", \"\"),\n",
    "        }\n",
    "    )\n",
    "# target = tvm.target.Target(\"cuda\", host=\"llvm\")\n",
    "target = _detect_local_cuda()\n",
    "\n",
    "print(target)\n",
    "# 定义计算任务\n",
    "dev = tvm.cuda(0)\n",
    "\n",
    "num_flop = 1228406784\n",
    "seq_len = 32\n",
    "W_w_np = np.random.uniform(size=(w_w_x, w_y)).astype(\"uint32\")\n",
    "W_s_np = np.random.uniform(size=(w_s_x, w_y)).astype(\"float16\")\n",
    "Input_np = np.random.uniform(size=(1, seq_len, x_shape)).astype(\"float16\")\n",
    "# W_w_np = np.ones((w_w_x, w_y), np.uint32) * 1#.astype(\"uint32\")\n",
    "# W_s_np = np.ones((w_s_x, w_y), np.float16) * 1#.astype(\"float16\") * 2\n",
    "# Input_np = np.ones((1, 1, x_shape), np.float16)#.astype(\"float16\")\n",
    "Output_nd = tvm.nd.array(np.zeros((1, seq_len, w_y), dtype=\"float16\"), dev)\n",
    "def numpy_caculate():\n",
    "    test_rows = 2\n",
    "    test_cols = 10\n",
    "    output = np.zeros((1, test_rows, test_cols), dtype = np.float16)\n",
    "    W_w_inv_np = np.transpose(W_w_np)\n",
    "    W_s_inv_np = np.transpose(W_s_np)\n",
    "    for row in range(test_rows):\n",
    "        for i in range(test_cols):\n",
    "            for r in range(x_shape):\n",
    "                temp = Input_np[0][row][r] * np.float16((W_w_inv_np[i][r // 8] >> ((r % 8) * 4) & (15)) - np.float16(7.0)) * W_s_inv_np[i][r // 32]\n",
    "                output[0][row][i] = output[0][row][i] + temp\n",
    "    print(output)\n",
    "    output = np.zeros((1, test_rows, test_cols), dtype = np.float16)\n",
    "    for row in range(test_rows):\n",
    "        for i in range(test_cols):\n",
    "            for r in range(x_shape):\n",
    "                temp = Input_np[0][row][r] * np.float16((W_w_np[r // 8][i] >> ((r % 8) * 4) & (15)) - np.float16(7.0)) * W_s_np[r // 32][i]\n",
    "                temp_output = output[0][row][i]\n",
    "                output[0][row][i] = temp_output + temp\n",
    "                # print(f\"{temp_output} + {temp} = {output[0][0][i]}\")\n",
    "    print(output)\n",
    "numpy_caculate()\n",
    "def print_npdata(np_data: np.ndarray) :\n",
    "    print(np_data)\n",
    "    print_num = 20\n",
    "    d = np_data.flatten()\n",
    "    p_size = print_num if d.size > print_num else d.size\n",
    "    print(d[:p_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual_evaluator GEMV-Blocking: 1.806445 GFLOPS\n",
      "[-6620. -7144. -7440. -6144. -5704. -6984. -6740. -6792. -5724. -6868.]\n"
     ]
    }
   ],
   "source": [
    "# cuda未优化版本测试\n",
    "sch = tvm.tir.Schedule(ModuleSrc)\n",
    "with target:\n",
    "    src_gpu_mod = tvm.tir.transform.DefaultGPUSchedule()(sch.mod) ##\n",
    "rt_mod = tvm.build(src_gpu_mod, target=\"cuda\")\n",
    "W_w_nd = tvm.nd.array(W_w_np, dev)\n",
    "W_s_nd = tvm.nd.array(W_s_np, dev)\n",
    "Input_nd = tvm.nd.array(Input_np, dev)\n",
    "Output_nd = tvm.nd.array(np.zeros((1, seq_len, w_y), dtype=\"float16\"), dev)\n",
    "evaluator = rt_mod.time_evaluator(\"main\", dev, number=100)\n",
    "print(\"manual_evaluator GEMV-Blocking: %f GFLOPS\" % (num_flop / evaluator(W_w_nd, W_s_nd, Input_nd, Output_nd).mean / 1e9))\n",
    "# print(Output_nd.numpy())\n",
    "print_npdata(Output_nd.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TVM_NDK_CC\"]=\"/home/sensetime/Android/Sdk/ndk/25.2.9519653/toolchains/llvm/prebuilt/linux-x86_64/bin/aarch64-linux-android33-clang++\"\n",
    "target = tvm.target.Target(\"opencl -device=adreno\", host=\"llvm -mtriple=aarch64-linux-gnu\")\n",
    "device_key=\"android\"\n",
    "rpc_host = \"10.4.236.32\"\n",
    "rpc_port = 9190\n",
    "comp_target = tvm.target.Target(\"opencl\", host=\"llvm -mtriple=aarch64-linux-android\")  # TODO: Only support arm64 for now\n",
    "\n",
    "def test_opencl(mod: tvm.IRModule, name_hint: str):\n",
    "    # mod = tvm.lower(sch_manual.mod)\n",
    "    print(\"Build ...\")\n",
    "    android_rt_mod = tvm.build(mod, target=\"opencl\", target_host=\"llvm -mtriple=aarch64-linux-android\")\n",
    "    # print(android_rt_mod.imported_modules[0].get_source())\n",
    "    temp = utils.tempdir()\n",
    "    path_dso_cl = temp.relpath(\"dev_lib_cl.so\")\n",
    "    android_rt_mod.export_library(path_dso_cl, ndk.create_shared)\n",
    "\n",
    "    print(\"Run GPU(OpenCL Flavor) test ...\")\n",
    "    # Establish remote connection with target hardware\n",
    "\n",
    "    tracker = rpc.connect_tracker(rpc_host, rpc_port)\n",
    "    remote = tracker.request(device_key, priority=0, session_timeout=60)\n",
    "    print(\"Connect to device done.\")\n",
    "    dev = remote.cl(0)\n",
    "    remote.upload(path_dso_cl)\n",
    "    f1 = remote.load_module(\"dev_lib_cl.so\")\n",
    "\n",
    "    W_w_nd = tvm.nd.array(W_w_np, dev)\n",
    "    W_s_nd = tvm.nd.array(W_s_np, dev)\n",
    "    Input_nd = tvm.nd.array(Input_np, dev)\n",
    "    Output_nd = tvm.nd.array(np.zeros((1, seq_len, w_y), dtype=\"float16\"), dev)\n",
    "    test_number=32\n",
    "    time_f = f1.time_evaluator(f1.entry_name, dev, number=test_number)\n",
    "    cost = time_f(W_w_nd, W_s_nd, Input_nd, Output_nd).mean\n",
    "    print(\"evaluator[%s] GEMV-Blocking: %fms with loop %d\" % (name_hint, cost * 1000, test_number))\n",
    "    print(\"evaluator[%s] GEMV-Blocking: %fGFLOPS\" % (name_hint, num_flop / cost / 1e9))\n",
    "    print_npdata(Output_nd.numpy())\n",
    "    # return Output_nd.numpy()\n",
    "    return cost*1000 # unit: ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[source] GEMV-Blocking: 211.527736ms with loop 32\n",
      "evaluator[source] GEMV-Blocking: 5.807308GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n"
     ]
    }
   ],
   "source": [
    "# 未优化版本opencl测试\n",
    "from tvm import dlight as dl\n",
    "sch = tvm.tir.Schedule(ModuleSrc)\n",
    "with target:\n",
    "    # src_gpu_mod = tvm.tir.transform.DefaultGPUSchedule()(sch.mod) ##\n",
    "    mod_deploy = dl.ApplyDefaultSchedule(  # pylint: disable=not-callable\n",
    "        dl.gpu.Matmul(),\n",
    "        dl.gpu.GEMV(),\n",
    "        dl.gpu.Reduction(),\n",
    "        dl.gpu.GeneralReduction(),\n",
    "        dl.gpu.Fallback(),\n",
    "    )(sch.mod)\n",
    "src_output = test_opencl(mod_deploy, \"source\")\n",
    "# print_npdata(src_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[opted] GEMV-Blocking: 115.591552ms with loop 32\n",
      "evaluator[opted] GEMV-Blocking: 10.627133GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n"
     ]
    }
   ],
   "source": [
    "#优化版本opencl测试\n",
    "# print(sch_manual.mod)\n",
    "opt_output = test_opencl(sch_manual.mod, \"opted\")\n",
    "# print_npdata(opt_output)\n",
    "np.testing.assert_equal(opt_output, src_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tasks: 150\n",
      "[8, 4, 2]\n",
      "search record [1/150]: start run 8 16 3 512 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 110.021752ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 11.165127GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [2/150]: start run 8 16 4 384 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 85.087872ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 14.436920GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [3/150]: start run 8 16 6 256 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 60.528880ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 20.294557GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [4/150]: start run 8 16 8 192 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 44.203992ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 27.789499GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [5/150]: start run 8 16 12 128 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 29.763640ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 41.272062GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [6/150]: start run 8 16 16 96 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 52.054816ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 23.598331GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [7/150]: start run 8 16 24 64 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 47.742856ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 25.729646GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [8/150]: start run 8 16 32 48 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 72.641008ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 16.910652GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [9/150]: start run 8 16 48 32 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 95.408624ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 12.875217GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [10/150]: start run 8 16 96 16 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 162.684688ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 7.550845GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [11/150]: skip 8 8 3 512 4\n",
      "search record [12/150]: skip 8 8 4 384 4\n",
      "search record [13/150]: start run 8 8 6 256 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 51.094816ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 24.041711GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [14/150]: start run 8 8 8 192 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 40.454080ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 30.365461GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [15/150]: start run 8 8 12 128 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 26.427904ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 46.481431GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [16/150]: start run 8 8 16 96 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 41.150280ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 29.851724GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [17/150]: start run 8 8 24 64 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 26.375080ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 46.574524GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [18/150]: start run 8 8 32 48 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 38.893728ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 31.583673GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [19/150]: start run 8 8 48 32 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 37.421784ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 32.825981GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [20/150]: start run 8 8 96 16 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 62.454912ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 19.668698GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [21/150]: skip 8 4 3 512 8\n",
      "search record [22/150]: skip 8 4 4 384 8\n",
      "search record [23/150]: skip 8 4 6 256 8\n",
      "search record [24/150]: skip 8 4 8 192 8\n",
      "search record [25/150]: start run 8 4 12 128 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 8.530512ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 144.001531GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [26/150]: start run 8 4 16 96 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 11.551216ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 106.344370GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [27/150]: start run 8 4 24 64 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 8.602088ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 142.803327GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [28/150]: start run 8 4 32 48 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 9.454952ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 129.922054GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [29/150]: start run 8 4 48 32 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 8.909304ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 137.879096GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [30/150]: start run 8 4 96 16 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 10.154048ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 120.977051GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [31/150]: skip 8 2 3 512 16\n",
      "search record [32/150]: skip 8 2 4 384 16\n",
      "search record [33/150]: skip 8 2 6 256 16\n",
      "search record [34/150]: skip 8 2 8 192 16\n",
      "search record [35/150]: skip 8 2 12 128 16\n",
      "search record [36/150]: skip 8 2 16 96 16\n",
      "search record [37/150]: start run 8 2 24 64 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 7.184712ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 170.975090GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [38/150]: start run 8 2 32 48 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 8.489912ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 144.690167GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [39/150]: start run 8 2 48 32 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 7.348896ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 167.155282GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [40/150]: start run 8 2 96 16 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 8.246712ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 148.957158GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [41/150]: skip 8 1 3 512 32\n",
      "search record [42/150]: skip 8 1 4 384 32\n",
      "search record [43/150]: skip 8 1 6 256 32\n",
      "search record [44/150]: skip 8 1 8 192 32\n",
      "search record [45/150]: skip 8 1 12 128 32\n",
      "search record [46/150]: skip 8 1 16 96 32\n",
      "search record [47/150]: skip 8 1 24 64 32\n",
      "search record [48/150]: skip 8 1 32 48 32\n",
      "search record [49/150]: start run 8 1 48 32 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 10.274512ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 119.558650GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [50/150]: start run 8 1 96 16 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 10.482144ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 117.190413GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [51/150]: start run 4 16 6 512 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 194.415296ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 6.318468GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [52/150]: start run 4 16 8 384 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 147.288520ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 8.340139GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [53/150]: start run 4 16 12 256 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 104.543376ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 11.750212GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [54/150]: start run 4 16 16 192 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 158.411200ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 7.754545GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [55/150]: start run 4 16 24 128 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 115.566080ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 10.629475GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [56/150]: start run 4 16 32 96 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 172.043520ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 7.140093GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [57/150]: start run 4 16 48 64 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 165.076656ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 7.441432GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [58/150]: start run 4 16 64 48 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 244.084416ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 5.032713GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [59/150]: start run 4 16 96 32 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 329.834920ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 3.724308GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [60/150]: start run 4 16 192 16 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 604.318608ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 2.032714GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [61/150]: skip 4 8 6 512 4\n",
      "search record [62/150]: skip 4 8 8 384 4\n",
      "search record [63/150]: start run 4 8 12 256 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 8.391288ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 146.390731GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [64/150]: start run 4 8 16 192 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 11.504952ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 106.772004GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [65/150]: start run 4 8 24 128 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 8.350488ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 147.105988GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [66/150]: start run 4 8 32 96 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 9.023528ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 136.133759GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [67/150]: start run 4 8 48 64 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 8.318152ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 147.677848GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [68/150]: start run 4 8 64 48 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 8.998848ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 136.507116GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [69/150]: start run 4 8 96 32 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 8.452680ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 145.327492GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [70/150]: start run 4 8 192 16 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 9.394544ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 130.757468GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [71/150]: skip 4 4 6 512 8\n",
      "search record [72/150]: skip 4 4 8 384 8\n",
      "search record [73/150]: skip 4 4 12 256 8\n",
      "search record [74/150]: skip 4 4 16 192 8\n",
      "search record [75/150]: start run 4 4 24 128 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 7.232272ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 169.850745GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [76/150]: start run 4 4 32 96 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 8.313432ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 147.761693GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [77/150]: start run 4 4 48 64 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 7.165184ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 171.441066GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [78/150]: start run 4 4 64 48 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 8.450808ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 145.359684GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [79/150]: start run 4 4 96 32 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 7.400880ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 165.981178GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [80/150]: start run 4 4 192 16 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 8.912248ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 137.833550GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [81/150]: skip 4 2 6 512 16\n",
      "search record [82/150]: skip 4 2 8 384 16\n",
      "search record [83/150]: skip 4 2 12 256 16\n",
      "search record [84/150]: skip 4 2 16 192 16\n",
      "search record [85/150]: skip 4 2 24 128 16\n",
      "search record [86/150]: skip 4 2 32 96 16\n",
      "search record [87/150]: start run 4 2 48 64 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 8.465000ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 145.115982GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [88/150]: start run 4 2 64 48 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 9.445848ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 130.047274GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [89/150]: start run 4 2 96 32 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 8.667264ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 141.729476GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [90/150]: start run 4 2 192 16 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 10.405672ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 118.051653GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [91/150]: skip 4 1 6 512 32\n",
      "search record [92/150]: skip 4 1 8 384 32\n",
      "search record [93/150]: skip 4 1 12 256 32\n",
      "search record [94/150]: skip 4 1 16 192 32\n",
      "search record [95/150]: skip 4 1 24 128 32\n",
      "search record [96/150]: skip 4 1 32 96 32\n",
      "search record [97/150]: skip 4 1 48 64 32\n",
      "search record [98/150]: skip 4 1 64 48 32\n",
      "search record [99/150]: start run 4 1 96 32 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 12.769552ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 96.198111GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [100/150]: start run 4 1 192 16 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 13.136256ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 93.512701GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [101/150]: start run 2 16 12 512 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 106.232216ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 11.563411GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [102/150]: start run 2 16 16 384 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 162.431656ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 7.562607GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [103/150]: start run 2 16 24 256 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 114.180592ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 10.758455GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [104/150]: start run 2 16 32 192 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 129.307376ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 9.499897GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [105/150]: start run 2 16 48 128 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 115.020120ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 10.679930GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [106/150]: start run 2 16 64 96 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 144.174624ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 8.520270GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [107/150]: start run 2 16 96 64 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 183.615584ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 6.690101GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [108/150]: start run 2 16 128 48 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 240.631632ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 5.104926GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [109/150]: start run 2 16 192 32 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 345.306392ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 3.557440GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [110/150]: start run 2 16 384 16 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 577.757848ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 2.126162GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [111/150]: skip 2 8 12 512 4\n",
      "search record [112/150]: skip 2 8 16 384 4\n",
      "search record [113/150]: start run 2 8 24 256 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 13.314504ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 92.260800GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [114/150]: start run 2 8 32 192 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 14.861936ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 82.654560GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [115/150]: start run 2 8 48 128 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 13.309256ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 92.297179GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [116/150]: start run 2 8 64 96 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 14.856032ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 82.687408GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [117/150]: start run 2 8 96 64 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 13.305120ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 92.325870GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [118/150]: start run 2 8 128 48 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 13.930912ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 88.178490GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [119/150]: start run 2 8 192 32 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 13.613632ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 90.233582GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [120/150]: start run 2 8 384 16 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 17.185032ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 71.481204GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [121/150]: skip 2 4 12 512 8\n",
      "search record [122/150]: skip 2 4 16 384 8\n",
      "search record [123/150]: skip 2 4 24 256 8\n",
      "search record [124/150]: skip 2 4 32 192 8\n",
      "search record [125/150]: start run 2 4 48 128 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 12.996560ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 94.517840GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [126/150]: start run 2 4 64 96 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 14.584176ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 84.228741GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [127/150]: start run 2 4 96 64 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 12.972456ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 94.693463GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [128/150]: start run 2 4 128 48 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 13.379840ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 91.810275GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [129/150]: start run 2 4 192 32 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 12.977088ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 94.659664GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [130/150]: start run 2 4 384 16 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 15.842232ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 77.540007GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [131/150]: skip 2 2 12 512 16\n",
      "search record [132/150]: skip 2 2 16 384 16\n",
      "search record [133/150]: skip 2 2 24 256 16\n",
      "search record [134/150]: skip 2 2 32 192 16\n",
      "search record [135/150]: skip 2 2 48 128 16\n",
      "search record [136/150]: skip 2 2 64 96 16\n",
      "search record [137/150]: start run 2 2 96 64 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 13.725480ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 89.498275GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [138/150]: start run 2 2 128 48 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 14.054008ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 87.406154GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [139/150]: start run 2 2 192 32 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 13.816400ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 88.909324GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [140/150]: start run 2 2 384 16 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 16.884952ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 72.751571GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [141/150]: skip 2 1 12 512 32\n",
      "search record [142/150]: skip 2 1 16 384 32\n",
      "search record [143/150]: skip 2 1 24 256 32\n",
      "search record [144/150]: skip 2 1 32 192 32\n",
      "search record [145/150]: skip 2 1 48 128 32\n",
      "search record [146/150]: skip 2 1 64 96 32\n",
      "search record [147/150]: skip 2 1 96 64 32\n",
      "search record [148/150]: skip 2 1 128 48 32\n",
      "search record [149/150]: start run 2 1 192 32 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 14.805736ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 82.968303GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "search record [150/150]: start run 2 1 384 16 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 15.709424ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 78.195533GFLOPS\n",
      "[[[-6756. -5420. -6856. ... -7424. -6828. -6592.]\n",
      "  [-6488. -5436. -6748. ... -7292. -6852. -6416.]\n",
      "  [-6684. -5436. -6724. ... -7256. -6856. -6576.]\n",
      "  ...\n",
      "  [-6700. -5428. -6776. ... -7340. -6980. -6664.]\n",
      "  [-6684. -5560. -6804. ... -7532. -7100. -6668.]\n",
      "  [-6812. -5488. -6828. ... -7572. -6888. -6540.]]]\n",
      "[-6756. -5420. -6856. -6464. -6528. -6744. -6688. -6516. -6676. -6472.\n",
      " -6040. -7108. -6156. -6668. -6668. -7044. -6000. -6464. -6640. -6648.]\n",
      "=====\n",
      "================================\n",
      "+------------------+---------------------------+------------+-------------+-------------+--------------------+\n",
      "| vectorize_factor | processed_rows_per_thread | blockIdx.x | threadIdx.x | threadIdx.y |      cost(ms)      |\n",
      "+------------------+---------------------------+------------+-------------+-------------+--------------------+\n",
      "|        8         |             16            |     3      |     512     |      2      |     110.021752     |\n",
      "|        8         |             16            |     4      |     384     |      2      |     85.087872      |\n",
      "|        8         |             16            |     6      |     256     |      2      |      60.52888      |\n",
      "|        8         |             16            |     8      |     192     |      2      |     44.203992      |\n",
      "|        8         |             16            |     12     |     128     |      2      |      29.76364      |\n",
      "|        8         |             16            |     16     |      96     |      2      |     52.054816      |\n",
      "|        8         |             16            |     24     |      64     |      2      |     47.742856      |\n",
      "|        8         |             16            |     32     |      48     |      2      |     72.641008      |\n",
      "|        8         |             16            |     48     |      32     |      2      |     95.408624      |\n",
      "|        8         |             16            |     96     |      16     |      2      |     162.684688     |\n",
      "|        8         |             8             |     6      |     256     |      4      |     51.094816      |\n",
      "|        8         |             8             |     8      |     192     |      4      |      40.45408      |\n",
      "|        8         |             8             |     12     |     128     |      4      |     26.427904      |\n",
      "|        8         |             8             |     16     |      96     |      4      |      41.15028      |\n",
      "|        8         |             8             |     24     |      64     |      4      |      26.37508      |\n",
      "|        8         |             8             |     32     |      48     |      4      |     38.893728      |\n",
      "|        8         |             8             |     48     |      32     |      4      |     37.421784      |\n",
      "|        8         |             8             |     96     |      16     |      4      |     62.454912      |\n",
      "|        8         |             4             |     12     |     128     |      8      |      8.530512      |\n",
      "|        8         |             4             |     16     |      96     |      8      |     11.551216      |\n",
      "|        8         |             4             |     24     |      64     |      8      |      8.602088      |\n",
      "|        8         |             4             |     32     |      48     |      8      |      9.454952      |\n",
      "|        8         |             4             |     48     |      32     |      8      |      8.909304      |\n",
      "|        8         |             4             |     96     |      16     |      8      |     10.154048      |\n",
      "|        8         |             2             |     24     |      64     |      16     |      7.184712      |\n",
      "|        8         |             2             |     32     |      48     |      16     |      8.489912      |\n",
      "|        8         |             2             |     48     |      32     |      16     |      7.348896      |\n",
      "|        8         |             2             |     96     |      16     |      16     |      8.246712      |\n",
      "|        8         |             1             |     48     |      32     |      32     |     10.274512      |\n",
      "|        8         |             1             |     96     |      16     |      32     |     10.482144      |\n",
      "|        4         |             16            |     6      |     512     |      2      |     194.415296     |\n",
      "|        4         |             16            |     8      |     384     |      2      |     147.28852      |\n",
      "|        4         |             16            |     12     |     256     |      2      |     104.543376     |\n",
      "|        4         |             16            |     16     |     192     |      2      |      158.4112      |\n",
      "|        4         |             16            |     24     |     128     |      2      |     115.56608      |\n",
      "|        4         |             16            |     32     |      96     |      2      |     172.04352      |\n",
      "|        4         |             16            |     48     |      64     |      2      |     165.076656     |\n",
      "|        4         |             16            |     64     |      48     |      2      |     244.084416     |\n",
      "|        4         |             16            |     96     |      32     |      2      |     329.83492      |\n",
      "|        4         |             16            |    192     |      16     |      2      |     604.318608     |\n",
      "|        4         |             8             |     12     |     256     |      4      |      8.391288      |\n",
      "|        4         |             8             |     16     |     192     |      4      |     11.504952      |\n",
      "|        4         |             8             |     24     |     128     |      4      |      8.350488      |\n",
      "|        4         |             8             |     32     |      96     |      4      |      9.023528      |\n",
      "|        4         |             8             |     48     |      64     |      4      |      8.318152      |\n",
      "|        4         |             8             |     64     |      48     |      4      |      8.998848      |\n",
      "|        4         |             8             |     96     |      32     |      4      |      8.45268       |\n",
      "|        4         |             8             |    192     |      16     |      4      |      9.394544      |\n",
      "|        4         |             4             |     24     |     128     |      8      |      7.232272      |\n",
      "|        4         |             4             |     32     |      96     |      8      |      8.313432      |\n",
      "|        4         |             4             |     48     |      64     |      8      |      7.165184      |\n",
      "|        4         |             4             |     64     |      48     |      8      |      8.450808      |\n",
      "|        4         |             4             |     96     |      32     |      8      |      7.40088       |\n",
      "|        4         |             4             |    192     |      16     |      8      |      8.912248      |\n",
      "|        4         |             2             |     48     |      64     |      16     |       8.465        |\n",
      "|        4         |             2             |     64     |      48     |      16     |      9.445848      |\n",
      "|        4         |             2             |     96     |      32     |      16     |      8.667264      |\n",
      "|        4         |             2             |    192     |      16     |      16     |     10.405672      |\n",
      "|        4         |             1             |     96     |      32     |      32     |     12.769552      |\n",
      "|        4         |             1             |    192     |      16     |      32     |     13.136256      |\n",
      "|        2         |             16            |     12     |     512     |      2      |     106.232216     |\n",
      "|        2         |             16            |     16     |     384     |      2      |     162.431656     |\n",
      "|        2         |             16            |     24     |     256     |      2      |     114.180592     |\n",
      "|        2         |             16            |     32     |     192     |      2      |     129.307376     |\n",
      "|        2         |             16            |     48     |     128     |      2      |     115.02012      |\n",
      "|        2         |             16            |     64     |      96     |      2      |     144.174624     |\n",
      "|        2         |             16            |     96     |      64     |      2      |     183.615584     |\n",
      "|        2         |             16            |    128     |      48     |      2      |     240.631632     |\n",
      "|        2         |             16            |    192     |      32     |      2      |     345.306392     |\n",
      "|        2         |             16            |    384     |      16     |      2      |     577.757848     |\n",
      "|        2         |             8             |     24     |     256     |      4      |     13.314504      |\n",
      "|        2         |             8             |     32     |     192     |      4      |     14.861936      |\n",
      "|        2         |             8             |     48     |     128     |      4      |     13.309256      |\n",
      "|        2         |             8             |     64     |      96     |      4      |     14.856032      |\n",
      "|        2         |             8             |     96     |      64     |      4      |      13.30512      |\n",
      "|        2         |             8             |    128     |      48     |      4      |     13.930912      |\n",
      "|        2         |             8             |    192     |      32     |      4      |     13.613632      |\n",
      "|        2         |             8             |    384     |      16     |      4      |     17.185032      |\n",
      "|        2         |             4             |     48     |     128     |      8      |      12.99656      |\n",
      "|        2         |             4             |     64     |      96     |      8      |     14.584176      |\n",
      "|        2         |             4             |     96     |      64     |      8      |     12.972456      |\n",
      "|        2         |             4             |    128     |      48     |      8      |      13.37984      |\n",
      "|        2         |             4             |    192     |      32     |      8      |     12.977088      |\n",
      "|        2         |             4             |    384     |      16     |      8      | 15.842231999999997 |\n",
      "|        2         |             2             |     96     |      64     |      16     |      13.72548      |\n",
      "|        2         |             2             |    128     |      48     |      16     |     14.054008      |\n",
      "|        2         |             2             |    192     |      32     |      16     |      13.8164       |\n",
      "|        2         |             2             |    384     |      16     |      16     |     16.884952      |\n",
      "|        2         |             1             |    192     |      32     |      32     |     14.805736      |\n",
      "|        2         |             1             |    384     |      16     |      32     |     15.709424      |\n",
      "+------------------+---------------------------+------------+-------------+-------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# 自动搜索\n",
    "# 以32为倍数先搜一波\n",
    "# @TODO: 探索更低的倍数，以降低padding的额外性能损耗\n",
    "def auto_tune(record_file: str):\n",
    "    from typing import Union\n",
    "    def search(vf: int, pr: int, bx: int, tx: int, ty: int):\n",
    "        \"\"\"search by workgroup\n",
    "\n",
    "        Args:\n",
    "            blockIdxX (_type_): blockIdx.x\n",
    "            threadIdxX (_type_): threadIdx.x\n",
    "            vectorize_output (_type_): 输出的vectorize参数, 决定单线程输出多少个结果\n",
    "            vectorize_input (list, optional): 输入X拷贝到shared_memory时的vectorize参数, 一般为4或8\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        @I.ir_module\n",
    "        class ModuleToManual:\n",
    "            @T.prim_func(private=False)\n",
    "            # fused_decode_NT_matmul_after\n",
    "            def main(\n",
    "                lv8: T.Buffer((512, w_y), \"uint32\"),\n",
    "                lv9: T.Buffer((128, w_y), \"float16\"),\n",
    "                p_lv6: T.handle,\n",
    "                p_output0: T.handle,\n",
    "            ):\n",
    "                T.func_attr({\"tir.noalias\": T.bool(True), \"tir.is_scheduled\": 1})\n",
    "                n = T.int32()\n",
    "                #输入hidden states\n",
    "                lv6 = T.match_buffer(p_lv6, (1, n, 4096), \"float16\")\n",
    "                # 输出 [1, n, 12288]\n",
    "                var_NT_matmul_intermediate = T.match_buffer(p_output0, (1, n, w_y), \"float16\")\n",
    "                # with T.block(\"root\"):\n",
    "                # 解码后的shape不变\n",
    "                decode_local = T.alloc_buffer((4096, 4096), \"float16\", scope=\"local\")\n",
    "                lv8_local = T.alloc_buffer((512, w_y), \"uint32\", scope=\"local\")\n",
    "                lv9_local = T.alloc_buffer((128, w_y), \"float16\", scope=\"local\")\n",
    "                # 输入, padding一下n 到32的倍数\n",
    "                lv6_pad_local = T.alloc_buffer(\n",
    "                    (1, (n + 31) // 32 * 32, 4096), \"float16\", scope=\"local\"\n",
    "                )\n",
    "                # 输出中间结果, padding到32的倍数\n",
    "                var_NT_matmul_intermediate_pad_local = T.alloc_buffer(\n",
    "                    (1, (n + 31) // 32 * 32, w_y), \"float16\", scope=\"local\"\n",
    "                )\n",
    "\n",
    "                # 任务划分:\n",
    "                ### 一个thread处理 `processed_rows_per_thread`行 `vectorize_factor` 列(输出角度)\n",
    "                ### 完整处理 `processed_rows_per_thread` 行输入需要: blockIdx.x * threadIdx.x 配合\n",
    "                ### 完整处理 `n` 行输入需要: blockIdx.y * threadIdx.y 配合\n",
    "                #### 分析: 根据`n`变化的只有 blockIdx.y, 说明 blockIdx.x * threadIdx.x * threadIdx.y 可以完整处理32行输入\n",
    "                BlockIdx_x = bx#32\n",
    "                # n = 32\n",
    "                # BlockIdx_y = (n+31)//32 * 32 # 这里32是假设输入为32的倍数, //32的32 = thready * \n",
    "                ThreadIdx_x = tx#16 * 3\n",
    "                ThreadIdx_y = ty#8\n",
    "                vectorize_factor = vf#8\n",
    "                # processed_columns_per_thread = vectorize_factor# w_y / (BlockIdx_x * ThreadIdx_x) == vectorize_factor\n",
    "                processed_rows_per_thread = pr#4\n",
    "\n",
    "                ## BlockIdx.y == [BlockIdx.x, ThreadIdx.x, ThraedIdx.y] 解决 seq_length为32的处理\n",
    "                for i0_i1_fused_0_i0_i1_fused_1_0_fused in T.thread_binding(\n",
    "                    (n + 31) // 32, thread=\"blockIdx.y\"\n",
    "                ):\n",
    "                    # 32的倍数, block负责完成n/processed_rows_per_thread的处理, thread负责完成 processed_rows_per_thread/n的处理\n",
    "                    for i2_0 in T.thread_binding(BlockIdx_x, thread=\"blockIdx.x\"):\n",
    "                        # threadIdx.X * threadIdx.y 是线程数，每个线程处理 4*8个元素的和\n",
    "                        for i0_i1_fused_1_1 in T.thread_binding(ThreadIdx_y, thread=\"threadIdx.y\"):\n",
    "                            for i2_1 in T.thread_binding(ThreadIdx_x, thread=\"threadIdx.x\"):\n",
    "                                for i0_i1_fused_1_2_init in range(processed_rows_per_thread):\n",
    "                                    for i2_2_init in T.vectorized(vectorize_factor):\n",
    "                                        with T.block(\"NT_matmul_init\"):\n",
    "                                            v_i0 = T.axis.spatial(1, 0)\n",
    "                                            v_i1 = T.axis.spatial(\n",
    "                                                (n + 31) // 32 * 32,\n",
    "                                                i0_i1_fused_0_i0_i1_fused_1_0_fused * 32\n",
    "                                                + i0_i1_fused_1_1 * processed_rows_per_thread\n",
    "                                                + i0_i1_fused_1_2_init,\n",
    "                                            )\n",
    "                                            v_i2 = T.axis.spatial(\n",
    "                                                w_y, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + i2_2_init\n",
    "                                            )\n",
    "                                            T.reads()\n",
    "                                            T.writes(\n",
    "                                                var_NT_matmul_intermediate_pad_local[\n",
    "                                                    v_i0, v_i1, v_i2\n",
    "                                                ]\n",
    "                                            )\n",
    "                                            var_NT_matmul_intermediate_pad_local[\n",
    "                                                v_i0, v_i1, v_i2\n",
    "                                            ] = T.float16(0)\n",
    "                                for k_0 in range(128):\n",
    "                                    for ax0 in range(1):\n",
    "                                        for ax1 in T.vectorized(vectorize_factor):\n",
    "                                            with T.block(\"lv9_local\"):\n",
    "                                                v0 = T.axis.spatial(128, k_0 + ax0)\n",
    "                                                v1 = T.axis.spatial(\n",
    "                                                    w_y, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + ax1\n",
    "                                                )\n",
    "                                                T.reads(lv9[v0, v1])\n",
    "                                                T.writes(lv9_local[v0, v1])\n",
    "                                                lv9_local[v0, v1] = lv9[v0, v1]\n",
    "                                    for k_1 in range(4):\n",
    "                                        for ax0 in range(1):\n",
    "                                            for ax1 in T.vectorized(vectorize_factor):\n",
    "                                                with T.block(\"lv8_local\"):\n",
    "                                                    v0 = T.axis.spatial(512, k_0 * 4 + k_1 + ax0)\n",
    "                                                    v1 = T.axis.spatial(\n",
    "                                                        w_y, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + ax1\n",
    "                                                    )\n",
    "                                                    T.reads(lv8[v0, v1])\n",
    "                                                    T.writes(lv8_local[v0, v1])\n",
    "                                                    lv8_local[v0, v1] = lv8[v0, v1]\n",
    "                                        for k_2 in range(8):\n",
    "                                            for ax0 in range(1):\n",
    "                                                for ax1 in T.vectorized(vectorize_factor):\n",
    "                                                    with T.block(\"decode\"):\n",
    "                                                        v_i = T.axis.spatial(\n",
    "                                                            4096, k_0 * 32 + k_1 * 8 + k_2 + ax0\n",
    "                                                        )\n",
    "                                                        v_j = T.axis.spatial(\n",
    "                                                            w_y, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + ax1\n",
    "                                                        )\n",
    "                                                        T.reads(\n",
    "                                                            lv8_local[v_i // 8, v_j],\n",
    "                                                            lv9_local[v_i // 32, v_j],\n",
    "                                                        )\n",
    "                                                        T.writes(decode_local[v_i, v_j])\n",
    "                                                        decode_local[v_i, v_j] = (\n",
    "                                                            T.Cast(\n",
    "                                                                \"float16\",\n",
    "                                                                T.bitwise_and(\n",
    "                                                                    T.shift_right(\n",
    "                                                                        lv8_local[v_i // 8, v_j],\n",
    "                                                                        T.Cast(\"uint32\", v_i % 8)\n",
    "                                                                        * T.uint32(4),\n",
    "                                                                    ),\n",
    "                                                                    T.uint32(15),\n",
    "                                                                ),\n",
    "                                                            )\n",
    "                                                            - T.float16(7)\n",
    "                                                        ) * lv9_local[v_i // 32, v_j]\n",
    "                                            for ax0, ax1 in T.grid(1, processed_rows_per_thread):\n",
    "                                                for ax2 in T.vectorized(1):\n",
    "                                                    with T.block(\"lv6_pad_local\"):\n",
    "                                                        v0 = T.axis.spatial(1, ax0)\n",
    "                                                        v1 = T.axis.spatial(\n",
    "                                                            (n + 31) // 32 * 32,\n",
    "                                                            i0_i1_fused_0_i0_i1_fused_1_0_fused * 32\n",
    "                                                            + i0_i1_fused_1_1 * processed_rows_per_thread\n",
    "                                                            + ax1,\n",
    "                                                        )\n",
    "                                                        v2 = T.axis.spatial(\n",
    "                                                            4096, k_0 * 32 + k_1 * 8 + k_2 + ax2\n",
    "                                                        )\n",
    "                                                        T.reads(lv6[v0, v1, v2])\n",
    "                                                        T.writes(lv6_pad_local[v0, v1, v2])\n",
    "                                                        lv6_pad_local[v0, v1, v2] = T.if_then_else(\n",
    "                                                            v1 < n, lv6[v0, v1, v2], T.float16(0)\n",
    "                                                        )\n",
    "                                            for i0_i1_fused_1_2 in range(processed_rows_per_thread):\n",
    "                                                for i2_2 in T.vectorized(vectorize_factor):\n",
    "                                                    with T.block(\"NT_matmul_update\"):\n",
    "                                                        v_i0 = T.axis.spatial(1, 0)\n",
    "                                                        v_i1 = T.axis.spatial(\n",
    "                                                            (n + 31) // 32 * 32,\n",
    "                                                            i0_i1_fused_0_i0_i1_fused_1_0_fused * 32\n",
    "                                                            + i0_i1_fused_1_1 * processed_rows_per_thread\n",
    "                                                            + i0_i1_fused_1_2,\n",
    "                                                        )\n",
    "                                                        v_i2 = T.axis.spatial(\n",
    "                                                            w_y, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * vectorize_factor + i2_2\n",
    "                                                        )\n",
    "                                                        v_k = T.axis.reduce(\n",
    "                                                            4096, k_0 * 32 + k_1 * 8 + k_2\n",
    "                                                        )\n",
    "                                                        T.reads(\n",
    "                                                            var_NT_matmul_intermediate_pad_local[\n",
    "                                                                v_i0, v_i1, v_i2\n",
    "                                                            ],\n",
    "                                                            lv6_pad_local[v_i0, v_i1, v_k],\n",
    "                                                            decode_local[v_k, v_i2],\n",
    "                                                        )\n",
    "                                                        T.writes(\n",
    "                                                            var_NT_matmul_intermediate_pad_local[\n",
    "                                                                v_i0, v_i1, v_i2\n",
    "                                                            ]\n",
    "                                                        )\n",
    "                                                        var_NT_matmul_intermediate_pad_local[\n",
    "                                                            v_i0, v_i1, v_i2\n",
    "                                                        ] = (\n",
    "                                                            var_NT_matmul_intermediate_pad_local[\n",
    "                                                                v_i0, v_i1, v_i2\n",
    "                                                            ]\n",
    "                                                            + lv6_pad_local[v_i0, v_i1, v_k]\n",
    "                                                            * decode_local[v_k, v_i2]\n",
    "                                                        )\n",
    "                                for ax0, ax1 in T.grid(1, processed_rows_per_thread):\n",
    "                                    for ax2 in T.vectorized(vectorize_factor):\n",
    "                                        with T.block(\"var_NT_matmul_intermediate_pad_local\"):\n",
    "                                            v0 = T.axis.spatial(1, ax0)\n",
    "                                            v1 = T.axis.spatial(\n",
    "                                                (n + 31) // 32 * 32,\n",
    "                                                i0_i1_fused_0_i0_i1_fused_1_0_fused * 32\n",
    "                                                + i0_i1_fused_1_1 * processed_rows_per_thread\n",
    "                                                + ax1,\n",
    "                                            )\n",
    "                                            v2 = T.axis.spatial(w_y, i2_0 * (ThreadIdx_x * vectorize_factor) + i2_1 * (vectorize_factor) + ax2)\n",
    "                                            T.reads(\n",
    "                                                var_NT_matmul_intermediate_pad_local[v0, v1, v2]\n",
    "                                            )\n",
    "                                            T.writes(var_NT_matmul_intermediate[v0, v1, v2])\n",
    "                                            if v1 < n:\n",
    "                                                var_NT_matmul_intermediate[\n",
    "                                                    v0, v1, v2\n",
    "                                                ] = var_NT_matmul_intermediate_pad_local[v0, v1, v2]\n",
    "        return tvm.tir.Schedule(ModuleToManual).mod\n",
    "\n",
    "    BlockIdx_x = [None] # 32\n",
    "    # n = 32\n",
    "    # BlockIdx_y = (n+31)//32 * 32 # 这里32是假设输入为32的倍数, //32的32 = thready * \n",
    "    ThreadIdx_x = [16, 32, 48, 64, 96, 128, 192, 256, 384, 512]#16 * 3\n",
    "    # ThreadIdx_y = 8 # = 32 / processed_rows_per_thread\n",
    "    vectorize_factor = [2, 4, 8]# 8\n",
    "    # processed_columns_per_thread = vectorize_factor# w_y / (BlockIdx_x * ThreadIdx_x) == vectorize_factor\n",
    "    processed_rows_per_thread = [1, 2, 4, 8, 16]#4\n",
    "    task_index = 0\n",
    "    total_task_num = len(vectorize_factor)*len(BlockIdx_x)*len(ThreadIdx_x)*len(processed_rows_per_thread)\n",
    "    records = {}\n",
    "    print(f\"Total tasks: {total_task_num}\")\n",
    "    # try:\n",
    "    vectorize_factor_r = vectorize_factor[::-1]\n",
    "    print(vectorize_factor_r)\n",
    "    processed_rows_per_thread_r = processed_rows_per_thread[::-1]\n",
    "    ThreadIdx_x_r = ThreadIdx_x[::-1]\n",
    "    # table\n",
    "    write_interval = 5\n",
    "    from prettytable import PrettyTable\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"vectorize_factor\", \"processed_rows_per_thread\", \"blockIdx.x\", \"threadIdx.x\", \"threadIdx.y\", \"cost(ms)\"]\n",
    "    for vf in vectorize_factor_r:\n",
    "        for pr in processed_rows_per_thread_r:\n",
    "            for tx in ThreadIdx_x_r:\n",
    "                task_index = task_index + 1\n",
    "                import math\n",
    "                bx = math.ceil(w_y /(vf * tx))\n",
    "                ty = math.ceil(32//pr)\n",
    "                if tx * vf >= w_y or tx*ty > 1024 or 32 % pr != 0: # w_y为输出列数, 工作组和vectorize相乘不能大于该数字\n",
    "                    print(f\"search record [{task_index}/{total_task_num}]: skip {vf} {pr} {bx} {tx} {ty}\")\n",
    "                    continue\n",
    "                if w_y % (vf * tx) != 0:\n",
    "                    print(f\"search record [{task_index}/{total_task_num}]: skip because bx isn't divisible {vf} {pr} {bx} {tx} {ty}\")\n",
    "                    continue\n",
    "                print(f\"search record [{task_index}/{total_task_num}]: start run {vf} {pr} {bx} {tx} {ty}\")\n",
    "                # vf: int, pr: int, bx: int, tx: int, ty: int):\n",
    "                mod_deploy = search(vf, pr, bx, tx, ty)\n",
    "                cost = test_opencl(mod_deploy, \"search\")\n",
    "                print(\"=====\")\n",
    "                records[(vf, pr, bx, tx, ty)] = cost\n",
    "                table.add_row([vf, pr, bx, tx, ty, cost])\n",
    "                if task_index % write_interval == 0:\n",
    "                    with open(record_file, 'wt') as f:\n",
    "                        f.write(table.get_csv_string())\n",
    "    # except Exception as e:\n",
    "    #     print(f\"error occured: {e}\")\n",
    "    ### write file\n",
    "    # from prettytable import PrettyTable\n",
    "    # table = PrettyTable()\n",
    "    # table.field_names = [\"vectorize_factor\", \"processed_rows_per_thread\", \"blockIdx.x\", \"threadIdx.x\", \"threadIdx.y\", \"cost(ms)\"]\n",
    "    # for config, cost in records.items():\n",
    "    #     table.add_row([config[0], config[1], config[2], config[3], config[4], cost])\n",
    "    #     print(f\"{config}: {cost}ms\")\n",
    "    print(\"================================\")\n",
    "    print(table)\n",
    "    with open(record_file, 'wt') as f:\n",
    "        f.write(table.get_csv_string())\n",
    "    \n",
    "    # record_sorted = sorted(record.items(), key=lambda x: x[1][0], reverse=True)\n",
    "auto_tune(\"./manual_tune/qkv_fused_n_tune_record_1.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "target = tvm.target.Target(\"opencl -device=adreno\", host=\"llvm -mtriple=aarch64-linux-gnu\")\n",
    "device_key=\"android\"\n",
    "rpc_host = \"10.158.176.30\"\n",
    "rpc_port = 5001\n",
    "# remote = autotvm.measure.request_remote(device_key, \"10.158.176.30\", 5001, timeout=10000)\n",
    "# dev = remote.device(str(target), 0)\n",
    "\n",
    "# num_flop = 1228406784\n",
    "# W_np = np.random.uniform(size=(512, vocab_size)).astype(\"uint32\")\n",
    "# S_np = np.random.uniform(size=(128, vocab_size)).astype(\"float16\")\n",
    "# Input_np = np.random.uniform(size=(1, 1, 4096)).astype(\"float16\")\n",
    "# # Output_np = np.random.uniform(size=(1, 1, 4096)).astype(\"float16\")\n",
    "# W_nd = tvm.nd.array(W_np, dev)\n",
    "# S_nd = tvm.nd.array(S_np, dev)\n",
    "# Input_nd = tvm.nd.array(Input_np, dev)\n",
    "# Output_nd = tvm.nd.array(np.zeros((1, 1, vocab_size), dtype=\"float32\"), dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpc_config = ms.runner.RPCConfig(tracker_host=rpc_host, tracker_port=rpc_port, tracker_key = device_key)\n",
    "runner= ms.runner.RPCRunner(rpc_config)\n",
    "# ms.builder.LocalBuilder()\n",
    "sch = tvm.tir.Schedule(ModuleSrc)\n",
    "database = ms.tune_tir(\n",
    "    mod=ModuleSrc,\n",
    "    target=target,\n",
    "    max_trials_global=64,\n",
    "    num_trials_per_iter=64,\n",
    "    work_dir=\"./tune_first\",\n",
    "    cost_model=\"xgb\",\n",
    "    runner = runner\n",
    ")\n",
    "print(len(database))\n",
    "sch1 = ms.tir_integration.compile_tir(database, sch.mod, target)\n",
    "print(type(sch1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.script import relax as R\n",
    "@I.ir_module\n",
    "class Module:\n",
    "    @R.function\n",
    "    def main(A: R.Tensor((3, 4), dtype=\"float32\"), B: R.Tensor((4, 5), dtype=\"float32\")):\n",
    "        with R.dataflow():\n",
    "            lv: R.Tensor((3, 5), dtype=\"float32\") = R.matmul(A, B)\n",
    "            gv: R.Tensor((3, 5), dtype=\"float32\") = lv\n",
    "            R.output(gv)\n",
    "        return gv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## auto_scheduler test\n",
    "from tvm import auto_scheduler\n",
    "import numpy as np\n",
    "a_np = np.random.rand(3, 4).astype(\"float32\")\n",
    "b_np = np.random.rand(4, 5).astype(\"float32\")\n",
    "a_nd = tvm.runtime.NDArray(a_np)\n",
    "b_nd = tvm.runtime.NDArray(b_np)\n",
    "sch = tvm.tir.Schedule(Module)\n",
    "\n",
    "params = {\"A\": a_np, \"B\": b_np}\n",
    "## 报错，这里只支持relay\n",
    "# tasks = auto_scheduler.extract_tasks(sch.mod, params, target=target)\n",
    "tasks = ms.relax_integration.extract_tasks(sch.mod, target=target, params=params)\n",
    "print(len(tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mod_deploy import Module as ModuleAll\n",
    "params_all = {}\n",
    "tasks_all = auto_scheduler.extract_tasks(ModuleAll, params_all, target=target)\n",
    "print(len(tasks_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "log_file = \"tune.json\"\n",
    "def _detect_local_cuda():\n",
    "    dev = tvm.cuda()\n",
    "    if not dev.exist:\n",
    "        return None\n",
    "    return tvm.target.Target(\n",
    "        {\n",
    "            \"kind\": \"cuda\",\n",
    "            \"max_shared_memory_per_block\": dev.max_shared_memory_per_block,\n",
    "            \"max_threads_per_block\": dev.max_threads_per_block,\n",
    "            \"thread_warp_size\": dev.warp_size,\n",
    "            \"registers_per_block\": 65536,\n",
    "            \"arch\": \"sm_\" + tvm.cuda().compute_version.replace(\".\", \"\"),\n",
    "        }\n",
    "    )\n",
    "# target = tvm.target.Target(\"cuda\", host=\"llvm\")\n",
    "target = _detect_local_cuda()\n",
    "\n",
    "print(target)\n",
    "# 定义计算任务\n",
    "dev = tvm.cuda(0)\n",
    "\n",
    "num_flop = 1228406784\n",
    "W_np = np.random.uniform(size=(512, vocab_size)).astype(\"uint32\")\n",
    "S_np = np.random.uniform(size=(128, vocab_size)).astype(\"float16\")\n",
    "Input_np = np.random.uniform(size=(1, 1, 4096)).astype(\"float16\")\n",
    "# Output_np = np.random.uniform(size=(1, 1, 4096)).astype(\"float16\")\n",
    "W_nd = tvm.nd.array(W_np, dev)\n",
    "S_nd = tvm.nd.array(S_np, dev)\n",
    "Input_nd = tvm.nd.array(Input_np, dev)\n",
    "Output_nd = tvm.nd.array(np.zeros((1, 1, vocab_size), dtype=\"float32\"), dev)\n",
    "sch = tvm.tir.Schedule(ModuleSrc)\n",
    "new_mod = sch.mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = auto_scheduler.SearchTask(func=sch.mod['fused_fused_decode11_fused_matmul5_cast2'], args=sch.mod['fused_fused_decode11_fused_matmul5_cast2'].params, target=target)\n",
    "\n",
    "# tune_option = auto_scheduler.TuningOptions(\n",
    "#     num_measure_trials=10,\n",
    "#     measure_callbacks=[auto_scheduler.RecordToFile(log_file)],\n",
    "#     verbose=2,\n",
    "# )\n",
    "\n",
    "\n",
    "database = ms.tune_tir(\n",
    "    mod=new_mod,\n",
    "    target=target,\n",
    "    max_trials_global=64,\n",
    "    num_trials_per_iter=64,\n",
    "    work_dir=\"./tune_45593_1\",\n",
    "    cost_model=\"xgb\"\n",
    ")\n",
    "print(len(database))\n",
    "sch1 = ms.tir_integration.compile_tir(database, new_mod, target)\n",
    "print(type(sch1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sch1.trace)\n",
    "# print(sch1.mod.script())\n",
    "rt_mod = tvm.build(sch1.mod, target=\"cuda\")\n",
    "\n",
    "evaluator = rt_mod.time_evaluator(\"main\", dev, number=100)\n",
    "\n",
    "print(\"evaluator GEMV-Blocking: %f GFLOPS\" % (1228406784 / evaluator(W_nd, S_nd, Input_nd, Output_nd).mean / 1e9))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "record_database = ms.Database.create(kind='json', work_dir='./tune_45593_1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_sch = ms.tir_integration.compile_tir(record_database, new_mod, target)\n",
    "\n",
    "record_rt_mod = tvm.build(record_sch.mod, target=\"cuda\")\n",
    "\n",
    "record_evaluator = record_rt_mod.time_evaluator(\"main\", dev, number=20)\n",
    "\n",
    "print(\"evaluator GEMV-Blocking: %f GFLOPS\" % (num_flop / record_evaluator(W_nd, S_nd, Input_nd, Output_nd).mean / 1e9))\n",
    "print(record_sch.trace)\n",
    "print(record_sch.mod.script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TYPE_CHECKING, Dict, List, Optional, Union, Callable\n",
    "from tvm import runtime\n",
    "if TYPE_CHECKING:\n",
    "    import numpy as np  # type: ignore\n",
    "    from tvm.ir import IRModule\n",
    "    from tvm.meta_schedule.runner import EvaluatorConfig, RPCConfig\n",
    "    from tvm.runtime import Device, Module, NDArray\n",
    "    from tvm.target import Target\n",
    "    from tvm.runtime.vm import Executable\n",
    "\n",
    "\n",
    "def f_measurement(\n",
    "    rt_mod: runtime.Module, device: runtime.ndarray.Device, input_data: Dict[str, runtime.NDArray]\n",
    "):\n",
    "    vm = relax.VirtualMachine(rt_mod, device=device)\n",
    "    vm.save_function(\"main\", \"measure_func\", **input_data, include_return=False)\n",
    "    evaluator = vm.time_evaluator(\n",
    "        func_name=\"measure_func\",\n",
    "        dev=device,\n",
    "        repeat=100,\n",
    "        number=1,\n",
    "        min_repeat_ms=500,\n",
    "    )\n",
    "    return evaluator()\n",
    "\n",
    "def run_module_via_rpc(\n",
    "    rpc_config: \"RPCConfig\",\n",
    "    lib: Union[\"Module\", \"Executable\"],\n",
    "    dev_type: str,\n",
    "    args: Union[Dict[int, \"np.ndarray\"], Dict[str, \"np.ndarray\"]],\n",
    "    continuation: Callable,\n",
    "    backend: Optional[str] = \"graph\",\n",
    "):\n",
    "    \"\"\"Execute a tvm.runtime.Module on RPC remote\"\"\"\n",
    "    # pylint: disable=import-outside-toplevel\n",
    "    import os\n",
    "    import tempfile\n",
    "\n",
    "    from tvm.contrib.tar import tar\n",
    "    from tvm.runtime import ndarray\n",
    "\n",
    "    # pylint: enable=import-outside-toplevel\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        # filename = os.path.join(tmp_dir, \"tvm_tmp_mod.\" + tar.output_format)\n",
    "        filename = os.path.join(tmp_dir, \"tvm_tmp_mod.\" + \"so\")\n",
    "        if backend == \"vm\":\n",
    "            code, lib = lib.save(filename, fmt=\"so\")\n",
    "        from tvm.contrib import ndk\n",
    "        lib.export_library(filename, ndk.create_shared)\n",
    "        session = rpc_config.connect_server()\n",
    "        print(type(session._sess))\n",
    "        session.upload(filename)\n",
    "        _, filename = os.path.split(filename)\n",
    "        rt_mod = session.load_module(filename)\n",
    "        \n",
    "        if backend == \"vm\":\n",
    "            rt_mod = session.get_function(\"runtime.Load_Executable\")(code, rt_mod)\n",
    "            # rt_mod = session.get_function(\"runtime.module.loadfile_relax.Executable\")(filename)\n",
    "        dev = session.device(dev_type=dev_type, dev_id=0)\n",
    "        # print(dev)\n",
    "        # create the remote runtime module\n",
    "        print(rt_mod)\n",
    "        print(rt_mod['main'])\n",
    "        from tvm.contrib import graph_executor as runtime\n",
    "        module = runtime.GraphModule(rt_mod[\"main\"](dev))\n",
    "        print(module)\n",
    "        for k, v in args.items():\n",
    "            module.set_input(k, tvm.nd.array(v))\n",
    "        return module.run()\n",
    "        # nd_args = {k: ndarray.array(v, dev) for k, v in args.items()}\n",
    "        nd_args = {k: ndarray.empty(v.shape, v.dtype, dev) for k, v in args.items()}\n",
    "        return continuation(rt_mod, dev, nd_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlc-chat-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18 (main, Sep 11 2023, 13:41:44) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adc680d7bb9506fe4cb4095bb1590f9337119923ef84dc5789278e013bf19adb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
