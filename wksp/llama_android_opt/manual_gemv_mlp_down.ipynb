{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tvm\n",
    "from tvm.script import ir as I\n",
    "from tvm.script import tir as T\n",
    "from tvm import autotvm, auto_scheduler\n",
    "from tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n",
    "from tvm import meta_schedule as ms\n",
    "from tvm.ir import IRModule\n",
    "from tvm import relax\n",
    "from tvm import rpc\n",
    "from tvm.contrib import utils, ndk\n",
    "x_shape = 11008\n",
    "w_w_x = 1376\n",
    "w_s_x = 344\n",
    "w_y = 4096\n",
    "func_name = \"main\"\n",
    "@I.ir_module\n",
    "class ModuleSrc:\n",
    "    @T.prim_func(private=False)\n",
    "    def main(lv575: T.Buffer((T.int64(1376), T.int64(4096)), \"uint32\"), lv576: T.Buffer((T.int64(344), T.int64(4096)), \"float16\"), lv574: T.Buffer((T.int64(1), T.int64(1), T.int64(11008)), \"float16\"), lv570: T.Buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\"), p_output0_intermediate: T.Buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\")):\n",
    "        T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": T.bool(True)})\n",
    "        # with T.block(\"root\"):\n",
    "        p_output0_intermediate_1 = T.alloc_buffer((T.int64(11008), T.int64(4096)), \"float16\")\n",
    "        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\")\n",
    "        for i, j in T.grid(T.int64(11008), T.int64(4096)):\n",
    "            with T.block(\"decode\"):\n",
    "                v_i, v_j = T.axis.remap(\"SS\", [i, j])\n",
    "                T.reads(lv575[v_i // T.int64(8), v_j], lv576[v_i // T.int64(32), v_j])\n",
    "                T.writes(p_output0_intermediate_1[v_i, v_j])\n",
    "                p_output0_intermediate_1[v_i, v_j] = (T.Cast(\"float16\", T.bitwise_and(T.shift_right(lv575[v_i // T.int64(8), v_j], T.Cast(\"uint32\", v_i % T.int64(8)) * T.uint32(4)), T.uint32(15))) - T.float16(7)) * lv576[v_i // T.int64(32), v_j]\n",
    "        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(1), T.int64(4096), T.int64(11008)):\n",
    "            with T.block(\"matmul\"):\n",
    "                v_i0, v_i1, v_i2, v_k = T.axis.remap(\"SSSR\", [i0, i1, i2, k])\n",
    "                T.reads(lv574[v_i0, v_i1, v_k], p_output0_intermediate_1[v_k, v_i2])\n",
    "                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])\n",
    "                with T.init():\n",
    "                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float16(0)\n",
    "                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv574[v_i0, v_i1, v_k] * p_output0_intermediate_1[v_k, v_i2]\n",
    "        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(4096)):\n",
    "            with T.block(\"T_add\"):\n",
    "                v_ax0, v_ax1, v_ax2 = T.axis.remap(\"SSS\", [ax0, ax1, ax2])\n",
    "                T.reads(lv570[v_ax0, v_ax1, v_ax2], var_matmul_intermediate[v_ax0, v_ax1, v_ax2])\n",
    "                T.writes(p_output0_intermediate[v_ax0, v_ax1, v_ax2])\n",
    "                p_output0_intermediate[v_ax0, v_ax1, v_ax2] = lv570[v_ax0, v_ax1, v_ax2] + var_matmul_intermediate[v_ax0, v_ax1, v_ax2]\n",
    "\n",
    "@I.ir_module\n",
    "class ModuleToManual:\n",
    "    @T.prim_func(private=False)\n",
    "    def main(lv575: T.Buffer((T.int64(1376), T.int64(4096)), \"uint32\"), lv576: T.Buffer((T.int64(344), T.int64(4096)), \"float16\"), lv574: T.Buffer((T.int64(1), T.int64(1), T.int64(11008)), \"float16\"), lv570: T.Buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\"), p_output0_intermediate: T.Buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\")):\n",
    "        T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": T.bool(True)})\n",
    "        # with T.block(\"root\"):\n",
    "        p_output0_intermediate_1 = T.alloc_buffer((T.int64(11008), T.int64(4096)), \"float16\")\n",
    "        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\")\n",
    "        for i, j in T.grid(T.int64(11008), T.int64(4096)):\n",
    "            with T.block(\"decode\"):\n",
    "                v_i, v_j = T.axis.remap(\"SS\", [i, j])\n",
    "                T.reads(lv575[v_i // T.int64(8), v_j], lv576[v_i // T.int64(32), v_j])\n",
    "                T.writes(p_output0_intermediate_1[v_i, v_j])\n",
    "                p_output0_intermediate_1[v_i, v_j] = (T.Cast(\"float16\", T.bitwise_and(T.shift_right(lv575[v_i // T.int64(8), v_j], T.Cast(\"uint32\", v_i % T.int64(8)) * T.uint32(4)), T.uint32(15))) - T.float16(7)) * lv576[v_i // T.int64(32), v_j]\n",
    "        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(1), T.int64(4096), T.int64(11008)):\n",
    "            with T.block(\"matmul\"):\n",
    "                v_i0, v_i1, v_i2, v_k = T.axis.remap(\"SSSR\", [i0, i1, i2, k])\n",
    "                T.reads(lv574[v_i0, v_i1, v_k], p_output0_intermediate_1[v_k, v_i2])\n",
    "                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])\n",
    "                with T.init():\n",
    "                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float16(0)\n",
    "                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv574[v_i0, v_i1, v_k] * p_output0_intermediate_1[v_k, v_i2]\n",
    "        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(4096)):\n",
    "            with T.block(\"T_add\"):\n",
    "                v_ax0, v_ax1, v_ax2 = T.axis.remap(\"SSS\", [ax0, ax1, ax2])\n",
    "                T.reads(lv570[v_ax0, v_ax1, v_ax2], var_matmul_intermediate[v_ax0, v_ax1, v_ax2])\n",
    "                T.writes(p_output0_intermediate[v_ax0, v_ax1, v_ax2])\n",
    "                p_output0_intermediate[v_ax0, v_ax1, v_ax2] = lv570[v_ax0, v_ax1, v_ax2] + var_matmul_intermediate[v_ax0, v_ax1, v_ax2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_0, i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_1 in T.grid(T.int64(16), T.int64(32)):\n",
      "    var_matmul_intermediate_local = T.Buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\", scope=\"local\")\n",
      "    for i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_2, k_0_0 in T.grid(T.int64(8), T.int64(8)):\n",
      "        with T.block(\"matmul\"):\n",
      "            vk_0_0 = T.axis.reduce(T.int64(8), k_0_0)\n",
      "            v_i0 = T.axis.spatial(T.int64(1), T.int64(0))\n",
      "            v_i1 = T.axis.spatial(T.int64(1), T.int64(0))\n",
      "            v_i2 = T.axis.spatial(T.int64(4096), i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_0 * T.int64(256) + i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_1 * T.int64(8) + i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_2)\n",
      "            var_matmul_intermediate_rf = T.Buffer((T.int64(8), T.int64(1), T.int64(1), T.int64(4096)), \"float16\")\n",
      "            T.reads(var_matmul_intermediate_rf[vk_0_0, v_i0, v_i1, v_i2])\n",
      "            T.writes(var_matmul_intermediate_local[v_i0, v_i1, v_i2])\n",
      "            with T.init():\n",
      "                var_matmul_intermediate_local[v_i0, v_i1, v_i2] = T.float16(0)\n",
      "            var_matmul_intermediate_local[v_i0, v_i1, v_i2] = var_matmul_intermediate_local[v_i0, v_i1, v_i2] + var_matmul_intermediate_rf[vk_0_0, v_i0, v_i1, v_i2]\n",
      "    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):\n",
      "        for ax2 in T.vectorized(T.int64(8)):\n",
      "            with T.block(\"var_matmul_intermediate_local\"):\n",
      "                v0, v1 = T.axis.remap(\"SS\", [ax0, ax1])\n",
      "                v2 = T.axis.spatial(T.int64(4096), i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_0 * T.int64(256) + i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_1 * T.int64(8) + ax2)\n",
      "                lv570 = T.Buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\")\n",
      "                T.reads(lv570[v0, v1, v2], var_matmul_intermediate_local[v0, v1, v2])\n",
      "                p_output0_intermediate = T.Buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\")\n",
      "                T.writes(p_output0_intermediate[v0, v1, v2])\n",
      "                p_output0_intermediate[v0, v1, v2] = lv570[v0, v1, v2] + var_matmul_intermediate_local[v0, v1, v2]\n",
      "================================================================\n",
      "for i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_0, i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_1 in T.grid(T.int64(16), T.int64(32)):\n",
      "    var_matmul_intermediate_local = T.Buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\", scope=\"local\")\n",
      "    for i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_2 in T.vectorized(T.int64(8)):\n",
      "        for k_0_0 in range(T.int64(8)):\n",
      "            with T.block(\"matmul\"):\n",
      "                vk_0_0 = T.axis.reduce(T.int64(8), k_0_0)\n",
      "                v_i0 = T.axis.spatial(T.int64(1), T.int64(0))\n",
      "                v_i1 = T.axis.spatial(T.int64(1), T.int64(0))\n",
      "                v_i2 = T.axis.spatial(T.int64(4096), i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_0 * T.int64(256) + i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_1 * T.int64(8) + i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_2)\n",
      "                var_matmul_intermediate_rf = T.Buffer((T.int64(8), T.int64(1), T.int64(1), T.int64(4096)), \"float16\")\n",
      "                T.reads(var_matmul_intermediate_rf[vk_0_0, v_i0, v_i1, v_i2])\n",
      "                T.writes(var_matmul_intermediate_local[v_i0, v_i1, v_i2])\n",
      "                with T.init():\n",
      "                    var_matmul_intermediate_local[v_i0, v_i1, v_i2] = T.float16(0)\n",
      "                var_matmul_intermediate_local[v_i0, v_i1, v_i2] = var_matmul_intermediate_local[v_i0, v_i1, v_i2] + var_matmul_intermediate_rf[vk_0_0, v_i0, v_i1, v_i2]\n",
      "    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):\n",
      "        for ax2 in T.vectorized(T.int64(8)):\n",
      "            with T.block(\"var_matmul_intermediate_local\"):\n",
      "                v0, v1 = T.axis.remap(\"SS\", [ax0, ax1])\n",
      "                v2 = T.axis.spatial(T.int64(4096), i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_0 * T.int64(256) + i0_i1_i2_fused_0_i0_i1_i2_fused_1_i0_i1_i2_fused_2_fused_1 * T.int64(8) + ax2)\n",
      "                lv570 = T.Buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\")\n",
      "                T.reads(lv570[v0, v1, v2], var_matmul_intermediate_local[v0, v1, v2])\n",
      "                p_output0_intermediate = T.Buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\")\n",
      "                T.writes(p_output0_intermediate[v0, v1, v2])\n",
      "                p_output0_intermediate[v0, v1, v2] = lv570[v0, v1, v2] + var_matmul_intermediate_local[v0, v1, v2]\n",
      "\n",
      "\n",
      "=================kernel source===============================\n",
      "// Function: main_kernel_1\n",
      "#ifdef cl_khr_fp16\n",
      "#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n",
      "#elif defined(cl_amd_fp16)\n",
      "#pragma OPENCL EXTENSION cl_amd_fp16 : enable\n",
      "#else\n",
      "#error \"Half precision floating point not supported by OpenCL implementation on your device.\" \n",
      "#endif\n",
      "\n",
      "__kernel void main_kernel_1(__global half* restrict lv570, __global half* restrict p_output0_intermediate, __global half* restrict var_matmul_intermediate_rf) {\n",
      "  half8 var_matmul_intermediate_local[1];\n",
      "  for (int k_0_0 = 0; k_0_0 < 8; ++k_0_0) {\n",
      "    if (k_0_0 == 0) {\n",
      "      var_matmul_intermediate_local[0] = ((half8)((half)0.000000e+00f, (half)0.000000e+00f, (half)0.000000e+00f, (half)0.000000e+00f, (half)0.000000e+00f, (half)0.000000e+00f, (half)0.000000e+00f, (half)0.000000e+00f));\n",
      "    }\n",
      "    var_matmul_intermediate_local[0] = (var_matmul_intermediate_local[0] + vload8(0, var_matmul_intermediate_rf + (((k_0_0 * 4096) + ((convert_int(get_group_id(0))) * 256)) + ((convert_int(get_local_id(0))) * 8))));\n",
      "  }\n",
      "  vstore8((vload8(0, lv570 + (((convert_int(get_group_id(0))) * 256) + ((convert_int(get_local_id(0))) * 8))) + var_matmul_intermediate_local[0]), 0, p_output0_intermediate + (((convert_int(get_group_id(0))) * 256) + ((convert_int(get_local_id(0))) * 8)));\n",
      "}\n",
      "\n",
      "// Function: main_kernel\n",
      "#ifdef cl_khr_fp16\n",
      "#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n",
      "#elif defined(cl_amd_fp16)\n",
      "#pragma OPENCL EXTENSION cl_amd_fp16 : enable\n",
      "#else\n",
      "#error \"Half precision floating point not supported by OpenCL implementation on your device.\" \n",
      "#endif\n",
      "\n",
      "__kernel void main_kernel(__global half* restrict lv574, __global uint* restrict lv575, __global half* restrict lv576, __global half* restrict var_matmul_intermediate_rf) {\n",
      "  half4 var_matmul_intermediate_rf_local[1];\n",
      "  __local half lv574_shared[11008];\n",
      "  half4 lv576_local[1];\n",
      "  uint4 lv575_local[1];\n",
      "  var_matmul_intermediate_rf_local[0] = ((half4)((half)0.000000e+00f, (half)0.000000e+00f, (half)0.000000e+00f, (half)0.000000e+00f));\n",
      "  for (int ax2_0 = 0; ax2_0 < 3; ++ax2_0) {\n",
      "    for (int ax2_3_s = 0; ax2_3_s < 4; ++ax2_3_s) {\n",
      "      if (((((ax2_0 * 4096) + ((convert_int(get_local_id(0))) * 32)) + ((convert_int(get_local_id(1))) * 4)) + ax2_3_s) < 11008) {\n",
      "        lv574_shared[((((ax2_0 * 4096) + ((convert_int(get_local_id(0))) * 32)) + ((convert_int(get_local_id(1))) * 4)) + ax2_3_s)] = lv574[((((ax2_0 * 4096) + ((convert_int(get_local_id(0))) * 32)) + ((convert_int(get_local_id(1))) * 4)) + ax2_3_s)];\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  barrier(CLK_LOCAL_MEM_FENCE);\n",
      "  for (int k_0_1 = 0; k_0_1 < 43; ++k_0_1) {\n",
      "    lv576_local[0] = vload4(0, lv576 + (((((convert_int(get_local_id(1))) * 176128) + (k_0_1 * 4096)) + ((convert_int(get_group_id(0))) * 512)) + ((convert_int(get_local_id(0))) * 4)));\n",
      "    for (int k_1 = 0; k_1 < 4; ++k_1) {\n",
      "      lv575_local[0] = vload4(0, lv575 + ((((((convert_int(get_local_id(1))) * 704512) + (k_0_1 * 16384)) + (k_1 * 4096)) + ((convert_int(get_group_id(0))) * 512)) + ((convert_int(get_local_id(0))) * 4)));\n",
      "      for (int k_2 = 0; k_2 < 8; ++k_2) {\n",
      "        var_matmul_intermediate_rf_local[0] = (var_matmul_intermediate_rf_local[0] + (((half4)(lv574_shared[(((((convert_int(get_local_id(1))) * 1376) + (k_0_1 * 32)) + (k_1 * 8)) + k_2)], lv574_shared[(((((convert_int(get_local_id(1))) * 1376) + (k_0_1 * 32)) + (k_1 * 8)) + k_2)], lv574_shared[(((((convert_int(get_local_id(1))) * 1376) + (k_0_1 * 32)) + (k_1 * 8)) + k_2)], lv574_shared[(((((convert_int(get_local_id(1))) * 1376) + (k_0_1 * 32)) + (k_1 * 8)) + k_2)])) * (((convert_half4(((lv575_local[0]  >>  ((uint4)(((convert_uint(k_2)) * (uint)4), ((convert_uint(k_2)) * (uint)4), ((convert_uint(k_2)) * (uint)4), ((convert_uint(k_2)) * (uint)4))))  &  ((uint4)((uint)15, (uint)15, (uint)15, (uint)15))))) - ((half4)((half)7.000000e+00f, (half)7.000000e+00f, (half)7.000000e+00f, (half)7.000000e+00f))) * lv576_local[0])));\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  vstore4(var_matmul_intermediate_rf_local[0], 0, var_matmul_intermediate_rf + ((((convert_int(get_local_id(1))) * 4096) + ((convert_int(get_group_id(0))) * 512)) + ((convert_int(get_local_id(0))) * 4)));\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ref to mlc-llm/dispatch/dispatch_tir_operator_adreno.py\n",
    "# 最优配置：0.711104ms\n",
    "## vf\tvi\ttx\tty\tbx\n",
    "## 4\t2\t128\t8\t8\n",
    "def sch_fused_decode6_fused_matmul7_add1(func):\n",
    "    sch = tvm.tir.Schedule(func)\n",
    "    b0 = sch.get_block(name=\"decode\", func_name=\"main\")\n",
    "    b1 = sch.get_block(name=\"matmul\", func_name=\"main\")\n",
    "    # 1 1 4096 11008\n",
    "    l2, l3, l4, l5 = sch.get_loops(block=b1)\n",
    "    # l6 = 4096\n",
    "    l6 = sch.fuse(l2, l3, l4, preserve_unit_iters=True)\n",
    "    v7, v8, v9 = sch.sample_perfect_tile(\n",
    "        # loop=l6, n=3, max_innermost_factor=4, decision=[8, 256, 2]\n",
    "        loop=l6, n=3, max_innermost_factor=4, decision=[8, 128, 4]\n",
    "    )\n",
    "    # 8  128   4\n",
    "    l10, l11, l12 = sch.split(loop=l6, factors=[v7, v8, v9], preserve_unit_iters=True)\n",
    "    v13, v14, v15 = sch.sample_perfect_tile(\n",
    "        loop=l5, n=3, max_innermost_factor=8, decision=[344, 4, 8]\n",
    "    )\n",
    "    l16, l17, l18 = sch.split(\n",
    "        loop=l5, factors=[v13, v14, v15], preserve_unit_iters=True\n",
    "    )\n",
    "    ## 搜索记录:\n",
    "    #       2, 172  0.939960ms\n",
    "    #       4, 86   0.757256ms\n",
    "    #       8, 43   716400ms\n",
    "    # v161, v162 = sch.sample_perfect_tile(loop=l16, n=2, max_innermost_factor=172, decision=[4, 86])\n",
    "    l161, _ = sch.split(l16, [8, 43], preserve_unit_iters=True)\n",
    "    # 将reduce操作按照l161做拆分，以便并行化. 其过程是: \n",
    "    #   1. 申请 [l161, 1, 1, 4096]个xxx_rf内存\n",
    "    #   2. 将计算拆为l161个chunks分别计算\n",
    "    #   3. 按照l161维度reduce, 得到最终的输出\n",
    "    sch.rfactor(l161, 0)\n",
    "    ## 此时b1还是block('matmul'), 但是计算内容变为rf的合并操作(即: reduce = sum(sub_reduces))\n",
    "    ## 此时拆分的reduce计算变为 block('matmul_rf')\n",
    "    b2 = sch.get_block(name=\"matmul_rf\", func_name = \"main\")\n",
    "    # 调用rfactor后, 计算部分转移到了 block('matmul_rf'), 所以得重新获取loops\n",
    "    # s = spatial,  r = reduce\n",
    "    lb2s1, lb2s2, lb2s3, lb2r1, lb2r2, lb2r3, lb2r4 = sch.get_loops(block=b2)\n",
    "    # 8, 128, 8, 43, 4, 8, 4\n",
    "    sch.reorder(lb2s1, lb2s2, lb2r1, lb2r2, lb2r3, lb2r4, lb2s3)\n",
    "    sch.bind(loop=lb2s1, thread_axis=\"blockIdx.x\")\n",
    "    sch.bind(loop=lb2s2, thread_axis=\"threadIdx.x\")\n",
    "    sch.bind(loop=lb2r1, thread_axis=\"threadIdx.y\")\n",
    "\n",
    "    sch.compute_inline(block=b0)\n",
    "    b21 = sch.cache_write(block = b2, write_buffer_index=0, storage_scope=\"local\")\n",
    "    sch.reverse_compute_at(block = b21, loop=lb2r1, preserve_unit_loops=True, index=-1)\n",
    "    lb21, lb22, lb23, lb24, lb25, lb26, lb27 = sch.get_loops(block=b2)\n",
    "    sch.vectorize(lb27)\n",
    "    lb211, lb212, lb213, lb214, lb215,lb216, lb217 = sch.get_loops(block=b21)\n",
    "    sch.vectorize(lb217)\n",
    "\n",
    "    # 权重W uint32: [1376, 4096]\n",
    "    b80 = sch.cache_read(block=b2, read_buffer_index=1, storage_scope=\"local\")\n",
    "    sch.compute_at(block=b80, loop=lb2r3, preserve_unit_loops=True, index=-1)\n",
    "    l801, l802, l803, l804, l805, l806, l807 = sch.get_loops(block=b80)\n",
    "    sch.vectorize(l807)\n",
    "\n",
    "    # 权重Scale fp16: [344, 4096]\n",
    "    b81 = sch.cache_read(block=b2, read_buffer_index=2, storage_scope=\"local\")\n",
    "    sch.compute_at(block=b81, loop=lb2r2, preserve_unit_loops=True, index=-1)\n",
    "    l811, l812, l813, l814, l815, l816 = sch.get_loops(block=b81)\n",
    "    sch.vectorize(l816)\n",
    "\n",
    "    # 输入X: lv574_shared, shape[1,1,11008] -> [8, 128, 8, 1, 1, 11008/(8*128*8)] (无法整除)-> [8, 128, 8, 1, 1, 11008]\n",
    "    b20 = sch.cache_read(block=b2, read_buffer_index=0, storage_scope=\"shared\")\n",
    "    sch.compute_at(block=b20, loop=lb2r1, preserve_unit_loops=True, index=-1)\n",
    "    lb20l1, lb20l2, lb20l3, lb20l4, lb20l5, lb20l6 = sch.get_loops(block=b20)\n",
    "    l34, l35, l36, l37 = sch.split(\n",
    "        # loop=l33, factors=[None, 256, 8], preserve_unit_iters=True\n",
    "        ### 注意这里的数字与最开始设置保持一致\n",
    "        # loop=lb20l6, factors=[None, 256, 4, 4], preserve_unit_iters=True\n",
    "        loop=lb20l6, factors=[None, 128, 8, 2], preserve_unit_iters=True\n",
    "    )\n",
    "    # 这里 l37 = 4, 11008 / (threadIdx.x * threadIdx.y * 4) 无法整除, 所以只有一部分线程可以执行到shared_memory构建\n",
    "    # 实际观测 sch.vectorize(loop=l37) 并没有生效，不知道是否因为不是所有线程都能执行, 所以取消了vload4\n",
    "    sch.vectorize(loop=l37)\n",
    "    sch.bind(loop=l35, thread_axis=\"threadIdx.x\")\n",
    "    sch.bind(loop=l36, thread_axis=\"threadIdx.y\")\n",
    "    v21 = sch.sample_categorical(\n",
    "        candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=2\n",
    "    )\n",
    "    sch.annotate(\n",
    "        block_or_loop=b20, ann_key=\"meta_schedule.cooperative_fetch\", ann_val=v21\n",
    "    )\n",
    "    sch.vectorize(loop=l12)\n",
    "    b27 = sch.decompose_reduction(block=b2, loop=lb2r1)\n",
    "    sch.enter_postproc()\n",
    "    sch.unannotate(block_or_loop=b20, ann_key=\"meta_schedule.cooperative_fetch\")\n",
    "\n",
    "    #######################################################################################\n",
    "    ###################以下为kenenl1: 执行 sub_reduce结果合并 & bias操作#######################\n",
    "    #######################################################################################\n",
    "    # 计算的中间结果: var_matmul_intermediate_rf, shape[8, 1,1,4096]\n",
    "    #  8   128   4\n",
    "    # l10, l11, l12\n",
    "    b19 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope=\"local\")\n",
    "    l41,l42,l43,l44 = sch.get_loops(block=b1)\n",
    "    l411 = sch.fuse(l41,l42, l43)\n",
    "    ## 调整记录:\n",
    "    #       4, 256, 4 0.717400ms\n",
    "    #       8, 128, 4 0.717368ms\n",
    "    #       16, 64, 4 0.717368ms\n",
    "    #       32, 32, 4 0.716808ms\n",
    "    #       64, 16, 4 0.718056ms\n",
    "\n",
    "    #       4, 128, 8 0.719936ms\n",
    "    #       8, 64,  8 0.719024ms\n",
    "    #       16, 32, 8 0.716400ms best\n",
    "    #       32, 16, 8 0.717544ms\n",
    "\n",
    "    #       4, 64, 16 0.722680ms\n",
    "    #       8, 32, 16 0.719608ms\n",
    "    #       16, 16, 16 0.718744ms\n",
    "    #       32, 8, 16 0.720376ms\n",
    "    l411_1, l411_2, l411_3 = sch.split(l411, [16, 32, 8], preserve_unit_iters=True)\n",
    "    sch.reverse_compute_at(block=b19, loop=l411_2, preserve_unit_loops=True, index=-1)\n",
    "    b28 = sch.get_block(name=\"T_add\", func_name=\"main\")\n",
    "    sch.reverse_compute_inline(block=b28)\n",
    "    # b19 对应block('matmul')的write部分，其实对应的是 block('T_add') write\n",
    "    # 8 128 1 1 4\n",
    "    l22, l23, l24, l25, l26 = sch.get_loops(block=b19)\n",
    "    sch.vectorize(loop=l26)\n",
    "    print(sch.get(l22))\n",
    "    # 8 128 4 8\n",
    "    l41,l42,l43,l44 = sch.get_loops(block=b1)\n",
    "    sch.vectorize(loop=l43)\n",
    "    print(\"================================================================\")\n",
    "    print(sch.get(l41))\n",
    "    sch.bind(loop=l41, thread_axis=\"blockIdx.x\")\n",
    "    sch.bind(loop=l42, thread_axis=\"threadIdx.x\")\n",
    "    return sch.mod[\"main\"].with_attr(\"tir.is_scheduled\", 1)\n",
    "\n",
    "\n",
    "sch_manual = tvm.tir.Schedule(ModuleToManual)\n",
    "sch_manual.mod['main'] = sch_fused_decode6_fused_matmul7_add1(sch_manual.mod[func_name])\n",
    "# print(\"\\n\\n=================final mod===============================\")\n",
    "# print(sch_manual.mod.script())\n",
    "print(\"\\n\\n=================kernel source===============================\")\n",
    "rt_mod = tvm.build(sch_manual.mod, target=\"opencl\")\n",
    "print(rt_mod.imported_modules[0].get_source())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda -keys=cuda,gpu -arch=sm_61 -max_num_threads=1024 -max_shared_memory_per_block=49152 -max_threads_per_block=1024 -registers_per_block=65536 -thread_warp_size=32\n",
      "[[[-20000. -19104. -19776. -18672. -20320. -18688. -18784. -19120.\n",
      "   -17808. -18256.]]]\n",
      "[[[-20000. -19104. -19776. -18672. -20320. -18688. -18784. -19120.\n",
      "   -17808. -18256.]]]\n"
     ]
    }
   ],
   "source": [
    "# run and compare with cuda\n",
    "import numpy as np\n",
    "def _detect_local_cuda():\n",
    "    dev = tvm.cuda()\n",
    "    if not dev.exist:\n",
    "        return None\n",
    "    return tvm.target.Target(\n",
    "        {\n",
    "            \"kind\": \"cuda\",\n",
    "            \"max_shared_memory_per_block\": dev.max_shared_memory_per_block,\n",
    "            \"max_threads_per_block\": dev.max_threads_per_block,\n",
    "            \"thread_warp_size\": dev.warp_size,\n",
    "            \"registers_per_block\": 65536,\n",
    "            \"arch\": \"sm_\" + tvm.cuda().compute_version.replace(\".\", \"\"),\n",
    "        }\n",
    "    )\n",
    "# target = tvm.target.Target(\"cuda\", host=\"llvm\")\n",
    "target = _detect_local_cuda()\n",
    "\n",
    "print(target)\n",
    "# 定义计算任务\n",
    "dev = tvm.cuda(0)\n",
    "\n",
    "num_flop = 1228406784\n",
    "W_w_np = np.random.uniform(size=(w_w_x, w_y)).astype(\"uint32\")\n",
    "W_s_np = np.random.uniform(size=(w_s_x, w_y)).astype(\"float16\")\n",
    "B_np = np.random.uniform(size=(1, 1, w_y)).astype(\"float16\")\n",
    "Input_np = np.random.uniform(size=(1, 1, x_shape)).astype(\"float16\")\n",
    "# W_w_np = np.ones((w_w_x, w_y), np.uint32) * 1#.astype(\"uint32\")\n",
    "# W_s_np = np.ones((w_s_x, w_y), np.float16) * 1#.astype(\"float16\") * 2\n",
    "# Input_np = np.ones((1, 1, x_shape), np.float16)#.astype(\"float16\")\n",
    "Output_nd = tvm.nd.array(np.zeros((1, 1, w_y), dtype=\"float16\"), dev)\n",
    "def numpy_caculate():\n",
    "    test_cols = 10\n",
    "    reduce_div_factor = 8\n",
    "    per_reduce_div_shape = x_shape//reduce_div_factor\n",
    "    output = np.zeros((1, 1, test_cols), dtype = np.float16)\n",
    "    output_rf = np.zeros((reduce_div_factor, 1, 1, test_cols), dtype = np.float16)\n",
    "    W_w_inv_np = np.transpose(W_w_np)\n",
    "    W_s_inv_np = np.transpose(W_s_np)\n",
    "    for i in range(test_cols):\n",
    "        for rf in range(reduce_div_factor):\n",
    "            for r in range(per_reduce_div_shape * rf, per_reduce_div_shape * (rf+1)):\n",
    "                temp = Input_np[0][0][r] * np.float16((W_w_inv_np[i][r // 8] >> ((r % 8) * 4) & (15)) - np.float16(7.0)) * W_s_inv_np[i][r // 32]\n",
    "                output_rf[rf][0][0][i] = output_rf[rf][0][0][i] + temp\n",
    "            output[0][0][i] = output[0][0][i] + output_rf[rf][0][0][i]\n",
    "        output[0][0][i] = output[0][0][i] + B_np[0][0][i]\n",
    "    print(output)\n",
    "\n",
    "    output = np.zeros((1, 1, test_cols), dtype = np.float16)\n",
    "    output_rf = np.zeros((reduce_div_factor, 1, 1, test_cols), dtype = np.float16)\n",
    "    for i in range(test_cols):\n",
    "        for rf in range(reduce_div_factor):\n",
    "            for r in range(per_reduce_div_shape * rf, per_reduce_div_shape * (rf+1)):\n",
    "                temp = Input_np[0][0][r] * np.float16((W_w_np[r // 8][i] >> ((r % 8) * 4) & (15)) - np.float16(7.0)) * W_s_np[r // 32][i]\n",
    "                output_rf[rf][0][0][i] = output_rf[rf][0][0][i] + temp\n",
    "            output[0][0][i] = output[0][0][i] + output_rf[rf][0][0][i]\n",
    "        output[0][0][i] = output[0][0][i] + B_np[0][0][i]\n",
    "    print(output)\n",
    "numpy_caculate()\n",
    "def print_npdata(np_data: np.ndarray) :\n",
    "    print(np_data)\n",
    "    print_num = 20\n",
    "    d = np_data.flatten()\n",
    "    p_size = print_num if d.size > print_num else d.size\n",
    "    print(d[:p_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual_evaluator GEMV-Blocking: 126.260829 GFLOPS\n",
      "[[[-19360. -18912. -18976. ... -19408. -17728. -18272.]]]\n",
      "[-19360. -18912. -18976. -19840. -19008. -19360. -18864. -18656. -19392.\n",
      " -19232. -19120. -19056. -19680. -18816. -18512. -18848. -18416. -20048.\n",
      " -19984. -18592.]\n"
     ]
    }
   ],
   "source": [
    "# cuda未优化版本测试\n",
    "sch = tvm.tir.Schedule(ModuleSrc)\n",
    "with target:\n",
    "    src_gpu_mod = tvm.tir.transform.DefaultGPUSchedule()(sch.mod) ##\n",
    "rt_mod = tvm.build(src_gpu_mod, target=\"cuda\")\n",
    "W_w_nd = tvm.nd.array(W_w_np, dev)\n",
    "W_s_nd = tvm.nd.array(W_s_np, dev)\n",
    "B_nd = tvm.nd.array(B_np, dev)\n",
    "Input_nd = tvm.nd.array(Input_np, dev)\n",
    "Output_nd = tvm.nd.array(np.zeros((1, 1, w_y), dtype=\"float16\"), dev)\n",
    "evaluator = rt_mod.time_evaluator(\"main\", dev, number=32)\n",
    "print(\"manual_evaluator GEMV-Blocking: %f GFLOPS\" % (num_flop / evaluator(W_w_nd, W_s_nd, Input_nd, B_nd, Output_nd).mean / 1e9))\n",
    "# print(Output_nd.numpy())\n",
    "print_npdata(Output_nd.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual_evaluator GEMV-Blocking: 199.075418 GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20320. -18688. -18768. -19120. -17808.\n",
      " -18256. -18416. -20128. -19120. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19664.]\n"
     ]
    }
   ],
   "source": [
    "# cuda优化版本测试\n",
    "rt_mod = tvm.build(sch_manual.mod, target=\"cuda\")\n",
    "W_w_nd = tvm.nd.array(W_w_np, dev)\n",
    "W_s_nd = tvm.nd.array(W_s_np, dev)\n",
    "B_nd = tvm.nd.array(B_np, dev)\n",
    "Input_nd = tvm.nd.array(Input_np, dev)\n",
    "Output_nd = tvm.nd.array(np.zeros((1, 1, w_y), dtype=\"float16\"), dev)\n",
    "evaluator = rt_mod.time_evaluator(\"main\", dev, number=32)\n",
    "print(\"manual_evaluator GEMV-Blocking: %f GFLOPS\" % (num_flop / evaluator(W_w_nd, W_s_nd, Input_nd, B_nd, Output_nd).mean / 1e9))\n",
    "# print(Output_nd.numpy())\n",
    "print_npdata(Output_nd.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TVM_NDK_CC\"]=\"/home/sensetime/Android/Sdk/ndk/25.2.9519653/toolchains/llvm/prebuilt/linux-x86_64/bin/aarch64-linux-android33-clang++\"\n",
    "target = tvm.target.Target(\"opencl -device=adreno\", host=\"llvm -mtriple=aarch64-linux-gnu\")\n",
    "device_key=\"android\"\n",
    "rpc_host = \"10.4.236.32\"\n",
    "rpc_port = 9190\n",
    "comp_target = tvm.target.Target(\"opencl\", host=\"llvm -mtriple=aarch64-linux-android\")  # TODO: Only support arm64 for now\n",
    "\n",
    "def test_opencl(mod: tvm.IRModule, name_hint: str):\n",
    "    # mod = tvm.lower(sch_manual.mod)\n",
    "    print(\"Build ...\")\n",
    "    android_rt_mod = tvm.build(mod, target=\"opencl\", target_host=\"llvm -mtriple=aarch64-linux-android\")\n",
    "    # print(android_rt_mod.imported_modules[0].get_source())\n",
    "    temp = utils.tempdir()\n",
    "    path_dso_cl = temp.relpath(\"dev_lib_cl.so\")\n",
    "    android_rt_mod.export_library(path_dso_cl, ndk.create_shared)\n",
    "\n",
    "    print(\"Run GPU(OpenCL Flavor) test ...\")\n",
    "    # Establish remote connection with target hardware\n",
    "\n",
    "    tracker = rpc.connect_tracker(rpc_host, rpc_port)\n",
    "    remote = tracker.request(device_key, priority=0, session_timeout=60)\n",
    "    print(\"Connect to device done.\")\n",
    "    dev = remote.cl(0)\n",
    "    remote.upload(path_dso_cl)\n",
    "    f1 = remote.load_module(\"dev_lib_cl.so\")\n",
    "\n",
    "    W_w_nd = tvm.nd.array(W_w_np, dev)\n",
    "    W_s_nd = tvm.nd.array(W_s_np, dev)\n",
    "    B_nd = tvm.nd.array(B_np, dev)\n",
    "    Input_nd = tvm.nd.array(Input_np, dev)\n",
    "    Output_nd = tvm.nd.array(np.zeros((1, 1, w_y), dtype=\"float16\"), dev)\n",
    "    test_number=32\n",
    "    time_f = f1.time_evaluator(f1.entry_name, dev, number=test_number)\n",
    "    cost = time_f(W_w_nd, W_s_nd, Input_nd, B_nd, Output_nd).mean\n",
    "    print(\"evaluator[%s] GEMV-Blocking: %fms with loop %d\" % (name_hint, cost * 1000, test_number))\n",
    "    print(\"evaluator[%s] GEMV-Blocking: %fGFLOPS\" % (name_hint, num_flop / cost / 1e9))\n",
    "    print_npdata(Output_nd.numpy())\n",
    "    # return Output_nd.numpy()\n",
    "    return cost * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/workspace/llm/github/new_wksp/tvm-unity/python/tvm/driver/build_module.py:264: UserWarning: target_host parameter is going to be deprecated. Please pass in tvm.target.Target(target, host=target_host) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connect to device done.\n",
      "evaluator[source] GEMV-Blocking: 2.098032ms with loop 32\n",
      "evaluator[source] GEMV-Blocking: 585.504313GFLOPS\n",
      "[[[-20176. -19312. -19920. ... -19136. -18432. -18688.]]]\n",
      "[-20176. -19312. -19920. -18944. -20512. -18912. -18928. -19344. -18016.\n",
      " -18432. -18576. -20272. -19328. -19136. -19232. -19232. -19136. -18160.\n",
      " -19056. -19872.]\n",
      "2.098032\n",
      "[2.098032]\n"
     ]
    }
   ],
   "source": [
    "# 未优化版本opencl测试\n",
    "from tvm import dlight as dl\n",
    "sch = tvm.tir.Schedule(ModuleSrc)\n",
    "with target:\n",
    "    # src_gpu_mod = tvm.tir.transform.DefaultGPUSchedule()(sch.mod) ##\n",
    "    mod_deploy = dl.ApplyDefaultSchedule(  # pylint: disable=not-callable\n",
    "        dl.gpu.Matmul(),\n",
    "        dl.gpu.GEMV(),\n",
    "        dl.gpu.Reduction(),\n",
    "        dl.gpu.GeneralReduction(),\n",
    "        dl.gpu.Fallback(),\n",
    "    )(sch.mod)\n",
    "src_output = test_opencl(mod_deploy, \"source\")\n",
    "print_npdata(src_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[opted] GEMV-Blocking: 0.717656ms with loop 32\n",
      "evaluator[opted] GEMV-Blocking: 1711.693045GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n"
     ]
    }
   ],
   "source": [
    "#优化版本opencl测试\n",
    "# print(sch_manual.mod)\n",
    "opt_output = test_opencl(sch_manual.mod, \"opted\")\n",
    "# print_npdata(opt_output)\n",
    "# np.testing.assert_equal(opt_output, src_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tasks: 162\n",
      "search record [1/162]: start run 2 2 16 2 128\n",
      "Build ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/workspace/llm/github/new_wksp/tvm-unity/python/tvm/driver/build_module.py:264: UserWarning: target_host parameter is going to be deprecated. Please pass in tvm.target.Target(target, host=target_host) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 7.009120ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 175.258347GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [2/162]: start run 2 2 16 4 128\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 3.906928ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 314.417564GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [3/162]: start run 2 2 16 8 128\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.436456ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 504.177701GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [4/162]: start run 2 2 32 2 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 4.003016ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 306.870316GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [5/162]: start run 2 2 32 4 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.507920ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 489.810992GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [6/162]: start run 2 2 32 8 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.387456ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 885.366299GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [7/162]: start run 2 2 64 2 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.414936ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 508.670534GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [8/162]: start run 2 2 64 4 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.259136ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 975.594998GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [9/162]: start run 2 2 64 8 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.017624ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1207.132285GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [10/162]: start run 2 2 128 2 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.620576ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 758.006279GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [11/162]: start run 2 2 128 4 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.265160ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 970.949749GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [12/162]: start run 2 2 128 8 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.217584ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1008.888737GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [13/162]: start run 2 2 256 2 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.249328ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 983.254025GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [14/162]: start run 2 2 256 4 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.172848ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1047.370831GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [15/162]: skip 2 2 256 8 8\n",
      "search record [16/162]: start run 2 2 512 2 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.324448ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 528.472473GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [17/162]: skip 2 2 512 4 4\n",
      "search record [18/162]: skip 2 2 512 8 4\n",
      "search record [19/162]: start run 2 4 16 2 128\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 6.854680ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 179.207021GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [20/162]: start run 2 4 16 4 128\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 3.800760ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 323.200303GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [21/162]: start run 2 4 16 8 128\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.734528ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 449.220774GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [22/162]: start run 2 4 32 2 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 4.022248ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 305.403044GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [23/162]: start run 2 4 32 4 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.687160ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 457.139427GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [24/162]: start run 2 4 32 8 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.423800ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 862.766389GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [25/162]: start run 2 4 64 2 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.473912ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 496.544252GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [26/162]: start run 2 4 64 4 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.275936ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 962.749530GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [27/162]: start run 2 4 64 8 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.041488ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1179.472816GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [28/162]: start run 2 4 128 2 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.622624ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 757.049559GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [29/162]: start run 2 4 128 4 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.300456ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 944.596960GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [30/162]: start run 2 4 128 8 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.236208ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 993.689399GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [31/162]: start run 2 4 256 2 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.263648ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 972.111525GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [32/162]: start run 2 4 256 4 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.191984ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1030.556437GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [33/162]: skip 2 4 256 8 8\n",
      "search record [34/162]: start run 2 4 512 2 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.337560ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 525.508130GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [35/162]: skip 2 4 512 4 4\n",
      "search record [36/162]: skip 2 4 512 8 4\n",
      "search record [37/162]: start run 2 8 16 2 128\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 6.778232ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 181.228200GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [38/162]: start run 2 8 16 4 128\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 4.306880ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 285.219645GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [39/162]: start run 2 8 16 8 128\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.736768ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 448.853094GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [40/162]: start run 2 8 32 2 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 4.220976ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 291.024347GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [41/162]: start run 2 8 32 4 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.713968ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 452.623901GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [42/162]: start run 2 8 32 8 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.422080ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 863.809901GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [43/162]: start run 2 8 64 2 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.518672ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 487.720030GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [44/162]: start run 2 8 64 4 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.302312ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 943.250760GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [45/162]: start run 2 8 64 8 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.043296ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1177.428826GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [46/162]: start run 2 8 128 2 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.639552ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 749.233195GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [47/162]: start run 2 8 128 4 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.314192ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 934.723986GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [48/162]: start run 2 8 128 8 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.235000ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 994.661364GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [49/162]: start run 2 8 256 2 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.275728ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 962.906500GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [50/162]: start run 2 8 256 4 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.201160ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1022.683726GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [51/162]: skip 2 8 256 8 8\n",
      "search record [52/162]: start run 2 8 512 2 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.349824ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 522.765443GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [53/162]: skip 2 8 512 4 4\n",
      "search record [54/162]: skip 2 8 512 8 4\n",
      "search record [55/162]: start run 4 2 16 2 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 4.171128ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 294.502299GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [56/162]: start run 4 2 16 4 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.372552ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 517.757581GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [57/162]: start run 4 2 16 8 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.504576ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 816.447148GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [58/162]: start run 4 2 32 2 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.271232ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 540.854824GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [59/162]: start run 4 2 32 4 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.431992ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 857.830759GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [60/162]: start run 4 2 32 8 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.831160ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1477.942615GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [61/162]: start run 4 2 64 2 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.855432ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 662.059717GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [62/162]: start run 4 2 64 4 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.997960ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1230.917856GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [63/162]: start run 4 2 64 8 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.813320ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1510.360970GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [64/162]: start run 4 2 128 2 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.949800ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1293.332053GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [65/162]: start run 4 2 128 4 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.754136ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1628.892911GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [66/162]: start run 4 2 128 8 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.711104ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1727.464315GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [67/162]: start run 4 2 256 2 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.475128ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 832.745893GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [68/162]: start run 4 2 256 4 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.363584ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 900.866235GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [69/162]: skip 4 2 256 8 4\n",
      "search record [70/162]: start run 4 2 512 2 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.699960ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 454.972216GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [71/162]: skip 4 2 512 4 2\n",
      "search record [72/162]: skip 4 2 512 8 2\n",
      "search record [73/162]: start run 4 4 16 2 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 4.062592ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 302.370207GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [74/162]: start run 4 4 16 4 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.353536ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 521.940937GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [75/162]: start run 4 4 16 8 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.662864ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 738.729556GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [76/162]: start run 4 4 32 2 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.239536ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 548.509506GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [77/162]: start run 4 4 32 4 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.505896ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 815.731487GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [78/162]: start run 4 4 32 8 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.850880ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1443.689808GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [79/162]: start run 4 4 64 2 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.884472ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 651.857276GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [80/162]: start run 4 4 64 4 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.009136ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1217.285662GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [81/162]: start run 4 4 64 8 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.828848ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1482.065209GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [82/162]: start run 4 4 128 2 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.946456ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1297.901629GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [83/162]: start run 4 4 128 4 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.768000ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1599.488000GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [84/162]: start run 4 4 128 8 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.719288ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1707.809367GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [85/162]: start run 4 4 256 2 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.482368ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 828.678698GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [86/162]: start run 4 4 256 4 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.379544ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 890.444077GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [87/162]: skip 4 4 256 8 4\n",
      "search record [88/162]: start run 4 4 512 2 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.705648ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 454.015742GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [89/162]: skip 4 4 512 4 2\n",
      "search record [90/162]: skip 4 4 512 8 2\n",
      "search record [91/162]: start run 4 8 16 2 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 4.134208ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 297.132313GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [92/162]: start run 4 8 16 4 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.587352ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 474.773739GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [93/162]: start run 4 8 16 8 64\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.654240ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 742.580752GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [94/162]: start run 4 8 32 2 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.364352ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 519.553258GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [95/162]: start run 4 8 32 4 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.517096ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 809.709329GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [96/162]: start run 4 8 32 8 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.839976ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1462.430812GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [97/162]: start run 4 8 64 2 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.901440ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 646.040256GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [98/162]: start run 4 8 64 4 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.012920ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1212.738206GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [99/162]: start run 4 8 64 8 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.828824ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1482.108124GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [100/162]: start run 4 8 128 2 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.945560ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1299.131503GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [101/162]: start run 4 8 128 4 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.776400ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1582.182875GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [102/162]: start run 4 8 128 8 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.719736ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1706.746340GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [103/162]: start run 4 8 256 2 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.494384ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 822.015482GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [104/162]: start run 4 8 256 4 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.386576ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 885.928203GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [105/162]: skip 4 8 256 8 4\n",
      "search record [106/162]: start run 4 8 512 2 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.717472ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 452.040273GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [107/162]: skip 4 8 512 4 2\n",
      "search record [108/162]: skip 4 8 512 8 2\n",
      "search record [109/162]: start run 8 2 16 2 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 3.651064ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 336.451726GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [110/162]: start run 8 2 16 4 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.026224ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 606.254187GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [111/162]: start run 8 2 16 8 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.086656ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1130.446787GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [112/162]: start run 8 2 32 2 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.681080ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 458.176102GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [113/162]: start run 8 2 32 4 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.371528ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 895.648345GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [114/162]: start run 8 2 32 8 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.936552ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1311.626887GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [115/162]: start run 8 2 64 2 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.341432ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 915.742866GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [116/162]: start run 8 2 64 4 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.884312ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1389.110160GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [117/162]: start run 8 2 64 8 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.756872ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1623.004661GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [118/162]: start run 8 2 128 2 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.714160ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 716.623176GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [119/162]: start run 8 2 128 4 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.441560ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 852.137118GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [120/162]: start run 8 2 128 8 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.319808ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 930.746581GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [121/162]: start run 8 2 256 2 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.844152ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 431.906165GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [122/162]: start run 8 2 256 4 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.600384ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 472.394379GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [123/162]: skip 8 2 256 8 2\n",
      "search record [124/162]: start run 8 2 512 2 1\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 5.215928ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 235.510686GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [125/162]: skip 8 2 512 4 1\n",
      "search record [126/162]: skip 8 2 512 8 1\n",
      "search record [127/162]: start run 8 4 16 2 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 3.499456ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 351.027927GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [128/162]: start run 8 4 16 4 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.040936ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 601.884030GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [129/162]: start run 8 4 16 8 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.160448ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1058.562541GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [130/162]: start run 8 4 32 2 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.598848ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 472.673578GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [131/162]: start run 8 4 32 4 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.442440ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 851.617249GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [132/162]: start run 8 4 32 8 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.974960ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1259.956084GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [133/162]: start run 8 4 64 2 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.412200ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 869.853267GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [134/162]: start run 8 4 64 4 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.906712ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1354.792684GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [135/162]: start run 8 4 64 8 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.744496ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1649.984397GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [136/162]: start run 8 4 128 2 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.730960ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 709.667921GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [137/162]: start run 8 4 128 4 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.409888ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 871.279693GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [138/162]: start run 8 4 128 8 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.302920ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 942.810598GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [139/162]: start run 8 4 256 2 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.772168ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 443.121335GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [140/162]: start run 8 4 256 4 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.546832ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 482.327371GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [141/162]: skip 8 4 256 8 2\n",
      "search record [142/162]: start run 8 4 512 2 1\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 5.078752ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 241.871780GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [143/162]: skip 8 4 512 4 1\n",
      "search record [144/162]: skip 8 4 512 8 1\n",
      "search record [145/162]: start run 8 8 16 2 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 3.520008ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 348.978407GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [146/162]: start run 8 8 16 4 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.259104ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 543.758403GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [147/162]: start run 8 8 16 8 32\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.174528ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1045.872711GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [148/162]: start run 8 8 32 2 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.851024ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 430.865115GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [149/162]: start run 8 8 32 4 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.469296ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 836.051268GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [150/162]: start run 8 8 32 8 16\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.967280ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1269.959871GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [151/162]: start run 8 8 64 2 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.410504ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 870.899185GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [152/162]: start run 8 8 64 4 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.908920ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1351.501545GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [153/162]: start run 8 8 64 8 8\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 0.743520ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 1652.150291GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [154/162]: start run 8 8 128 2 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.736760ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 707.297948GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [155/162]: start run 8 8 128 4 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.417648ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 866.510434GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [156/162]: start run 8 8 128 8 4\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 1.304856ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 941.411760GFLOPS\n",
      "[[[-20000. -19136. -19776. ... -18976. -18240. -18496.]]]\n",
      "[-20000. -19136. -19776. -18672. -20336. -18688. -18784. -19120. -17808.\n",
      " -18256. -18432. -20128. -19136. -18912. -19024. -19008. -18928. -18032.\n",
      " -18944. -19680.]\n",
      "=====\n",
      "search record [157/162]: start run 8 8 256 2 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.782320ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 441.504494GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [158/162]: start run 8 8 256 4 2\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 2.554768ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 480.829094GFLOPS\n",
      "[[[-19328. -18496. -19200. ... -18336. -17712. -17984.]]]\n",
      "[-19328. -18496. -19200. -18096. -19680. -18064. -18176. -18608. -17312.\n",
      " -17696. -17824. -19456. -18512. -18208. -18432. -18416. -18448. -17520.\n",
      " -18304. -19152.]\n",
      "=====\n",
      "search record [159/162]: skip 8 8 256 8 2\n",
      "search record [160/162]: start run 8 8 512 2 1\n",
      "Build ...\n",
      "Run GPU(OpenCL Flavor) test ...\n",
      "Connect to device done.\n",
      "evaluator[search] GEMV-Blocking: 5.081464ms with loop 32\n",
      "evaluator[search] GEMV-Blocking: 241.742691GFLOPS\n",
      "[[[-17616. -17040. -17248. ... -16928. -16560. -16288.]]]\n",
      "[-17616. -17040. -17248. -16672. -18000. -16784. -16960. -16944. -16160.\n",
      " -16312. -16352. -17648. -17056. -16800. -16736. -16864. -16864. -16192.\n",
      " -16720. -17120.]\n",
      "=====\n",
      "search record [161/162]: skip 8 8 512 4 1\n",
      "search record [162/162]: skip 8 8 512 8 1\n",
      "================================\n",
      "+----+----+-----+----+-----+--------------------+\n",
      "| vf | vi |  tx | ty |  bx |      cost(ms)      |\n",
      "+----+----+-----+----+-----+--------------------+\n",
      "| 2  | 2  |  16 | 2  | 128 |      7.00912       |\n",
      "| 2  | 2  |  16 | 4  | 128 | 3.9069280000000006 |\n",
      "| 2  | 2  |  16 | 8  | 128 |      2.436456      |\n",
      "| 2  | 2  |  32 | 2  |  64 |      4.003016      |\n",
      "| 2  | 2  |  32 | 4  |  64 |      2.50792       |\n",
      "| 2  | 2  |  32 | 8  |  64 |      1.387456      |\n",
      "| 2  | 2  |  64 | 2  |  32 |      2.414936      |\n",
      "| 2  | 2  |  64 | 4  |  32 |      1.259136      |\n",
      "| 2  | 2  |  64 | 8  |  32 |      1.017624      |\n",
      "| 2  | 2  | 128 | 2  |  16 |      1.620576      |\n",
      "| 2  | 2  | 128 | 4  |  16 |      1.26516       |\n",
      "| 2  | 2  | 128 | 8  |  16 |      1.217584      |\n",
      "| 2  | 2  | 256 | 2  |  8  |      1.249328      |\n",
      "| 2  | 2  | 256 | 4  |  8  |      1.172848      |\n",
      "| 2  | 2  | 512 | 2  |  4  |      2.324448      |\n",
      "| 2  | 4  |  16 | 2  | 128 |      6.85468       |\n",
      "| 2  | 4  |  16 | 4  | 128 |      3.80076       |\n",
      "| 2  | 4  |  16 | 8  | 128 |      2.734528      |\n",
      "| 2  | 4  |  32 | 2  |  64 |      4.022248      |\n",
      "| 2  | 4  |  32 | 4  |  64 |      2.68716       |\n",
      "| 2  | 4  |  32 | 8  |  64 |       1.4238       |\n",
      "| 2  | 4  |  64 | 2  |  32 |      2.473912      |\n",
      "| 2  | 4  |  64 | 4  |  32 |      1.275936      |\n",
      "| 2  | 4  |  64 | 8  |  32 |      1.041488      |\n",
      "| 2  | 4  | 128 | 2  |  16 |      1.622624      |\n",
      "| 2  | 4  | 128 | 4  |  16 |      1.300456      |\n",
      "| 2  | 4  | 128 | 8  |  16 |      1.236208      |\n",
      "| 2  | 4  | 256 | 2  |  8  |      1.263648      |\n",
      "| 2  | 4  | 256 | 4  |  8  |      1.191984      |\n",
      "| 2  | 4  | 512 | 2  |  4  |      2.33756       |\n",
      "| 2  | 8  |  16 | 2  | 128 |      6.778232      |\n",
      "| 2  | 8  |  16 | 4  | 128 |      4.30688       |\n",
      "| 2  | 8  |  16 | 8  | 128 |      2.736768      |\n",
      "| 2  | 8  |  32 | 2  |  64 |      4.220976      |\n",
      "| 2  | 8  |  32 | 4  |  64 |      2.713968      |\n",
      "| 2  | 8  |  32 | 8  |  64 |      1.42208       |\n",
      "| 2  | 8  |  64 | 2  |  32 |      2.518672      |\n",
      "| 2  | 8  |  64 | 4  |  32 |      1.302312      |\n",
      "| 2  | 8  |  64 | 8  |  32 |      1.043296      |\n",
      "| 2  | 8  | 128 | 2  |  16 |      1.639552      |\n",
      "| 2  | 8  | 128 | 4  |  16 |      1.314192      |\n",
      "| 2  | 8  | 128 | 8  |  16 |       1.235        |\n",
      "| 2  | 8  | 256 | 2  |  8  |      1.275728      |\n",
      "| 2  | 8  | 256 | 4  |  8  |      1.20116       |\n",
      "| 2  | 8  | 512 | 2  |  4  |      2.349824      |\n",
      "| 4  | 2  |  16 | 2  |  64 |      4.171128      |\n",
      "| 4  | 2  |  16 | 4  |  64 |      2.372552      |\n",
      "| 4  | 2  |  16 | 8  |  64 |      1.504576      |\n",
      "| 4  | 2  |  32 | 2  |  32 |      2.271232      |\n",
      "| 4  | 2  |  32 | 4  |  32 |      1.431992      |\n",
      "| 4  | 2  |  32 | 8  |  32 |      0.83116       |\n",
      "| 4  | 2  |  64 | 2  |  16 |      1.855432      |\n",
      "| 4  | 2  |  64 | 4  |  16 |      0.99796       |\n",
      "| 4  | 2  |  64 | 8  |  16 |      0.81332       |\n",
      "| 4  | 2  | 128 | 2  |  8  |       0.9498       |\n",
      "| 4  | 2  | 128 | 4  |  8  |      0.754136      |\n",
      "| 4  | 2  | 128 | 8  |  8  |      0.711104      |\n",
      "| 4  | 2  | 256 | 2  |  4  |      1.475128      |\n",
      "| 4  | 2  | 256 | 4  |  4  |      1.363584      |\n",
      "| 4  | 2  | 512 | 2  |  2  |      2.69996       |\n",
      "| 4  | 4  |  16 | 2  |  64 |      4.062592      |\n",
      "| 4  | 4  |  16 | 4  |  64 |      2.353536      |\n",
      "| 4  | 4  |  16 | 8  |  64 |      1.662864      |\n",
      "| 4  | 4  |  32 | 2  |  32 |      2.239536      |\n",
      "| 4  | 4  |  32 | 4  |  32 |      1.505896      |\n",
      "| 4  | 4  |  32 | 8  |  32 |      0.85088       |\n",
      "| 4  | 4  |  64 | 2  |  16 |      1.884472      |\n",
      "| 4  | 4  |  64 | 4  |  16 |      1.009136      |\n",
      "| 4  | 4  |  64 | 8  |  16 |      0.828848      |\n",
      "| 4  | 4  | 128 | 2  |  8  |      0.946456      |\n",
      "| 4  | 4  | 128 | 4  |  8  |       0.768        |\n",
      "| 4  | 4  | 128 | 8  |  8  |      0.719288      |\n",
      "| 4  | 4  | 256 | 2  |  4  |      1.482368      |\n",
      "| 4  | 4  | 256 | 4  |  4  |      1.379544      |\n",
      "| 4  | 4  | 512 | 2  |  2  |      2.705648      |\n",
      "| 4  | 8  |  16 | 2  |  64 |      4.134208      |\n",
      "| 4  | 8  |  16 | 4  |  64 |      2.587352      |\n",
      "| 4  | 8  |  16 | 8  |  64 |      1.65424       |\n",
      "| 4  | 8  |  32 | 2  |  32 |      2.364352      |\n",
      "| 4  | 8  |  32 | 4  |  32 |      1.517096      |\n",
      "| 4  | 8  |  32 | 8  |  32 |      0.839976      |\n",
      "| 4  | 8  |  64 | 2  |  16 |      1.90144       |\n",
      "| 4  | 8  |  64 | 4  |  16 |      1.01292       |\n",
      "| 4  | 8  |  64 | 8  |  16 |      0.828824      |\n",
      "| 4  | 8  | 128 | 2  |  8  |      0.94556       |\n",
      "| 4  | 8  | 128 | 4  |  8  |       0.7764       |\n",
      "| 4  | 8  | 128 | 8  |  8  |      0.719736      |\n",
      "| 4  | 8  | 256 | 2  |  4  |      1.494384      |\n",
      "| 4  | 8  | 256 | 4  |  4  |      1.386576      |\n",
      "| 4  | 8  | 512 | 2  |  2  |      2.717472      |\n",
      "| 8  | 2  |  16 | 2  |  32 |      3.651064      |\n",
      "| 8  | 2  |  16 | 4  |  32 |      2.026224      |\n",
      "| 8  | 2  |  16 | 8  |  32 |      1.086656      |\n",
      "| 8  | 2  |  32 | 2  |  16 |      2.68108       |\n",
      "| 8  | 2  |  32 | 4  |  16 |      1.371528      |\n",
      "| 8  | 2  |  32 | 8  |  16 |      0.936552      |\n",
      "| 8  | 2  |  64 | 2  |  8  |      1.341432      |\n",
      "| 8  | 2  |  64 | 4  |  8  |      0.884312      |\n",
      "| 8  | 2  |  64 | 8  |  8  |      0.756872      |\n",
      "| 8  | 2  | 128 | 2  |  4  |      1.71416       |\n",
      "| 8  | 2  | 128 | 4  |  4  |      1.44156       |\n",
      "| 8  | 2  | 128 | 8  |  4  |      1.319808      |\n",
      "| 8  | 2  | 256 | 2  |  2  |      2.844152      |\n",
      "| 8  | 2  | 256 | 4  |  2  |      2.600384      |\n",
      "| 8  | 2  | 512 | 2  |  1  |      5.215928      |\n",
      "| 8  | 4  |  16 | 2  |  32 |      3.499456      |\n",
      "| 8  | 4  |  16 | 4  |  32 |      2.040936      |\n",
      "| 8  | 4  |  16 | 8  |  32 |      1.160448      |\n",
      "| 8  | 4  |  32 | 2  |  16 |      2.598848      |\n",
      "| 8  | 4  |  32 | 4  |  16 |      1.44244       |\n",
      "| 8  | 4  |  32 | 8  |  16 |      0.97496       |\n",
      "| 8  | 4  |  64 | 2  |  8  |       1.4122       |\n",
      "| 8  | 4  |  64 | 4  |  8  |      0.906712      |\n",
      "| 8  | 4  |  64 | 8  |  8  |      0.744496      |\n",
      "| 8  | 4  | 128 | 2  |  4  |      1.73096       |\n",
      "| 8  | 4  | 128 | 4  |  4  |      1.409888      |\n",
      "| 8  | 4  | 128 | 8  |  4  |      1.30292       |\n",
      "| 8  | 4  | 256 | 2  |  2  |      2.772168      |\n",
      "| 8  | 4  | 256 | 4  |  2  |      2.546832      |\n",
      "| 8  | 4  | 512 | 2  |  1  |      5.078752      |\n",
      "| 8  | 8  |  16 | 2  |  32 |      3.520008      |\n",
      "| 8  | 8  |  16 | 4  |  32 |      2.259104      |\n",
      "| 8  | 8  |  16 | 8  |  32 |      1.174528      |\n",
      "| 8  | 8  |  32 | 2  |  16 |      2.851024      |\n",
      "| 8  | 8  |  32 | 4  |  16 |      1.469296      |\n",
      "| 8  | 8  |  32 | 8  |  16 |      0.96728       |\n",
      "| 8  | 8  |  64 | 2  |  8  |      1.410504      |\n",
      "| 8  | 8  |  64 | 4  |  8  |      0.90892       |\n",
      "| 8  | 8  |  64 | 8  |  8  |      0.74352       |\n",
      "| 8  | 8  | 128 | 2  |  4  |      1.73676       |\n",
      "| 8  | 8  | 128 | 4  |  4  |      1.417648      |\n",
      "| 8  | 8  | 128 | 8  |  4  |      1.304856      |\n",
      "| 8  | 8  | 256 | 2  |  2  |      2.78232       |\n",
      "| 8  | 8  | 256 | 4  |  2  |      2.554768      |\n",
      "| 8  | 8  | 512 | 2  |  1  |      5.081464      |\n",
      "+----+----+-----+----+-----+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# 自动搜索\n",
    "def auto_tune(record_file: str):\n",
    "    from typing import Union\n",
    "    def search(vectorize_factor: int, vectorize_input: int, threadIdxX: int, threadIdxY: int, blockIdxX: Union[int, None] = None):\n",
    "        \"\"\"search by workgroup\n",
    "\n",
    "        Args:\n",
    "            blockIdxX (_type_): blockIdx.x\n",
    "            threadIdxX (_type_): threadIdx.x\n",
    "            vectorize_output (_type_): 输出的vectorize参数, 决定单线程输出多少个结果\n",
    "            vectorize_input (list, optional): 输入X拷贝到shared_memory时的vectorize参数, 一般为4或8\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        @I.ir_module\n",
    "        class ModuleToManual:\n",
    "            @T.prim_func(private=False)\n",
    "            def main(lv575: T.Buffer((T.int64(1376), T.int64(4096)), \"uint32\"), lv576: T.Buffer((T.int64(344), T.int64(4096)), \"float16\"), lv574: T.Buffer((T.int64(1), T.int64(1), T.int64(11008)), \"float16\"), lv570: T.Buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\"), p_output0_intermediate: T.Buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\")):\n",
    "                T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": T.bool(True)})\n",
    "                # with T.block(\"root\"):\n",
    "                p_output0_intermediate_1 = T.alloc_buffer((T.int64(11008), T.int64(4096)), \"float16\")\n",
    "                var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\")\n",
    "                for i, j in T.grid(T.int64(11008), T.int64(4096)):\n",
    "                    with T.block(\"decode\"):\n",
    "                        v_i, v_j = T.axis.remap(\"SS\", [i, j])\n",
    "                        T.reads(lv575[v_i // T.int64(8), v_j], lv576[v_i // T.int64(32), v_j])\n",
    "                        T.writes(p_output0_intermediate_1[v_i, v_j])\n",
    "                        p_output0_intermediate_1[v_i, v_j] = (T.Cast(\"float16\", T.bitwise_and(T.shift_right(lv575[v_i // T.int64(8), v_j], T.Cast(\"uint32\", v_i % T.int64(8)) * T.uint32(4)), T.uint32(15))) - T.float16(7)) * lv576[v_i // T.int64(32), v_j]\n",
    "                for i0, i1, i2, k in T.grid(T.int64(1), T.int64(1), T.int64(4096), T.int64(11008)):\n",
    "                    with T.block(\"matmul\"):\n",
    "                        v_i0, v_i1, v_i2, v_k = T.axis.remap(\"SSSR\", [i0, i1, i2, k])\n",
    "                        T.reads(lv574[v_i0, v_i1, v_k], p_output0_intermediate_1[v_k, v_i2])\n",
    "                        T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])\n",
    "                        with T.init():\n",
    "                            var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float16(0)\n",
    "                        var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv574[v_i0, v_i1, v_k] * p_output0_intermediate_1[v_k, v_i2]\n",
    "                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(4096)):\n",
    "                    with T.block(\"T_add\"):\n",
    "                        v_ax0, v_ax1, v_ax2 = T.axis.remap(\"SSS\", [ax0, ax1, ax2])\n",
    "                        T.reads(lv570[v_ax0, v_ax1, v_ax2], var_matmul_intermediate[v_ax0, v_ax1, v_ax2])\n",
    "                        T.writes(p_output0_intermediate[v_ax0, v_ax1, v_ax2])\n",
    "                        p_output0_intermediate[v_ax0, v_ax1, v_ax2] = lv570[v_ax0, v_ax1, v_ax2] + var_matmul_intermediate[v_ax0, v_ax1, v_ax2]\n",
    "\n",
    "        sch = tvm.tir.Schedule(ModuleToManual)\n",
    "        b0 = sch.get_block(name=\"decode\", func_name=\"main\")\n",
    "        b1 = sch.get_block(name=\"matmul\", func_name=\"main\")\n",
    "        # 1 1 4096 11008\n",
    "        l2, l3, l4, l5 = sch.get_loops(block=b1)\n",
    "        # l6 = 4096\n",
    "        l6 = sch.fuse(l2, l3, l4, preserve_unit_iters=True)\n",
    "        v7, v8, v9 = sch.sample_perfect_tile(\n",
    "            # loop=l6, n=3, max_innermost_factor=4, decision=[8, 256, 2]\n",
    "            loop=l6, n=3, max_innermost_factor=4, decision=[blockIdxX, threadIdxX, vectorize_factor]\n",
    "        )\n",
    "        # 8  128   4\n",
    "        l10, l11, l12 = sch.split(loop=l6, factors=[v7, v8, v9], preserve_unit_iters=True)\n",
    "        v13, v14, v15 = sch.sample_perfect_tile(\n",
    "            loop=l5, n=3, max_innermost_factor=8, decision=[344, 4, 8]\n",
    "        )\n",
    "        l16, l17, l18 = sch.split(\n",
    "            loop=l5, factors=[v13, v14, v15], preserve_unit_iters=True\n",
    "        )\n",
    "        ## 搜索记录:\n",
    "        #       2, 172  0.939960ms\n",
    "        #       4, 86   0.757256ms\n",
    "        #       8, 43   716400ms\n",
    "        # v161, v162 = sch.sample_perfect_tile(loop=l16, n=2, max_innermost_factor=172, decision=[4, 86])\n",
    "        l161, _ = sch.split(l16, [threadIdxY, 344//threadIdxY], preserve_unit_iters=True)\n",
    "        # 将reduce操作按照l161做拆分，以便并行化. 其过程是: \n",
    "        #   1. 申请 [l161, 1, 1, 4096]个xxx_rf内存\n",
    "        #   2. 将计算拆为l161个chunks分别计算\n",
    "        #   3. 按照l161维度reduce, 得到最终的输出\n",
    "        sch.rfactor(l161, 0)\n",
    "        ## 此时b1还是block('matmul'), 但是计算内容变为rf的合并操作(即: reduce = sum(sub_reduces))\n",
    "        ## 此时拆分的reduce计算变为 block('matmul_rf')\n",
    "        b2 = sch.get_block(name=\"matmul_rf\", func_name = \"main\")\n",
    "        # 调用rfactor后, 计算部分转移到了 block('matmul_rf'), 所以得重新获取loops\n",
    "        # s = spatial,  r = reduce\n",
    "        lb2s1, lb2s2, lb2s3, lb2r1, lb2r2, lb2r3, lb2r4 = sch.get_loops(block=b2)\n",
    "        # 8, 128, 8, 43, 4, 8, 4\n",
    "        sch.reorder(lb2s1, lb2s2, lb2r1, lb2r2, lb2r3, lb2r4, lb2s3)\n",
    "        sch.bind(loop=lb2s1, thread_axis=\"blockIdx.x\")\n",
    "        sch.bind(loop=lb2s2, thread_axis=\"threadIdx.x\")\n",
    "        sch.bind(loop=lb2r1, thread_axis=\"threadIdx.y\")\n",
    "\n",
    "        sch.compute_inline(block=b0)\n",
    "        b21 = sch.cache_write(block = b2, write_buffer_index=0, storage_scope=\"local\")\n",
    "        sch.reverse_compute_at(block = b21, loop=lb2r1, preserve_unit_loops=True, index=-1)\n",
    "        lb21, lb22, lb23, lb24, lb25, lb26, lb27 = sch.get_loops(block=b2)\n",
    "        sch.vectorize(lb27)\n",
    "        lb211, lb212, lb213, lb214, lb215,lb216, lb217 = sch.get_loops(block=b21)\n",
    "        sch.vectorize(lb217)\n",
    "\n",
    "        # 权重W uint32: [1376, 4096]\n",
    "        b80 = sch.cache_read(block=b2, read_buffer_index=1, storage_scope=\"local\")\n",
    "        sch.compute_at(block=b80, loop=lb2r3, preserve_unit_loops=True, index=-1)\n",
    "        l801, l802, l803, l804, l805, l806, l807 = sch.get_loops(block=b80)\n",
    "        sch.vectorize(l807)\n",
    "\n",
    "        # 权重Scale fp16: [344, 4096]\n",
    "        b81 = sch.cache_read(block=b2, read_buffer_index=2, storage_scope=\"local\")\n",
    "        sch.compute_at(block=b81, loop=lb2r2, preserve_unit_loops=True, index=-1)\n",
    "        l811, l812, l813, l814, l815, l816 = sch.get_loops(block=b81)\n",
    "        sch.vectorize(l816)\n",
    "\n",
    "        # 输入X: lv574_shared, shape[1,1,11008] -> [8, 128, 8, 1, 1, 11008/(8*128*8)] (无法整除)-> [8, 128, 8, 1, 1, 11008]\n",
    "        b20 = sch.cache_read(block=b2, read_buffer_index=0, storage_scope=\"shared\")\n",
    "        sch.compute_at(block=b20, loop=lb2r1, preserve_unit_loops=True, index=-1)\n",
    "\n",
    "        lb20l1, lb20l2, lb20l3, lb20l4, lb20l5, lb20l6 = sch.get_loops(block=b20)\n",
    "        l34, l35, l36, l37 = sch.split(\n",
    "            # loop=l33, factors=[None, 256, 8], preserve_unit_iters=True\n",
    "            ### 注意这里的数字与最开始设置保持一致\n",
    "            # loop=lb20l6, factors=[None, 256, 4, 4], preserve_unit_iters=True\n",
    "            loop=lb20l6, factors=[None, threadIdxX, threadIdxY, vectorize_input], preserve_unit_iters=True\n",
    "        )\n",
    "        # 这里 l37 = 4, 11008 / (threadIdx.x * threadIdx.y * 4) 无法整除, 所以只有一部分线程可以执行到shared_memory构建\n",
    "        # 实际观测 sch.vectorize(loop=l37) 并没有生效，不知道是否因为不是所有线程都能执行, 所以取消了vload4\n",
    "        sch.vectorize(loop=l37)\n",
    "        sch.bind(loop=l35, thread_axis=\"threadIdx.x\")\n",
    "        sch.bind(loop=l36, thread_axis=\"threadIdx.y\")\n",
    "\n",
    "        v21 = sch.sample_categorical(\n",
    "            candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=[1, 2, 4, 8].index(vectorize_input)\n",
    "        )\n",
    "        sch.annotate(\n",
    "            block_or_loop=b20, ann_key=\"meta_schedule.cooperative_fetch\", ann_val=v21\n",
    "        )\n",
    "        sch.vectorize(loop=l12)\n",
    "        b27 = sch.decompose_reduction(block=b2, loop=lb2r1)\n",
    "        sch.enter_postproc()\n",
    "        sch.unannotate(block_or_loop=b20, ann_key=\"meta_schedule.cooperative_fetch\")\n",
    "        \n",
    "        #######################################################################################\n",
    "        ###################以下为kenenl1: 执行 sub_reduce结果合并 & bias操作#######################\n",
    "        #######################################################################################\n",
    "        # 计算的中间结果: var_matmul_intermediate_rf, shape[8, 1,1,4096]\n",
    "        #  8   128   4\n",
    "        # l10, l11, l12\n",
    "        b19 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope=\"local\")\n",
    "        l41,l42,l43,l44 = sch.get_loops(block=b1)\n",
    "        l411 = sch.fuse(l41,l42, l43)\n",
    "        ## 调整记录:\n",
    "        #       4, 256, 4 0.717400ms\n",
    "        #       8, 128, 4 0.717368ms\n",
    "        #       16, 64, 4 0.717368ms\n",
    "        #       32, 32, 4 0.716808ms\n",
    "        #       64, 16, 4 0.718056ms\n",
    "\n",
    "        #       4, 128, 8 0.719936ms\n",
    "        #       8, 64,  8 0.719024ms\n",
    "        #       16, 32, 8 0.716400ms best\n",
    "        #       32, 16, 8 0.717544ms\n",
    "\n",
    "        #       4, 64, 16 0.722680ms\n",
    "        #       8, 32, 16 0.719608ms\n",
    "        #       16, 16, 16 0.718744ms\n",
    "        #       32, 8, 16 0.720376ms\n",
    "        l411_1, l411_2, l411_3 = sch.split(l411, [16, 32, 8], preserve_unit_iters=True)\n",
    "        sch.reverse_compute_at(block=b19, loop=l411_2, preserve_unit_loops=True, index=-1)\n",
    "        b28 = sch.get_block(name=\"T_add\", func_name=\"main\")\n",
    "        sch.reverse_compute_inline(block=b28)\n",
    "        l22, l23, l24, l25, l26 = sch.get_loops(block=b19)\n",
    "        l41,l42,l43,l44 = sch.get_loops(block=b1)\n",
    "        sch.vectorize(loop=l43)\n",
    "        sch.bind(loop=l41, thread_axis=\"blockIdx.x\")\n",
    "        sch.bind(loop=l42, thread_axis=\"threadIdx.x\")\n",
    "        return sch.mod\n",
    "\n",
    "    vec_factor = [2, 4, 8]\n",
    "    vec_input = [2, 4, 8]\n",
    "    blockx = [None]\n",
    "    threadx = [16, 32, 64, 128, 256, 512]\n",
    "    thready = [2, 4, 8]\n",
    "    task_index = 0\n",
    "    total_task_num = len(vec_factor)*len(vec_input)*len(blockx)*len(threadx) * len(thready)\n",
    "    records = {}\n",
    "    print(f\"Total tasks: {total_task_num}\")\n",
    "    write_interval = 5\n",
    "    from prettytable import PrettyTable\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"vf\", \"vi\", \"tx\", \"ty\", \"bx\", \"cost(ms)\"]\n",
    "    for vf in vec_factor:\n",
    "        for vi in vec_input:\n",
    "            for tx in threadx:\n",
    "                for ty in thready:\n",
    "                    task_index = task_index + 1\n",
    "                    import math\n",
    "                    bx = math.ceil(w_y /(vf * tx))\n",
    "                    if bx * tx * vf > w_y or tx * ty > 1024 or 344 % ty != 0  or w_y % (vf * tx) != 0:\n",
    "                        print(f\"search record [{task_index}/{total_task_num}]: skip {vf} {vi} {tx} {ty} {bx}\")\n",
    "                        continue\n",
    "                    print(f\"search record [{task_index}/{total_task_num}]: start run {vf} {vi} {tx} {ty} {bx}\")\n",
    "                    mod_deploy = search(vf, vi, tx, ty, bx)\n",
    "                    cost = test_opencl(mod_deploy, \"search\")\n",
    "                    print(\"=====\")\n",
    "                    records[(vf, vi, tx, ty, bx)] = cost\n",
    "                    table.add_row([vf, vi, tx, ty, bx, cost])\n",
    "                    if task_index % write_interval == 0:\n",
    "                        with open(record_file, 'wt') as f:\n",
    "                            f.write(table.get_csv_string())\n",
    "    print(\"================================\")\n",
    "    print(table)\n",
    "    \n",
    "    # record_sorted = sorted(record.items(), key=lambda x: x[1][0], reverse=True)\n",
    "auto_tune(\"./mlp_down_tune_record_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "target = tvm.target.Target(\"opencl -device=adreno\", host=\"llvm -mtriple=aarch64-linux-gnu\")\n",
    "device_key=\"android\"\n",
    "rpc_host = \"10.158.176.30\"\n",
    "rpc_port = 5001\n",
    "# remote = autotvm.measure.request_remote(device_key, \"10.158.176.30\", 5001, timeout=10000)\n",
    "# dev = remote.device(str(target), 0)\n",
    "\n",
    "# num_flop = 1228406784\n",
    "# W_np = np.random.uniform(size=(512, vocab_size)).astype(\"uint32\")\n",
    "# S_np = np.random.uniform(size=(128, vocab_size)).astype(\"float16\")\n",
    "# Input_np = np.random.uniform(size=(1, 1, 4096)).astype(\"float16\")\n",
    "# # Output_np = np.random.uniform(size=(1, 1, 4096)).astype(\"float16\")\n",
    "# W_nd = tvm.nd.array(W_np, dev)\n",
    "# S_nd = tvm.nd.array(S_np, dev)\n",
    "# Input_nd = tvm.nd.array(Input_np, dev)\n",
    "# Output_nd = tvm.nd.array(np.zeros((1, 1, vocab_size), dtype=\"float32\"), dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpc_config = ms.runner.RPCConfig(tracker_host=rpc_host, tracker_port=rpc_port, tracker_key = device_key)\n",
    "runner= ms.runner.RPCRunner(rpc_config)\n",
    "# ms.builder.LocalBuilder()\n",
    "sch = tvm.tir.Schedule(ModuleSrc)\n",
    "database = ms.tune_tir(\n",
    "    mod=ModuleSrc,\n",
    "    target=target,\n",
    "    max_trials_global=64,\n",
    "    num_trials_per_iter=64,\n",
    "    work_dir=\"./tune_first\",\n",
    "    cost_model=\"xgb\",\n",
    "    runner = runner\n",
    ")\n",
    "print(len(database))\n",
    "sch1 = ms.tir_integration.compile_tir(database, sch.mod, target)\n",
    "print(type(sch1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.script import relax as R\n",
    "@I.ir_module\n",
    "class Module:\n",
    "    @R.function\n",
    "    def main(A: R.Tensor((3, 4), dtype=\"float32\"), B: R.Tensor((4, 5), dtype=\"float32\")):\n",
    "        with R.dataflow():\n",
    "            lv: R.Tensor((3, 5), dtype=\"float32\") = R.matmul(A, B)\n",
    "            gv: R.Tensor((3, 5), dtype=\"float32\") = lv\n",
    "            R.output(gv)\n",
    "        return gv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## auto_scheduler test\n",
    "from tvm import auto_scheduler\n",
    "import numpy as np\n",
    "a_np = np.random.rand(3, 4).astype(\"float32\")\n",
    "b_np = np.random.rand(4, 5).astype(\"float32\")\n",
    "a_nd = tvm.runtime.NDArray(a_np)\n",
    "b_nd = tvm.runtime.NDArray(b_np)\n",
    "sch = tvm.tir.Schedule(Module)\n",
    "\n",
    "params = {\"A\": a_np, \"B\": b_np}\n",
    "## 报错，这里只支持relay\n",
    "# tasks = auto_scheduler.extract_tasks(sch.mod, params, target=target)\n",
    "tasks = ms.relax_integration.extract_tasks(sch.mod, target=target, params=params)\n",
    "print(len(tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mod_deploy import Module as ModuleAll\n",
    "params_all = {}\n",
    "tasks_all = auto_scheduler.extract_tasks(ModuleAll, params_all, target=target)\n",
    "print(len(tasks_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "log_file = \"tune.json\"\n",
    "def _detect_local_cuda():\n",
    "    dev = tvm.cuda()\n",
    "    if not dev.exist:\n",
    "        return None\n",
    "    return tvm.target.Target(\n",
    "        {\n",
    "            \"kind\": \"cuda\",\n",
    "            \"max_shared_memory_per_block\": dev.max_shared_memory_per_block,\n",
    "            \"max_threads_per_block\": dev.max_threads_per_block,\n",
    "            \"thread_warp_size\": dev.warp_size,\n",
    "            \"registers_per_block\": 65536,\n",
    "            \"arch\": \"sm_\" + tvm.cuda().compute_version.replace(\".\", \"\"),\n",
    "        }\n",
    "    )\n",
    "# target = tvm.target.Target(\"cuda\", host=\"llvm\")\n",
    "target = _detect_local_cuda()\n",
    "\n",
    "print(target)\n",
    "# 定义计算任务\n",
    "dev = tvm.cuda(0)\n",
    "\n",
    "num_flop = 1228406784\n",
    "W_np = np.random.uniform(size=(512, vocab_size)).astype(\"uint32\")\n",
    "S_np = np.random.uniform(size=(128, vocab_size)).astype(\"float16\")\n",
    "Input_np = np.random.uniform(size=(1, 1, 4096)).astype(\"float16\")\n",
    "# Output_np = np.random.uniform(size=(1, 1, 4096)).astype(\"float16\")\n",
    "W_nd = tvm.nd.array(W_np, dev)\n",
    "S_nd = tvm.nd.array(S_np, dev)\n",
    "Input_nd = tvm.nd.array(Input_np, dev)\n",
    "Output_nd = tvm.nd.array(np.zeros((1, 1, vocab_size), dtype=\"float32\"), dev)\n",
    "sch = tvm.tir.Schedule(ModuleSrc)\n",
    "new_mod = sch.mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = auto_scheduler.SearchTask(func=sch.mod['fused_fused_decode11_fused_matmul5_cast2'], args=sch.mod['fused_fused_decode11_fused_matmul5_cast2'].params, target=target)\n",
    "\n",
    "# tune_option = auto_scheduler.TuningOptions(\n",
    "#     num_measure_trials=10,\n",
    "#     measure_callbacks=[auto_scheduler.RecordToFile(log_file)],\n",
    "#     verbose=2,\n",
    "# )\n",
    "\n",
    "\n",
    "database = ms.tune_tir(\n",
    "    mod=new_mod,\n",
    "    target=target,\n",
    "    max_trials_global=64,\n",
    "    num_trials_per_iter=64,\n",
    "    work_dir=\"./tune_45593_1\",\n",
    "    cost_model=\"xgb\"\n",
    ")\n",
    "print(len(database))\n",
    "sch1 = ms.tir_integration.compile_tir(database, new_mod, target)\n",
    "print(type(sch1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sch1.trace)\n",
    "# print(sch1.mod.script())\n",
    "rt_mod = tvm.build(sch1.mod, target=\"cuda\")\n",
    "\n",
    "evaluator = rt_mod.time_evaluator(\"main\", dev, number=100)\n",
    "\n",
    "print(\"evaluator GEMV-Blocking: %f GFLOPS\" % (1228406784 / evaluator(W_nd, S_nd, Input_nd, Output_nd).mean / 1e9))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "record_database = ms.Database.create(kind='json', work_dir='./tune_45593_1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_sch = ms.tir_integration.compile_tir(record_database, new_mod, target)\n",
    "\n",
    "record_rt_mod = tvm.build(record_sch.mod, target=\"cuda\")\n",
    "\n",
    "record_evaluator = record_rt_mod.time_evaluator(\"main\", dev, number=20)\n",
    "\n",
    "print(\"evaluator GEMV-Blocking: %f GFLOPS\" % (num_flop / record_evaluator(W_nd, S_nd, Input_nd, Output_nd).mean / 1e9))\n",
    "print(record_sch.trace)\n",
    "print(record_sch.mod.script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TYPE_CHECKING, Dict, List, Optional, Union, Callable\n",
    "from tvm import runtime\n",
    "if TYPE_CHECKING:\n",
    "    import numpy as np  # type: ignore\n",
    "    from tvm.ir import IRModule\n",
    "    from tvm.meta_schedule.runner import EvaluatorConfig, RPCConfig\n",
    "    from tvm.runtime import Device, Module, NDArray\n",
    "    from tvm.target import Target\n",
    "    from tvm.runtime.vm import Executable\n",
    "\n",
    "\n",
    "def f_measurement(\n",
    "    rt_mod: runtime.Module, device: runtime.ndarray.Device, input_data: Dict[str, runtime.NDArray]\n",
    "):\n",
    "    vm = relax.VirtualMachine(rt_mod, device=device)\n",
    "    vm.save_function(\"main\", \"measure_func\", **input_data, include_return=False)\n",
    "    evaluator = vm.time_evaluator(\n",
    "        func_name=\"measure_func\",\n",
    "        dev=device,\n",
    "        repeat=100,\n",
    "        number=1,\n",
    "        min_repeat_ms=500,\n",
    "    )\n",
    "    return evaluator()\n",
    "\n",
    "def run_module_via_rpc(\n",
    "    rpc_config: \"RPCConfig\",\n",
    "    lib: Union[\"Module\", \"Executable\"],\n",
    "    dev_type: str,\n",
    "    args: Union[Dict[int, \"np.ndarray\"], Dict[str, \"np.ndarray\"]],\n",
    "    continuation: Callable,\n",
    "    backend: Optional[str] = \"graph\",\n",
    "):\n",
    "    \"\"\"Execute a tvm.runtime.Module on RPC remote\"\"\"\n",
    "    # pylint: disable=import-outside-toplevel\n",
    "    import os\n",
    "    import tempfile\n",
    "\n",
    "    from tvm.contrib.tar import tar\n",
    "    from tvm.runtime import ndarray\n",
    "\n",
    "    # pylint: enable=import-outside-toplevel\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        # filename = os.path.join(tmp_dir, \"tvm_tmp_mod.\" + tar.output_format)\n",
    "        filename = os.path.join(tmp_dir, \"tvm_tmp_mod.\" + \"so\")\n",
    "        if backend == \"vm\":\n",
    "            code, lib = lib.save(filename, fmt=\"so\")\n",
    "        from tvm.contrib import ndk\n",
    "        lib.export_library(filename, ndk.create_shared)\n",
    "        session = rpc_config.connect_server()\n",
    "        print(type(session._sess))\n",
    "        session.upload(filename)\n",
    "        _, filename = os.path.split(filename)\n",
    "        rt_mod = session.load_module(filename)\n",
    "        \n",
    "        if backend == \"vm\":\n",
    "            rt_mod = session.get_function(\"runtime.Load_Executable\")(code, rt_mod)\n",
    "            # rt_mod = session.get_function(\"runtime.module.loadfile_relax.Executable\")(filename)\n",
    "        dev = session.device(dev_type=dev_type, dev_id=0)\n",
    "        # print(dev)\n",
    "        # create the remote runtime module\n",
    "        print(rt_mod)\n",
    "        print(rt_mod['main'])\n",
    "        from tvm.contrib import graph_executor as runtime\n",
    "        module = runtime.GraphModule(rt_mod[\"main\"](dev))\n",
    "        print(module)\n",
    "        for k, v in args.items():\n",
    "            module.set_input(k, tvm.nd.array(v))\n",
    "        return module.run()\n",
    "        # nd_args = {k: ndarray.array(v, dev) for k, v in args.items()}\n",
    "        nd_args = {k: ndarray.empty(v.shape, v.dtype, dev) for k, v in args.items()}\n",
    "        return continuation(rt_mod, dev, nd_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlc-chat-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
