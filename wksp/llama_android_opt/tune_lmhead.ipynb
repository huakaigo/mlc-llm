{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm.script import ir as I\n",
    "from tvm.script import tir as T\n",
    "import os\n",
    "from tvm import autotvm, auto_scheduler\n",
    "from tvm.autotvm.tuner import XGBTuner, GATuner, RandomTuner, GridSearchTuner\n",
    "from tvm import meta_schedule as ms\n",
    "from tvm.ir import IRModule\n",
    "from tvm import relax\n",
    "vocab_size = 49984\n",
    "@I.ir_module\n",
    "class ModuleSrc:\n",
    "    @T.prim_func\n",
    "    def main(lv1323: T.Buffer((T.int64(512), T.int64(vocab_size)), \"uint32\"), lv1324: T.Buffer((T.int64(128), T.int64(vocab_size)), \"float16\"), lv1607: T.Buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\"), p_output0_intermediate: T.Buffer((T.int64(1), T.int64(1), T.int64(vocab_size)), \"float32\")):\n",
    "        T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": T.bool(True)})\n",
    "        # with T.block(\"root\"):\n",
    "        p_output0_intermediate_1 = T.alloc_buffer((T.int64(4096), T.int64(vocab_size)), \"float16\")\n",
    "        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(vocab_size)), \"float16\")\n",
    "        for i, j in T.grid(T.int64(4096), T.int64(vocab_size)):\n",
    "            with T.block(\"decode\"):\n",
    "                v_i, v_j = T.axis.remap(\"SS\", [i, j])\n",
    "                T.reads(lv1323[v_i // T.int64(8), v_j], lv1324[v_i // T.int64(32), v_j])\n",
    "                T.writes(p_output0_intermediate_1[v_i, v_j])\n",
    "                p_output0_intermediate_1[v_i, v_j] = (T.Cast(\"float16\", T.bitwise_and(T.shift_right(lv1323[v_i // T.int64(8), v_j], T.Cast(\"uint32\", v_i % T.int64(8)) * T.uint32(4)), T.uint32(15))) - T.float16(7)) * lv1324[v_i // T.int64(32), v_j]\n",
    "        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(1), T.int64(vocab_size), T.int64(4096)):\n",
    "            with T.block(\"matmul\"):\n",
    "                v_i0, v_i1, v_i2, v_k = T.axis.remap(\"SSSR\", [i0, i1, i2, k])\n",
    "                T.reads(lv1607[v_i0, v_i1, v_k], p_output0_intermediate_1[v_k, v_i2])\n",
    "                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])\n",
    "                with T.init():\n",
    "                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float16(0)\n",
    "                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv1607[v_i0, v_i1, v_k] * p_output0_intermediate_1[v_k, v_i2]\n",
    "        for i0, i1, i2 in T.grid(T.int64(1), T.int64(1), T.int64(vocab_size)):\n",
    "            with T.block(\"compute\"):\n",
    "                v_i0, v_i1, v_i2 = T.axis.remap(\"SSS\", [i0, i1, i2])\n",
    "                T.reads(var_matmul_intermediate[v_i0, v_i1, v_i2])\n",
    "                T.writes(p_output0_intermediate[v_i0, v_i1, v_i2])\n",
    "                p_output0_intermediate[v_i0, v_i1, v_i2] = T.Cast(\"float32\", var_matmul_intermediate[v_i0, v_i1, v_i2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "target = tvm.target.Target(\"opencl -device=adreno\", host=\"llvm -mtriple=aarch64-linux-gnu\")\n",
    "device_key=\"android\"\n",
    "rpc_host = \"10.158.176.30\"\n",
    "rpc_port = 5001\n",
    "# remote = autotvm.measure.request_remote(device_key, \"10.158.176.30\", 5001, timeout=10000)\n",
    "# dev = remote.device(str(target), 0)\n",
    "\n",
    "# num_flop = 1228406784\n",
    "# W_np = np.random.uniform(size=(512, vocab_size)).astype(\"uint32\")\n",
    "# S_np = np.random.uniform(size=(128, vocab_size)).astype(\"float16\")\n",
    "# Input_np = np.random.uniform(size=(1, 1, 4096)).astype(\"float16\")\n",
    "# # Output_np = np.random.uniform(size=(1, 1, 4096)).astype(\"float16\")\n",
    "# W_nd = tvm.nd.array(W_np, dev)\n",
    "# S_nd = tvm.nd.array(S_np, dev)\n",
    "# Input_nd = tvm.nd.array(Input_np, dev)\n",
    "# Output_nd = tvm.nd.array(np.zeros((1, 1, vocab_size), dtype=\"float32\"), dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====-==-=-=-=-==\n",
      "====-==-=-=-=-==\n",
      "====-==-=-=-=-==\n",
      "2023-08-02 09:07:53 [INFO] Logging directory: ./tune_first/logs\n"
     ]
    },
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  7: 0xffffffffffffffff\n  6: 0x00000000005b7412\n  5: __libc_start_main\n  4: ffi_call\n  3: tvm::meta_schedule::TuneContextNode::Initialize()\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/meta_schedule/tune_context.cc:58\n  2: tvm::meta_schedule::PostOrderApplyNode::InitializeWithTuneContext(tvm::meta_schedule::TuneContext const&)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/meta_schedule/space_generator/post_order_apply.cc:44\n  1: tvm::meta_schedule::SpaceGeneratorNode::InitializeWithTuneContext(tvm::meta_schedule::TuneContext const&)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/meta_schedule/space_generator/space_generator.cc:91\n  0: tvm::meta_schedule::GetRuleKindFromTarget(tvm::Target const&)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/meta_schedule/space_generator/space_generator.cc:82\n  File \"/data/workspace/llm/github/new_wksp/tvm-unity/src/meta_schedule/space_generator/space_generator.cc\", line 82\nTVMError: Unsupported target: opencl -keys=adreno,opencl,gpu -device=adreno -max_num_threads=256 -max_shared_memory_per_block=16384 -max_threads_per_block=256 -texture_spatial_limit=16384 -thread_warp_size=1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m# ms.builder.LocalBuilder()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m sch \u001b[39m=\u001b[39m tvm\u001b[39m.\u001b[39mtir\u001b[39m.\u001b[39mSchedule(ModuleSrc)\n\u001b[0;32m----> 5\u001b[0m database \u001b[39m=\u001b[39m ms\u001b[39m.\u001b[39mtune_tir(\n\u001b[1;32m      6\u001b[0m     mod\u001b[39m=\u001b[39mModuleSrc,\n\u001b[1;32m      7\u001b[0m     target\u001b[39m=\u001b[39mtarget,\n\u001b[1;32m      8\u001b[0m     max_trials_global\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m,\n\u001b[1;32m      9\u001b[0m     num_trials_per_iter\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m,\n\u001b[1;32m     10\u001b[0m     work_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./tune_first\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     cost_model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mxgb\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     runner \u001b[39m=\u001b[39m runner\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(database))\n\u001b[1;32m     15\u001b[0m sch1 \u001b[39m=\u001b[39m ms\u001b[39m.\u001b[39mtir_integration\u001b[39m.\u001b[39mcompile_tir(database, sch\u001b[39m.\u001b[39mmod, target)\n",
      "File \u001b[0;32m/data/workspace/llm/github/new_wksp/tvm-unity/python/tvm/meta_schedule/tir_integration.py:137\u001b[0m, in \u001b[0;36mtune_tir\u001b[0;34m(mod, target, work_dir, max_trials_global, max_trials_per_task, num_trials_per_iter, builder, runner, database, cost_model, measure_callbacks, task_scheduler, space, strategy, num_tuning_cores, seed, module_equality, special_space)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m task_space \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     tasks\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 137\u001b[0m         TuneContext(\n\u001b[1;32m    138\u001b[0m             mod\u001b[39m=\u001b[39mtask_func,\n\u001b[1;32m    139\u001b[0m             target\u001b[39m=\u001b[39mtarget,\n\u001b[1;32m    140\u001b[0m             space_generator\u001b[39m=\u001b[39mtask_space,\n\u001b[1;32m    141\u001b[0m             search_strategy\u001b[39m=\u001b[39mstrategy,\n\u001b[1;32m    142\u001b[0m             task_name\u001b[39m=\u001b[39mtask_name,\n\u001b[1;32m    143\u001b[0m             rand_state\u001b[39m=\u001b[39mrand_state,\n\u001b[1;32m    144\u001b[0m             num_threads\u001b[39m=\u001b[39mnum_tuning_cores,\n\u001b[1;32m    145\u001b[0m             logger\u001b[39m=\u001b[39mlogger,\n\u001b[1;32m    146\u001b[0m         )\u001b[39m.\u001b[39mclone()\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    148\u001b[0m \u001b[39mreturn\u001b[39;00m tune_tasks(\n\u001b[1;32m    149\u001b[0m     tasks\u001b[39m=\u001b[39mtasks,\n\u001b[1;32m    150\u001b[0m     task_weights\u001b[39m=\u001b[39m[\u001b[39m1.0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(tasks),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m     module_equality\u001b[39m=\u001b[39mmodule_equality,\n\u001b[1;32m    162\u001b[0m )\n",
      "File \u001b[0;32m/data/workspace/llm/github/new_wksp/tvm-unity/python/tvm/meta_schedule/tune_context.py:149\u001b[0m, in \u001b[0;36mTuneContext.__init__\u001b[0;34m(self, mod, target, space_generator, search_strategy, task_name, rand_state, num_threads, logger)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    135\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid num_threads: \u001b[39m\u001b[39m{\u001b[39;00mnum_threads\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mshould be either an integer, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mphysical\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlogical\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         )\n\u001b[1;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__init_handle_by_constructor__(\n\u001b[1;32m    139\u001b[0m     _ffi_api\u001b[39m.\u001b[39mTuneContext,  \u001b[39m# type: ignore # pylint: disable=no-member\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     mod,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m     get_logging_func(logger),\n\u001b[1;32m    148\u001b[0m )\n\u001b[0;32m--> 149\u001b[0m _ffi_api\u001b[39m.\u001b[39mTuneContextInitialize(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m/data/workspace/llm/github/new_wksp/tvm-unity/python/tvm/_ffi/_ctypes/packed_func.py:238\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    226\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    228\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    229\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    237\u001b[0m ):\n\u001b[0;32m--> 238\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    239\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    240\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  7: 0xffffffffffffffff\n  6: 0x00000000005b7412\n  5: __libc_start_main\n  4: ffi_call\n  3: tvm::meta_schedule::TuneContextNode::Initialize()\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/meta_schedule/tune_context.cc:58\n  2: tvm::meta_schedule::PostOrderApplyNode::InitializeWithTuneContext(tvm::meta_schedule::TuneContext const&)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/meta_schedule/space_generator/post_order_apply.cc:44\n  1: tvm::meta_schedule::SpaceGeneratorNode::InitializeWithTuneContext(tvm::meta_schedule::TuneContext const&)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/meta_schedule/space_generator/space_generator.cc:91\n  0: tvm::meta_schedule::GetRuleKindFromTarget(tvm::Target const&)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/meta_schedule/space_generator/space_generator.cc:82\n  File \"/data/workspace/llm/github/new_wksp/tvm-unity/src/meta_schedule/space_generator/space_generator.cc\", line 82\nTVMError: Unsupported target: opencl -keys=adreno,opencl,gpu -device=adreno -max_num_threads=256 -max_shared_memory_per_block=16384 -max_threads_per_block=256 -texture_spatial_limit=16384 -thread_warp_size=1"
     ]
    }
   ],
   "source": [
    "rpc_config = ms.runner.RPCConfig(tracker_host=rpc_host, tracker_port=rpc_port, tracker_key = device_key)\n",
    "runner= ms.runner.RPCRunner(rpc_config)\n",
    "# ms.builder.LocalBuilder()\n",
    "sch = tvm.tir.Schedule(ModuleSrc)\n",
    "database = ms.tune_tir(\n",
    "    mod=ModuleSrc,\n",
    "    target=target,\n",
    "    max_trials_global=64,\n",
    "    num_trials_per_iter=64,\n",
    "    work_dir=\"./tune_first\",\n",
    "    cost_model=\"xgb\",\n",
    "    runner = runner\n",
    ")\n",
    "print(len(database))\n",
    "sch1 = ms.tir_integration.compile_tir(database, sch.mod, target)\n",
    "print(type(sch1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.script import relax as R\n",
    "@I.ir_module\n",
    "class Module:\n",
    "    @R.function\n",
    "    def main(A: R.Tensor((3, 4), dtype=\"float32\"), B: R.Tensor((4, 5), dtype=\"float32\")):\n",
    "        with R.dataflow():\n",
    "            lv: R.Tensor((3, 5), dtype=\"float32\") = R.matmul(A, B)\n",
    "            gv: R.Tensor((3, 5), dtype=\"float32\") = lv\n",
    "            R.output(gv)\n",
    "        return gv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "## auto_scheduler test\n",
    "from tvm import auto_scheduler\n",
    "import numpy as np\n",
    "a_np = np.random.rand(3, 4).astype(\"float32\")\n",
    "b_np = np.random.rand(4, 5).astype(\"float32\")\n",
    "a_nd = tvm.runtime.NDArray(a_np)\n",
    "b_nd = tvm.runtime.NDArray(b_np)\n",
    "sch = tvm.tir.Schedule(Module)\n",
    "\n",
    "params = {\"A\": a_np, \"B\": b_np}\n",
    "## 报错，这里只支持relay\n",
    "# tasks = auto_scheduler.extract_tasks(sch.mod, params, target=target)\n",
    "tasks = ms.relax_integration.extract_tasks(sch.mod, target=target, params=params)\n",
    "print(len(tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TVMError",
     "evalue": "Task extraction had the following errors:\nTraceback (most recent call last):\n  File \"/data/workspace/llm/github/new_wksp/tvm-unity/python/tvm/auto_scheduler/relay_integration.py\", line 71, in call_all_topi_funcs\n    compiler.lower(mod, target)\n  File \"/data/workspace/llm/github/new_wksp/tvm-unity/python/tvm/relay/backend/vm.py\", line 126, in lower\n    self._lower(mod, raw_targets)\n  File \"/data/workspace/llm/github/new_wksp/tvm-unity/python/tvm/_ffi/_ctypes/packed_func.py\", line 238, in __call__\n    raise get_last_ffi_error()\ntvm.error.InternalError: Traceback (most recent call last):\n  12: 0xffffffffffffffff\n  11: clone\n  10: start_thread\n        at /build/glibc-S7Ft5T/glibc-2.23/nptl/pthread_create.c:333\n  9: ffi_call\n  8: operator()\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/backend/vm/compiler.cc:834\n  7: tvm::relay::vm::VMCompiler::Lower(tvm::IRModule, tvm::runtime::Array<tvm::Target, void> const&)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/backend/vm/compiler.cc:878\n  6: tvm::relay::vm::VMCompiler::LowerImpl(tvm::IRModule)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/backend/vm/compiler.cc:912\n  5: tvm::relay::vm::VMCompiler::OptimizeModuleImpl(tvm::IRModule)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/backend/vm/compiler.cc:1133\n  4: operator()\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/backend/vm/removed_unused_funcs.cc:128\n  3: tvm::relay::vm::RemoveUnusedFunctions(tvm::IRModule const&, tvm::runtime::Array<tvm::runtime::String, void>)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/backend/vm/removed_unused_funcs.cc:107\n  2: tvm::relay::vm::CallTracer::Trace(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/backend/vm/removed_unused_funcs.cc:91\n  1: tvm::relay::ExprVisitor::VisitExpr(tvm::RelayExpr const&)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/ir/expr_functor.cc:295\n  0: tvm::relay::ExprFunctor<void (tvm::RelayExpr const&)>::VisitExpr(tvm::RelayExpr const&)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/include/tvm/relay/expr_functor.h:95\n  File \"/data/workspace/llm/github/new_wksp/tvm-unity/include/tvm/node/functor.h\", line 95\nInternalError: Check failed: (can_dispatch(n)) is false: NodeFunctor calls un-registered function on type relax.expr.Function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmod_deploy\u001b[39;00m \u001b[39mimport\u001b[39;00m Module \u001b[39mas\u001b[39;00m ModuleAll\n\u001b[1;32m      2\u001b[0m params_all \u001b[39m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m tasks_all \u001b[39m=\u001b[39m auto_scheduler\u001b[39m.\u001b[39mextract_tasks(ModuleAll, params_all, target\u001b[39m=\u001b[39mtarget)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(tasks_all))\n",
      "File \u001b[0;32m/data/workspace/llm/github/new_wksp/tvm-unity/python/tvm/auto_scheduler/relay_integration.py:146\u001b[0m, in \u001b[0;36mextract_tasks\u001b[0;34m(mod, params, target, target_host, hardware_params, include_simple_tasks, dump_workload_to_dag_log, opt_level, other_targets)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m errors:\n\u001b[1;32m    145\u001b[0m     error_strings \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mTask extraction had the following errors:\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m errors\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mraise\u001b[39;00m TVMError(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_strings))\n\u001b[1;32m    148\u001b[0m dispatch_ctx\u001b[39m.\u001b[39mverbose \u001b[39m=\u001b[39m old_verbose\n\u001b[1;32m    150\u001b[0m \u001b[39m# create search tasks\u001b[39;00m\n",
      "\u001b[0;31mTVMError\u001b[0m: Task extraction had the following errors:\nTraceback (most recent call last):\n  File \"/data/workspace/llm/github/new_wksp/tvm-unity/python/tvm/auto_scheduler/relay_integration.py\", line 71, in call_all_topi_funcs\n    compiler.lower(mod, target)\n  File \"/data/workspace/llm/github/new_wksp/tvm-unity/python/tvm/relay/backend/vm.py\", line 126, in lower\n    self._lower(mod, raw_targets)\n  File \"/data/workspace/llm/github/new_wksp/tvm-unity/python/tvm/_ffi/_ctypes/packed_func.py\", line 238, in __call__\n    raise get_last_ffi_error()\ntvm.error.InternalError: Traceback (most recent call last):\n  12: 0xffffffffffffffff\n  11: clone\n  10: start_thread\n        at /build/glibc-S7Ft5T/glibc-2.23/nptl/pthread_create.c:333\n  9: ffi_call\n  8: operator()\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/backend/vm/compiler.cc:834\n  7: tvm::relay::vm::VMCompiler::Lower(tvm::IRModule, tvm::runtime::Array<tvm::Target, void> const&)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/backend/vm/compiler.cc:878\n  6: tvm::relay::vm::VMCompiler::LowerImpl(tvm::IRModule)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/backend/vm/compiler.cc:912\n  5: tvm::relay::vm::VMCompiler::OptimizeModuleImpl(tvm::IRModule)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/backend/vm/compiler.cc:1133\n  4: operator()\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/backend/vm/removed_unused_funcs.cc:128\n  3: tvm::relay::vm::RemoveUnusedFunctions(tvm::IRModule const&, tvm::runtime::Array<tvm::runtime::String, void>)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/backend/vm/removed_unused_funcs.cc:107\n  2: tvm::relay::vm::CallTracer::Trace(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/backend/vm/removed_unused_funcs.cc:91\n  1: tvm::relay::ExprVisitor::VisitExpr(tvm::RelayExpr const&)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/relay/ir/expr_functor.cc:295\n  0: tvm::relay::ExprFunctor<void (tvm::RelayExpr const&)>::VisitExpr(tvm::RelayExpr const&)\n        at /data/workspace/llm/github/new_wksp/tvm-unity/include/tvm/relay/expr_functor.h:95\n  File \"/data/workspace/llm/github/new_wksp/tvm-unity/include/tvm/node/functor.h\", line 95\nInternalError: Check failed: (can_dispatch(n)) is false: NodeFunctor calls un-registered function on type relax.expr.Function\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from mod_deploy import Module as ModuleAll\n",
    "params_all = {}\n",
    "tasks_all = auto_scheduler.extract_tasks(ModuleAll, params_all, target=target)\n",
    "print(len(tasks_all))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda -keys=cuda,gpu -arch=sm_61 -max_num_threads=1024 -max_shared_memory_per_block=49152 -max_threads_per_block=1024 -registers_per_block=65536 -thread_warp_size=32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "log_file = \"tune.json\"\n",
    "def _detect_local_cuda():\n",
    "    dev = tvm.cuda()\n",
    "    if not dev.exist:\n",
    "        return None\n",
    "    return tvm.target.Target(\n",
    "        {\n",
    "            \"kind\": \"cuda\",\n",
    "            \"max_shared_memory_per_block\": dev.max_shared_memory_per_block,\n",
    "            \"max_threads_per_block\": dev.max_threads_per_block,\n",
    "            \"thread_warp_size\": dev.warp_size,\n",
    "            \"registers_per_block\": 65536,\n",
    "            \"arch\": \"sm_\" + tvm.cuda().compute_version.replace(\".\", \"\"),\n",
    "        }\n",
    "    )\n",
    "# target = tvm.target.Target(\"cuda\", host=\"llvm\")\n",
    "target = _detect_local_cuda()\n",
    "\n",
    "print(target)\n",
    "# 定义计算任务\n",
    "dev = tvm.cuda(0)\n",
    "\n",
    "num_flop = 1228406784\n",
    "W_np = np.random.uniform(size=(512, vocab_size)).astype(\"uint32\")\n",
    "S_np = np.random.uniform(size=(128, vocab_size)).astype(\"float16\")\n",
    "Input_np = np.random.uniform(size=(1, 1, 4096)).astype(\"float16\")\n",
    "# Output_np = np.random.uniform(size=(1, 1, 4096)).astype(\"float16\")\n",
    "W_nd = tvm.nd.array(W_np, dev)\n",
    "S_nd = tvm.nd.array(S_np, dev)\n",
    "Input_nd = tvm.nd.array(Input_np, dev)\n",
    "Output_nd = tvm.nd.array(np.zeros((1, 1, vocab_size), dtype=\"float32\"), dev)\n",
    "sch = tvm.tir.Schedule(ModuleSrc)\n",
    "new_mod = sch.mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====-==-=-=-=-==\n",
      "====-==-=-=-=-==\n",
      "====-==-=-=-=-==\n",
      "2023-08-01 15:46:14 [INFO] Logging directory: ./tune_45593_1/logs\n",
      "2023-08-01 15:46:14 [INFO] LocalBuilder: max_workers = 4\n",
      "2023-08-01 15:46:14 [INFO] LocalRunner: max_workers = 1\n",
      "2023-08-01 15:46:17 [INFO] [task_scheduler.cc:159] Initializing Task #0: \"main\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main</td>\n",
       "      <td>1228406784</td>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0   main    1228406784         1               N/A             N/A    \n",
       "\n",
       "    Weighted Latency (us)    Trials    Done   \n",
       "0                     N/A         0           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total trials: 0\n",
      "Total latency (us): 0\n",
      "\n",
      "2023-08-01 15:46:17 [DEBUG] [task_scheduler.cc:318] \n",
      " ID | Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 1228406784 |      1 |            N/A |          N/A |                   N/A |      0 |      \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Total trials: 0\n",
      "Total latency (us): 0\n",
      "\n",
      "2023-08-01 15:46:17 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: \"main\"\n",
      "2023-08-01 15:46:37 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder\n",
      "2023-08-01 15:46:48 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner\n",
      "2023-08-01 15:47:31 [DEBUG] XGB iter   0: tr-p-rmse: 0.384314\ttr-a-peak@32: 0.959011\ttr-rmse: 0.550808\ttr-rmse: 0.550808\n",
      "2023-08-01 15:47:31 [DEBUG] XGB iter  25: tr-p-rmse: 0.081095\ttr-a-peak@32: 0.999847\ttr-rmse: 0.599649\ttr-rmse: 0.599649\n",
      "2023-08-01 15:47:32 [DEBUG] XGB iter  50: tr-p-rmse: 0.081095\ttr-a-peak@32: 0.999847\ttr-rmse: 0.599649\ttr-rmse: 0.599649\n",
      "2023-08-01 15:47:32 [DEBUG] XGB stopped. Best iteration: [16] tr-p-rmse:0.08064\ttr-a-peak@32:0.99985\ttr-rmse:0.59968\ttr-rmse:0.59968 \n",
      "2023-08-01 15:47:32 [INFO] [task_scheduler.cc:237] [Updated] Task #0: \"main\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main</td>\n",
       "      <td>1228406784</td>\n",
       "      <td>1</td>\n",
       "      <td>63.7432</td>\n",
       "      <td>19271.1677</td>\n",
       "      <td>19271.1677</td>\n",
       "      <td>64</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0   main    1228406784         1           63.7432      19271.1677    \n",
       "\n",
       "    Weighted Latency (us)    Trials    Done   \n",
       "0              19271.1677        64           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-01 15:47:32 [DEBUG] [task_scheduler.cc:318] \n",
      " ID | Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 1228406784 |      1 |        63.7432 |   19271.1677 |            19271.1677 |     64 |      \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Total trials: 64\n",
      "Total latency (us): 19271.2\n",
      "\n",
      "\n",
      "Total trials: 64\n",
      "Total latency (us): 19271.2\n",
      "\n",
      "2023-08-01 15:47:32 [INFO] [task_scheduler.cc:260] Task #0 has finished. Remaining task(s): 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>FLOP</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Speed (GFLOPS)</th>\n",
       "      <th>Latency (us)</th>\n",
       "      <th>Weighted Latency (us)</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main</td>\n",
       "      <td>1228406784</td>\n",
       "      <td>1</td>\n",
       "      <td>63.7432</td>\n",
       "      <td>19271.1677</td>\n",
       "      <td>19271.1677</td>\n",
       "      <td>64</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name          FLOP    Weight    Speed (GFLOPS)    Latency (us)   \\\n",
       "0   main    1228406784         1           63.7432      19271.1677    \n",
       "\n",
       "    Weighted Latency (us)    Trials    Done   \n",
       "0              19271.1677        64       Y   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-01 15:47:32 [DEBUG] [task_scheduler.cc:318] \n",
      " ID | Name |       FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "  0 | main | 1228406784 |      1 |        63.7432 |   19271.1677 |            19271.1677 |     64 |    Y \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "Total trials: 64\n",
      "Total latency (us): 19271.2\n",
      "\n",
      "\n",
      "Total trials: 64\n",
      "Total latency (us): 19271.2\n",
      "\n",
      "1598\n",
      "<class 'tvm.tir.schedule.schedule.Schedule'>\n"
     ]
    }
   ],
   "source": [
    "# task = auto_scheduler.SearchTask(func=sch.mod['fused_fused_decode11_fused_matmul5_cast2'], args=sch.mod['fused_fused_decode11_fused_matmul5_cast2'].params, target=target)\n",
    "\n",
    "# tune_option = auto_scheduler.TuningOptions(\n",
    "#     num_measure_trials=10,\n",
    "#     measure_callbacks=[auto_scheduler.RecordToFile(log_file)],\n",
    "#     verbose=2,\n",
    "# )\n",
    "\n",
    "\n",
    "database = ms.tune_tir(\n",
    "    mod=new_mod,\n",
    "    target=target,\n",
    "    max_trials_global=64,\n",
    "    num_trials_per_iter=64,\n",
    "    work_dir=\"./tune_45593_1\",\n",
    "    cost_model=\"xgb\"\n",
    ")\n",
    "print(len(database))\n",
    "sch1 = ms.tir_integration.compile_tir(database, new_mod, target)\n",
    "print(type(sch1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator GEMV-Blocking: 62.644059 GFLOPS\n"
     ]
    }
   ],
   "source": [
    "# print(sch1.trace)\n",
    "# print(sch1.mod.script())\n",
    "rt_mod = tvm.build(sch1.mod, target=\"cuda\")\n",
    "\n",
    "evaluator = rt_mod.time_evaluator(\"main\", dev, number=100)\n",
    "\n",
    "print(\"evaluator GEMV-Blocking: %f GFLOPS\" % (1228406784 / evaluator(W_nd, S_nd, Input_nd, Output_nd).mean / 1e9))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "record_database = ms.Database.create(kind='json', work_dir='./tune_45593_1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluator GEMV-Blocking: 56.786827 GFLOPS\n",
      "# from tvm import tir\n",
      "def apply_trace(sch: tir.Schedule) -> None:\n",
      "  b0 = sch.get_block(name=\"decode\", func_name=\"main\")\n",
      "  b1 = sch.get_block(name=\"matmul\", func_name=\"main\")\n",
      "  b2 = sch.get_block(name=\"compute\", func_name=\"main\")\n",
      "  b3 = sch.get_block(name=\"root\", func_name=\"main\")\n",
      "  sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.tiling_structure\", ann_val=\"SSSRRSRS\")\n",
      "  l4, l5, l6, l7 = sch.get_loops(block=b1)\n",
      "  v8, v9, v10, v11, v12 = sch.sample_perfect_tile(loop=l4, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])\n",
      "  l13, l14, l15, l16, l17 = sch.split(loop=l4, factors=[v8, v9, v10, v11, v12], preserve_unit_iters=True)\n",
      "  v18, v19, v20, v21, v22 = sch.sample_perfect_tile(loop=l5, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])\n",
      "  l23, l24, l25, l26, l27 = sch.split(loop=l5, factors=[v18, v19, v20, v21, v22], preserve_unit_iters=True)\n",
      "  v28, v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[781, 2, 32, 1, 1])\n",
      "  l33, l34, l35, l36, l37 = sch.split(loop=l6, factors=[v28, v29, v30, v31, v32], preserve_unit_iters=True)\n",
      "  v38, v39, v40 = sch.sample_perfect_tile(loop=l7, n=3, max_innermost_factor=64, decision=[128, 2, 16])\n",
      "  l41, l42, l43 = sch.split(loop=l7, factors=[v38, v39, v40], preserve_unit_iters=True)\n",
      "  sch.reorder(l13, l23, l33, l14, l24, l34, l15, l25, l35, l41, l42, l16, l26, l36, l43, l17, l27, l37)\n",
      "  l44 = sch.fuse(l13, l23, l33, preserve_unit_iters=True)\n",
      "  sch.bind(loop=l44, thread_axis=\"blockIdx.x\")\n",
      "  l45 = sch.fuse(l14, l24, l34, preserve_unit_iters=True)\n",
      "  sch.bind(loop=l45, thread_axis=\"vthread.x\")\n",
      "  l46 = sch.fuse(l15, l25, l35, preserve_unit_iters=True)\n",
      "  sch.bind(loop=l46, thread_axis=\"threadIdx.x\")\n",
      "  sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.thread_extent_low_inclusive\", ann_val=32)\n",
      "  sch.annotate(block_or_loop=b1, ann_key=\"meta_schedule.thread_extent_high_inclusive\", ann_val=1024)\n",
      "  b47 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope=\"local\")\n",
      "  sch.reverse_compute_at(block=b47, loop=l46, preserve_unit_loops=True, index=-1)\n",
      "  b48 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope=\"shared\", consumer_blocks=[b1])\n",
      "  sch.compute_at(block=b48, loop=l41, preserve_unit_loops=True, index=-1)\n",
      "  l49, l50, l51, l52, l53, l54, l55 = sch.get_loops(block=b48)\n",
      "  l56 = sch.fuse(l53, l54, l55, preserve_unit_iters=True)\n",
      "  v57 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=1)\n",
      "  sch.annotate(block_or_loop=b48, ann_key=\"meta_schedule.cooperative_fetch\", ann_val=v57)\n",
      "  b58 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope=\"shared\", consumer_blocks=[b1])\n",
      "  sch.compute_at(block=b58, loop=l41, preserve_unit_loops=True, index=-1)\n",
      "  l59, l60, l61, l62, l63, l64 = sch.get_loops(block=b58)\n",
      "  l65 = sch.fuse(l63, l64, preserve_unit_iters=True)\n",
      "  v66 = sch.sample_categorical(candidates=[1, 2, 4, 8], probs=[0.25, 0.25, 0.25, 0.25], decision=1)\n",
      "  sch.annotate(block_or_loop=b58, ann_key=\"meta_schedule.cooperative_fetch\", ann_val=v66)\n",
      "  sch.reverse_compute_inline(block=b2)\n",
      "  sch.compute_inline(block=b0)\n",
      "  v67 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)\n",
      "  sch.annotate(block_or_loop=b3, ann_key=\"meta_schedule.unroll_explicit\", ann_val=v67)\n",
      "  sch.enter_postproc()\n",
      "  sch.unannotate(block_or_loop=b48, ann_key=\"meta_schedule.cooperative_fetch\")\n",
      "  l68, l69, l70, l71, l72 = sch.get_loops(block=b48)\n",
      "  l73, l74, l75 = sch.split(loop=l72, factors=[None, 32, 2], preserve_unit_iters=True)\n",
      "  sch.vectorize(loop=l75)\n",
      "  sch.bind(loop=l74, thread_axis=\"threadIdx.x\")\n",
      "  sch.unannotate(block_or_loop=b58, ann_key=\"meta_schedule.cooperative_fetch\")\n",
      "  l76, l77, l78, l79, l80 = sch.get_loops(block=b58)\n",
      "  l81, l82, l83 = sch.split(loop=l80, factors=[None, 32, 2], preserve_unit_iters=True)\n",
      "  sch.vectorize(loop=l83)\n",
      "  sch.bind(loop=l82, thread_axis=\"threadIdx.x\")\n",
      "  b84 = sch.get_block(name=\"root\", func_name=\"main\")\n",
      "  sch.unannotate(block_or_loop=b84, ann_key=\"meta_schedule.unroll_explicit\")\n",
      "  b85, b86, b87, b88 = sch.get_child_blocks(b84)\n",
      "  l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b85)\n",
      "  l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b86)\n",
      "  l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b87)\n",
      "  sch.annotate(block_or_loop=l103, ann_key=\"pragma_auto_unroll_max_step\", ann_val=1024)\n",
      "  sch.annotate(block_or_loop=l103, ann_key=\"pragma_unroll_explicit\", ann_val=1)\n",
      "  l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b88)\n",
      "  b121 = sch.get_block(name=\"matmul\", func_name=\"main\")\n",
      "  l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b121)\n",
      "  b134 = sch.decompose_reduction(block=b121, loop=l125)\n",
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(lv1323: T.Buffer((T.int64(512), T.int64(49984)), \"uint32\"), lv1324: T.Buffer((T.int64(128), T.int64(49984)), \"float16\"), lv1607: T.Buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\"), p_output0_intermediate: T.Buffer((T.int64(1), T.int64(1), T.int64(49984)), \"float32\")):\n",
      "        T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": T.bool(True)})\n",
      "        # with T.block(\"root\"):\n",
      "        var_matmul_intermediate_local = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(49984)), \"float16\", scope=\"local\")\n",
      "        lv1607_shared = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\", scope=\"shared\")\n",
      "        p_output0_intermediate_1_shared = T.alloc_buffer((T.int64(4096), T.int64(49984)), \"float16\", scope=\"shared\")\n",
      "        for i0_0_i1_0_i2_0_fused in T.thread_binding(T.int64(781), thread=\"blockIdx.x\", annotations={\"pragma_auto_unroll_max_step\": T.int64(1024), \"pragma_unroll_explicit\": T.int64(1)}):\n",
      "            for i0_1_i1_1_i2_1_fused in T.thread_binding(T.int64(2), thread=\"vthread.x\"):\n",
      "                for i0_2_i1_2_i2_2_fused in T.thread_binding(T.int64(32), thread=\"threadIdx.x\"):\n",
      "                    for i0_3_init, i1_3_init, i2_3_init, i0_4_init, i1_4_init, i2_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):\n",
      "                        with T.block(\"matmul_init\"):\n",
      "                            v_i0 = T.axis.spatial(T.int64(1), i0_3_init + i0_4_init)\n",
      "                            v_i1 = T.axis.spatial(T.int64(1), i1_3_init + i1_4_init)\n",
      "                            v_i2 = T.axis.spatial(T.int64(49984), i0_0_i1_0_i2_0_fused * T.int64(64) + i0_1_i1_1_i2_1_fused * T.int64(32) + i0_2_i1_2_i2_2_fused + i2_3_init + i2_4_init)\n",
      "                            T.reads()\n",
      "                            T.writes(var_matmul_intermediate_local[v_i0, v_i1, v_i2])\n",
      "                            T.block_attr({\"meta_schedule.thread_extent_high_inclusive\": T.int64(1024), \"meta_schedule.thread_extent_low_inclusive\": T.int64(32), \"meta_schedule.tiling_structure\": \"SSSRRSRS\"})\n",
      "                            var_matmul_intermediate_local[v_i0, v_i1, v_i2] = T.float16(0)\n",
      "                    for k_0 in range(T.int64(128)):\n",
      "                        for ax0_ax1_ax2_fused_0 in range(T.int64(1)):\n",
      "                            for ax0_ax1_ax2_fused_1 in T.thread_binding(T.int64(32), thread=\"threadIdx.x\"):\n",
      "                                for ax0_ax1_ax2_fused_2 in T.vectorized(T.int64(2)):\n",
      "                                    with T.block(\"lv1607_shared\"):\n",
      "                                        v0 = T.axis.spatial(T.int64(1), T.int64(0))\n",
      "                                        v1 = T.axis.spatial(T.int64(1), T.int64(0))\n",
      "                                        v2 = T.axis.spatial(T.int64(4096), k_0 * T.int64(32) + (ax0_ax1_ax2_fused_0 * T.int64(64) + ax0_ax1_ax2_fused_1 * T.int64(2) + ax0_ax1_ax2_fused_2))\n",
      "                                        T.where((ax0_ax1_ax2_fused_0 * T.int64(32) + ax0_ax1_ax2_fused_1) * T.int64(2) + ax0_ax1_ax2_fused_2 < T.int64(32))\n",
      "                                        T.reads(lv1607[v0, v1, v2])\n",
      "                                        T.writes(lv1607_shared[v0, v1, v2])\n",
      "                                        lv1607_shared[v0, v1, v2] = lv1607[v0, v1, v2]\n",
      "                        for ax0_ax1_fused_0 in range(T.int64(32)):\n",
      "                            for ax0_ax1_fused_1 in T.thread_binding(T.int64(32), thread=\"threadIdx.x\"):\n",
      "                                for ax0_ax1_fused_2 in T.vectorized(T.int64(2)):\n",
      "                                    with T.block(\"p_output0_intermediate_1_shared\"):\n",
      "                                        v0 = T.axis.spatial(T.int64(4096), k_0 * T.int64(32) + (ax0_ax1_fused_0 * T.int64(64) + ax0_ax1_fused_1 * T.int64(2) + ax0_ax1_fused_2) // T.int64(64))\n",
      "                                        v1 = T.axis.spatial(T.int64(49984), i0_0_i1_0_i2_0_fused * T.int64(64) + (ax0_ax1_fused_0 * T.int64(64) + ax0_ax1_fused_1 * T.int64(2) + ax0_ax1_fused_2) % T.int64(64))\n",
      "                                        T.reads(lv1323[v0 // T.int64(8), v1], lv1324[v0 // T.int64(32), v1])\n",
      "                                        T.writes(p_output0_intermediate_1_shared[v0, v1])\n",
      "                                        p_output0_intermediate_1_shared[v0, v1] = (T.Cast(\"float16\", T.bitwise_and(T.shift_right(lv1323[v0 // T.int64(8), v1], T.Cast(\"uint32\", v0 % T.int64(8)) * T.uint32(4)), T.uint32(15))) - T.float16(7)) * lv1324[v0 // T.int64(32), v1]\n",
      "                        for k_1, i0_3, i1_3, i2_3, k_2, i0_4, i1_4, i2_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1)):\n",
      "                            with T.block(\"matmul_update\"):\n",
      "                                v_i0 = T.axis.spatial(T.int64(1), i0_3 + i0_4)\n",
      "                                v_i1 = T.axis.spatial(T.int64(1), i1_3 + i1_4)\n",
      "                                v_i2 = T.axis.spatial(T.int64(49984), i0_0_i1_0_i2_0_fused * T.int64(64) + i0_1_i1_1_i2_1_fused * T.int64(32) + i0_2_i1_2_i2_2_fused + i2_3 + i2_4)\n",
      "                                v_k = T.axis.reduce(T.int64(4096), k_0 * T.int64(32) + k_1 * T.int64(16) + k_2)\n",
      "                                T.reads(var_matmul_intermediate_local[v_i0, v_i1, v_i2], lv1607_shared[v_i0, v_i1, v_k], p_output0_intermediate_1_shared[v_k, v_i2])\n",
      "                                T.writes(var_matmul_intermediate_local[v_i0, v_i1, v_i2])\n",
      "                                T.block_attr({\"meta_schedule.thread_extent_high_inclusive\": T.int64(1024), \"meta_schedule.thread_extent_low_inclusive\": T.int64(32), \"meta_schedule.tiling_structure\": \"SSSRRSRS\"})\n",
      "                                var_matmul_intermediate_local[v_i0, v_i1, v_i2] = var_matmul_intermediate_local[v_i0, v_i1, v_i2] + lv1607_shared[v_i0, v_i1, v_k] * p_output0_intermediate_1_shared[v_k, v_i2]\n",
      "                    for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(1)):\n",
      "                        with T.block(\"var_matmul_intermediate_local\"):\n",
      "                            v0, v1 = T.axis.remap(\"SS\", [ax0, ax1])\n",
      "                            v2 = T.axis.spatial(T.int64(49984), i0_0_i1_0_i2_0_fused * T.int64(64) + i0_1_i1_1_i2_1_fused * T.int64(32) + i0_2_i1_2_i2_2_fused + ax2)\n",
      "                            T.reads(var_matmul_intermediate_local[v0, v1, v2])\n",
      "                            T.writes(p_output0_intermediate[v0, v1, v2])\n",
      "                            p_output0_intermediate[v0, v1, v2] = T.Cast(\"float32\", var_matmul_intermediate_local[v0, v1, v2])\n"
     ]
    }
   ],
   "source": [
    "record_sch = ms.tir_integration.compile_tir(record_database, new_mod, target)\n",
    "\n",
    "record_rt_mod = tvm.build(record_sch.mod, target=\"cuda\")\n",
    "\n",
    "record_evaluator = record_rt_mod.time_evaluator(\"main\", dev, number=20)\n",
    "\n",
    "print(\"evaluator GEMV-Blocking: %f GFLOPS\" % (num_flop / record_evaluator(W_nd, S_nd, Input_nd, Output_nd).mean / 1e9))\n",
    "print(record_sch.trace)\n",
    "print(record_sch.mod.script())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lm_head(32000, 4096) 原始优化性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  5: 0xffffffffffffffff\n  4: 0x00000000005b7412\n  3: __libc_start_main\n  2: ffi_call\n  1: operator()\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/runtime/profiling.cc:879\n  0: operator()\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/runtime/library_module.cc:90\n  File \"/data/workspace/llm/github/new_wksp/tvm-unity/src/runtime/library_module.cc\", line 87\nTVMError: Assert fail: T.Cast(\"int32\", main_lv1323_handle_shape[1]) == 32000, Argument main.lv1323_handle.shape[1] has an unsatisfied constraint: 32000 == T.Cast(\"int32\", main_lv1323_handle_shape[1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m rt_mod_opted \u001b[39m=\u001b[39m tvm\u001b[39m.\u001b[39mbuild(sch_opted\u001b[39m.\u001b[39mmod, target\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m evaluator_opted \u001b[39m=\u001b[39m rt_mod_opted\u001b[39m.\u001b[39mtime_evaluator(\u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m, dev, number\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mevaluator_opted GEMV-Blocking: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m GFLOPS\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (num_flop \u001b[39m/\u001b[39m evaluator_opted(W_nd, S_nd, Input_nd, Output_nd)\u001b[39m.\u001b[39mmean \u001b[39m/\u001b[39m \u001b[39m1e9\u001b[39m))\n",
      "File \u001b[0;32m/data/workspace/llm/github/new_wksp/tvm-unity/python/tvm/runtime/module.py:402\u001b[0m, in \u001b[0;36mModule.time_evaluator.<locals>.evaluator\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Internal wrapped evaluator.\"\"\"\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[39m# Wrap feval so we can add more stats in future.\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m blob \u001b[39m=\u001b[39m feval(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    403\u001b[0m fmt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m@\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39md\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m repeat)\n\u001b[1;32m    404\u001b[0m results \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(fmt, blob)\n",
      "File \u001b[0;32m/data/workspace/llm/github/new_wksp/tvm-unity/python/tvm/_ffi/_ctypes/packed_func.py:238\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    226\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    228\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    229\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    237\u001b[0m ):\n\u001b[0;32m--> 238\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    239\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    240\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  5: 0xffffffffffffffff\n  4: 0x00000000005b7412\n  3: __libc_start_main\n  2: ffi_call\n  1: operator()\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/runtime/profiling.cc:879\n  0: operator()\n        at /data/workspace/llm/github/new_wksp/tvm-unity/src/runtime/library_module.cc:90\n  File \"/data/workspace/llm/github/new_wksp/tvm-unity/src/runtime/library_module.cc\", line 87\nTVMError: Assert fail: T.Cast(\"int32\", main_lv1323_handle_shape[1]) == 32000, Argument main.lv1323_handle.shape[1] has an unsatisfied constraint: 32000 == T.Cast(\"int32\", main_lv1323_handle_shape[1])"
     ]
    }
   ],
   "source": [
    "@I.ir_module\n",
    "class ModuleOpted:\n",
    "    @T.prim_func\n",
    "    def main(lv1323: T.Buffer((512, 32000), \"uint32\"), lv1324: T.Buffer((128, 32000), \"float16\"), lv1607: T.Buffer((1, 1, 4096), \"float16\"), p_output0_intermediate: T.Buffer((1, 1, 32000), \"float32\")):\n",
    "        T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": T.bool(True)})\n",
    "        # with T.block(\"root\"):\n",
    "        var_matmul_intermediate_local = T.alloc_buffer((1, 1, 32000), \"float16\", scope=\"local\")\n",
    "        var_matmul_intermediate_rf_local = T.alloc_buffer((16, 1, 1, 32000), \"float16\", scope=\"local\")\n",
    "        for ax0_fused_0 in T.thread_binding(2000, thread=\"blockIdx.x\"):\n",
    "            for ax0_fused_1 in T.thread_binding(16, thread=\"threadIdx.x\"):\n",
    "                for ax1_0_fused_1 in T.thread_binding(16, thread=\"threadIdx.y\"):\n",
    "                    with T.block(\"matmul_rf_init\"):\n",
    "                        vax1_0_fused_1 = T.axis.spatial(16, ax1_0_fused_1)\n",
    "                        v0 = T.axis.spatial(32000, ax0_fused_0 * 16 + ax0_fused_1)\n",
    "                        T.reads()\n",
    "                        T.writes(var_matmul_intermediate_rf_local[vax1_0_fused_1, 0, 0, v0])\n",
    "                        var_matmul_intermediate_rf_local[vax1_0_fused_1, 0, 0, v0] = T.float16(0)\n",
    "                    for ax1_0_fused_0, ax1_1 in T.grid(32, 8):\n",
    "                        with T.block(\"matmul_rf_update\"):\n",
    "                            vax1_0_fused_1 = T.axis.spatial(16, ax1_0_fused_1)\n",
    "                            v0 = T.axis.spatial(32000, ax0_fused_0 * 16 + ax0_fused_1)\n",
    "                            vax1_0_fused_0, vax1_1 = T.axis.remap(\"RR\", [ax1_0_fused_0, ax1_1])\n",
    "                            T.reads(var_matmul_intermediate_rf_local[vax1_0_fused_1, 0, 0, v0], lv1607[0, 0, vax1_0_fused_0 * 128 + vax1_0_fused_1 * 8 + vax1_1], lv1323[(vax1_0_fused_0 * 128 + vax1_0_fused_1 * 8 + vax1_1) // 8, v0], lv1324[(vax1_0_fused_0 * 128 + vax1_0_fused_1 * 8 + vax1_1) // 32, v0])\n",
    "                            T.writes(var_matmul_intermediate_rf_local[vax1_0_fused_1, 0, 0, v0])\n",
    "                            var_matmul_intermediate_rf_local[vax1_0_fused_1, 0, 0, v0] = var_matmul_intermediate_rf_local[vax1_0_fused_1, 0, 0, v0] + lv1607[0, 0, vax1_0_fused_0 * 128 + vax1_0_fused_1 * 8 + vax1_1] * ((T.Cast(\"float16\", T.bitwise_and(T.shift_right(lv1323[(vax1_0_fused_0 * 128 + vax1_0_fused_1 * 8 + vax1_1) // 8, v0], T.Cast(\"uint32\", (vax1_0_fused_0 * 128 + vax1_0_fused_1 * 8 + vax1_1) % 8) * T.uint32(4)), T.uint32(15))) - T.float16(7)) * lv1324[(vax1_0_fused_0 * 128 + vax1_0_fused_1 * 8 + vax1_1) // 32, v0])\n",
    "            for ax1_fused in T.thread_binding(16, thread=\"threadIdx.x\"):\n",
    "                for ax0 in T.thread_binding(16, thread=\"threadIdx.y\"):\n",
    "                    with T.block(\"matmul\"):\n",
    "                        vax1_0_fused_1 = T.axis.reduce(16, ax0)\n",
    "                        v0 = T.axis.spatial(32000, ax0_fused_0 * 16 + ax1_fused)\n",
    "                        T.reads(var_matmul_intermediate_rf_local[vax1_0_fused_1, 0, 0, v0])\n",
    "                        T.writes(var_matmul_intermediate_local[0, 0, v0])\n",
    "                        with T.init():\n",
    "                            var_matmul_intermediate_local[0, 0, v0] = T.float16(0)\n",
    "                        var_matmul_intermediate_local[0, 0, v0] = var_matmul_intermediate_local[0, 0, v0] + var_matmul_intermediate_rf_local[vax1_0_fused_1, 0, 0, v0]\n",
    "            for ax0_fused in T.thread_binding(16, thread=\"threadIdx.x\"):\n",
    "                with T.block(\"compute\"):\n",
    "                    v0 = T.axis.spatial(32000, ax0_fused_0 * 16 + ax0_fused)\n",
    "                    T.reads(var_matmul_intermediate_local[0, 0, v0])\n",
    "                    T.writes(p_output0_intermediate[0, 0, v0])\n",
    "                    p_output0_intermediate[0, 0, v0] = T.Cast(\"float32\", var_matmul_intermediate_local[0, 0, v0])\n",
    "\n",
    "sch_opted = tvm.tir.Schedule(ModuleOpted)\n",
    "rt_mod_opted = tvm.build(sch_opted.mod, target=\"cuda\")\n",
    "evaluator_opted = rt_mod_opted.time_evaluator(\"main\", dev, number=20)\n",
    "\n",
    "print(\"evaluator_opted GEMV-Blocking: %f GFLOPS\" % (num_flop / evaluator_opted(W_nd, S_nd, Input_nd, Output_nd).mean / 1e9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda -keys=cuda,gpu -arch=sm_61 -max_num_threads=1024 -max_shared_memory_per_block=49152 -max_threads_per_block=1024 -registers_per_block=65536 -thread_warp_size=32\n",
      "evaluator_opted GEMV-Blocking: 32.723813 GFLOPS\n"
     ]
    }
   ],
   "source": [
    "## 未优化版本\n",
    "# vocab_size = vocab_size\n",
    "num_flop = 1228406784\n",
    "W_np = np.random.uniform(size=(512, vocab_size)).astype(\"uint32\")\n",
    "S_np = np.random.uniform(size=(128, vocab_size)).astype(\"float16\")\n",
    "Input_np = np.random.uniform(size=(1, 1, 4096)).astype(\"float16\")\n",
    "# Output_np = np.random.uniform(size=(1, 1, 4096)).astype(\"float16\")\n",
    "W_nd = tvm.nd.array(W_np, dev)\n",
    "S_nd = tvm.nd.array(S_np, dev)\n",
    "Input_nd = tvm.nd.array(Input_np, dev)\n",
    "Output_nd = tvm.nd.array(np.zeros((1, 1, vocab_size), dtype=\"float32\"), dev)\n",
    "@I.ir_module\n",
    "class ModuleUnOpt:\n",
    "    @T.prim_func\n",
    "    def main(lv1323: T.Buffer((T.int64(512), T.int64(vocab_size)), \"uint32\"), lv1324: T.Buffer((T.int64(128), T.int64(vocab_size)), \"float16\"), lv1607: T.Buffer((T.int64(1), T.int64(1), T.int64(4096)), \"float16\"), p_output0_intermediate: T.Buffer((T.int64(1), T.int64(1), T.int64(vocab_size)), \"float32\")):\n",
    "        T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
    "        # with T.block(\"root\"):\n",
    "        p_output0_intermediate_1 = T.alloc_buffer((T.int64(4096), T.int64(vocab_size)), \"float16\")\n",
    "        var_matmul_intermediate = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(vocab_size)), \"float16\")\n",
    "        for i, j in T.grid(T.int64(4096), T.int64(vocab_size)):\n",
    "            with T.block(\"decode\"):\n",
    "                v_i, v_j = T.axis.remap(\"SS\", [i, j])\n",
    "                T.reads(lv1323[v_i // T.int64(8), v_j], lv1324[v_i // T.int64(32), v_j])\n",
    "                T.writes(p_output0_intermediate_1[v_i, v_j])\n",
    "                p_output0_intermediate_1[v_i, v_j] = (T.Cast(\"float16\", T.bitwise_and(T.shift_right(lv1323[v_i // T.int64(8), v_j], T.Cast(\"uint32\", v_i % T.int64(8)) * T.uint32(4)), T.uint32(15))) - T.float16(7)) * lv1324[v_i // T.int64(32), v_j]\n",
    "        for i0, i1, i2, k in T.grid(T.int64(1), T.int64(1), T.int64(vocab_size), T.int64(4096)):\n",
    "            with T.block(\"matmul\"):\n",
    "                v_i0, v_i1, v_i2, v_k = T.axis.remap(\"SSSR\", [i0, i1, i2, k])\n",
    "                T.reads(lv1607[v_i0, v_i1, v_k], p_output0_intermediate_1[v_k, v_i2])\n",
    "                T.writes(var_matmul_intermediate[v_i0, v_i1, v_i2])\n",
    "                with T.init():\n",
    "                    var_matmul_intermediate[v_i0, v_i1, v_i2] = T.float16(0)\n",
    "                var_matmul_intermediate[v_i0, v_i1, v_i2] = var_matmul_intermediate[v_i0, v_i1, v_i2] + lv1607[v_i0, v_i1, v_k] * p_output0_intermediate_1[v_k, v_i2]\n",
    "        for i0, i1, i2 in T.grid(T.int64(1), T.int64(1), T.int64(vocab_size)):\n",
    "            with T.block(\"compute\"):\n",
    "                v_i0, v_i1, v_i2 = T.axis.remap(\"SSS\", [i0, i1, i2])\n",
    "                T.reads(var_matmul_intermediate[v_i0, v_i1, v_i2])\n",
    "                T.writes(p_output0_intermediate[v_i0, v_i1, v_i2])\n",
    "                p_output0_intermediate[v_i0, v_i1, v_i2] = T.Cast(\"float32\", var_matmul_intermediate[v_i0, v_i1, v_i2])\n",
    "    \n",
    "sch_unopt = tvm.tir.Schedule(ModuleUnOpt)\n",
    "# sch_unopt_mod = relax.transform.RewriteCUDAGraph()(sch_unopt.mod)\n",
    "print(target)\n",
    "### 将原始代码转为gpu代码\n",
    "with target:\n",
    "    sch_unopt_mod = tvm.tir.transform.DefaultGPUSchedule()(sch_unopt.mod)\n",
    "# print(sch_unopt_mod.script())\n",
    "rt_mod_unopt = tvm.build(sch_unopt_mod, target=\"cuda\")\n",
    "evaluator_unopt = rt_mod_unopt.time_evaluator(\"main\", dev, number=100)\n",
    "\n",
    "print(\"evaluator_opted GEMV-Blocking: %f GFLOPS\" % (num_flop / evaluator_unopt(W_nd, S_nd, Input_nd, Output_nd).mean / 1e9))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlc-chat-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
